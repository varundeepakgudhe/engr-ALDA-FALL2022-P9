{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmfhxkfM9S6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/corpus/train.csv\")\n",
        "\n",
        "#data_csv = pd.read_csv(url_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_csv.head()"
      ],
      "metadata": {
        "id": "kXMDQXJ3BX3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/unhealthy_full.csv\")\n",
        "\n",
        "data_csv = pd.read_csv(url_data)"
      ],
      "metadata": {
        "id": "NT6AepL6BX9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LeCtp8vgBYAK",
        "outputId": "92ea23b8-ca5f-4afa-9326-445191d9bcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90036f00-e55c-44d2-a655-1c3bca3eaab8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90036f00-e55c-44d2-a655-1c3bca3eaab8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90036f00-e55c-44d2-a655-1c3bca3eaab8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90036f00-e55c-44d2-a655-1c3bca3eaab8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7mQ2QVRBYCV",
        "outputId": "dabab9d3-1550-48af-8cc6-164ebf301872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227975, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv[\"comment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyUo0Kw5p-L",
        "outputId": "5df195ed-409f-46e0-83dd-94daeac69bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Moon, Do you *really* need it spelled out to you?\n",
              "1         It means you can ask the values questions, but...\n",
              "2                                           To you perhaps.\n",
              "3         I don't want to put words in your mouth, but a...\n",
              "4         perhaps this is not a problem seeing as how ev...\n",
              "                                ...                        \n",
              "227970    In 2001 the price of oil was around $25 a barr...\n",
              "227971    How about answering the question asked rather ...\n",
              "227972    Re: 'he is not a war mugger' [sic]You seem to ...\n",
              "227973    At last someone trotting out facts instead of ...\n",
              "227974    why should I care what the catholic dinosaurs ...\n",
              "Name: comment, Length: 227975, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop=data_csv.drop_duplicates(subset=\"comment\")"
      ],
      "metadata": {
        "id": "nDc5Mt7R1o6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2idkutuJ1ze-",
        "outputId": "3e4813f2-5d77-4557-a518-4f4f7064cd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44355, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull= data_csv_drop.dropna()\n",
        "data_cnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqqNcmOYpywO",
        "outputId": "bc46f844-6e47-45ba-a1eb-55cbbb775daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44354, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yOs2LL6ot3dP",
        "outputId": "52cb8bce-95ed-4b68-a0ac-4a62603fba21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b360bebb-de2a-48c4-a9a0-8a6d3a90a8f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b360bebb-de2a-48c4-a9a0-8a6d3a90a8f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b360bebb-de2a-48c4-a9a0-8a6d3a90a8f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b360bebb-de2a-48c4-a9a0-8a6d3a90a8f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_del_ind= data_cnull[(data_cnull[\"sarcastic\"]==0) & (data_cnull[\"healthy\"]==0) & (data_cnull[\"antagonize\"]==0) & (data_cnull[\"condescending\"]==0) & (data_cnull[\"dismissive\"]==0) & (data_cnull[\"hostile\"]==0)].index\n",
        "data_pnull = data_cnull.drop(data_del_ind)\n",
        "data_pnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWvcOswmtkC1",
        "outputId": "fa396b95-0516-41c1-cced-2f41ee34ba33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42278, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n",
        "data_wnull = data_pnull.drop(data_wnull_ind)\n",
        "data_wnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOdsHMpvzyrM",
        "outputId": "219d76ed-3c3a-43e9-a2be-f5207c818f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9fd0ced5066b>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39533, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_test= train_test_split(data_wnull, test_size=0.2, random_state=42)\n",
        "print(data_train.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5g_K__T0wfa",
        "outputId": "991b3845-8c57-438a-f1fb-30252a0131ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31626, 12) (7907, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_wnull[(data_wnull['sarcastic']==1) & (data_wnull['healthy']==0)]"
      ],
      "metadata": {
        "id": "olJUcqUtzlbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_wnull[(data_wnull['sarcastic']==0) & (data_wnull['healthy']==0) & (data_wnull['antagonize']==0) & (data_wnull['condescending']==0) & (data_wnull['dismissive']==0) & (data_wnull['generalisation']==0) & (data_wnull['generalisation_unfair']==0) & (data_wnull['hostile']==0)]"
      ],
      "metadata": {
        "id": "rlBcbpTktIjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_all= data_wnull.drop(data_wnull[(data_wnull['sarcastic']==0) & (data_wnull['healthy']==0) & (data_wnull['antagonize']==0) & (data_wnull['condescending']==0) & (data_wnull['dismissive']==0) & (data_wnull['generalisation']==0) & (data_wnull['generalisation_unfair']==0) & (data_wnull['hostile']==0)].index)\n",
        "# data_all.shape"
      ],
      "metadata": {
        "id": "3OWD6fgwwu65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgEKZzkNVe-",
        "outputId": "2c163907-6114-4a5c-a87b-ce2ecc58fa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "embed_size = 300\n",
        "max_features = 20000 \n",
        "maxlen = 300 \n",
        "\n",
        "print('Loading data...')\n",
        "\n",
        "classes = [\"sarcastic\", \"healthy\", \"antagonize\", \"condescending\", \"dismissive\", \"hostile\"]\n",
        "y = data_train[classes].values\n",
        "y_test = data_test[classes].values\n",
        "\n",
        "train_sentences = data_train[\"comment\"]\n",
        "test_sentences = data_test[\"comment\"]\n",
        "\n",
        "# print('Preprocessing train') \n",
        "# train = list()\n",
        "# for i in train_sentences:\n",
        "#     tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "#     train.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "# print('Preprocessing test')\n",
        "# test = list()\n",
        "# for i in test_sentences:\n",
        "#     tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "#     test.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "# train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTivuJ6Ltju",
        "outputId": "78b36b5e-cf90-43c3-afb0-90a99bb8390c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnAgYv_Rh1tc",
        "outputId": "363b7fac-6cd1-49d0-ce31-ac5c56e7118d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31626"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS7--RqfjBhm",
        "outputId": "80cd8f07-9478-45af-c932-28336dae17d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7907"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "EMBEDDING_FILE = '/content/drive/My Drive/glove.840B.300d.txt' "
      ],
      "metadata": {
        "id": "L7Q4DB-pmVOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c10008-4b37-4e86-83bd-6f51e3fb4aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "g-a2OOXgzZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, BatchNormalization, SpatialDropout1D, GlobalAveragePooling1D, concatenate, Activation, LSTM, Bidirectional\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, multilabel_confusion_matrix"
      ],
      "metadata": {
        "id": "g8yG4oc_zKiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "tokenized_train_sentences = tokenizer.texts_to_sequences(train_sentences)\n",
        "tokenized_test_sentences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_train_sentences, maxlen)\n",
        "test_padding = pad_sequences(tokenized_test_sentences, maxlen)\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "\n",
        "print(list(embeddings_index.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUdkl7HP0J9x",
        "outputId": "f7540574-eea8-4920-ed95-378753d55233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', array([-0.082752 ,  0.67204  , -0.14987  , -0.064983 ,  0.056491 ,\n",
            "        0.40228  ,  0.0027747, -0.3311   , -0.30691  ,  2.0817   ,\n",
            "        0.031819 ,  0.013643 ,  0.30265  ,  0.0071297, -0.5819   ,\n",
            "       -0.2774   , -0.062254 ,  1.1451   , -0.24232  ,  0.1235   ,\n",
            "       -0.12243  ,  0.33152  , -0.006162 , -0.30541  , -0.13057  ,\n",
            "       -0.054601 ,  0.037083 , -0.070552 ,  0.5893   , -0.30385  ,\n",
            "        0.2898   , -0.14653  , -0.27052  ,  0.37161  ,  0.32031  ,\n",
            "       -0.29125  ,  0.0052483, -0.13212  , -0.052736 ,  0.087349 ,\n",
            "       -0.26668  , -0.16897  ,  0.015162 , -0.0083746, -0.14871  ,\n",
            "        0.23413  , -0.20719  , -0.091386 ,  0.40075  , -0.17223  ,\n",
            "        0.18145  ,  0.37586  , -0.28682  ,  0.37289  , -0.16185  ,\n",
            "        0.18008  ,  0.3032   , -0.13216  ,  0.18352  ,  0.095759 ,\n",
            "        0.094916 ,  0.008289 ,  0.11761  ,  0.34046  ,  0.03677  ,\n",
            "       -0.29077  ,  0.058303 , -0.027814 ,  0.082941 ,  0.1862   ,\n",
            "       -0.031494 ,  0.27985  , -0.074412 , -0.13762  , -0.21866  ,\n",
            "        0.18138  ,  0.040855 , -0.113    ,  0.24107  ,  0.3657   ,\n",
            "       -0.27525  , -0.05684  ,  0.34872  ,  0.011884 ,  0.14517  ,\n",
            "       -0.71395  ,  0.48497  ,  0.14807  ,  0.62287  ,  0.20599  ,\n",
            "        0.58379  , -0.13438  ,  0.40207  ,  0.18311  ,  0.28021  ,\n",
            "       -0.42349  , -0.25626  ,  0.17715  , -0.54095  ,  0.16596  ,\n",
            "       -0.036058 ,  0.08499  , -0.64989  ,  0.075549 , -0.28831  ,\n",
            "        0.40626  , -0.2802   ,  0.094062 ,  0.32406  ,  0.28437  ,\n",
            "       -0.26341  ,  0.11553  ,  0.071918 , -0.47215  , -0.18366  ,\n",
            "       -0.34709  ,  0.29964  , -0.66514  ,  0.002516 , -0.42333  ,\n",
            "        0.27512  ,  0.36012  ,  0.16311  ,  0.23964  , -0.05923  ,\n",
            "        0.3261   ,  0.20559  ,  0.038677 , -0.045816 ,  0.089764 ,\n",
            "        0.43151  , -0.15954  ,  0.08532  , -0.26572  , -0.15001  ,\n",
            "        0.084286 , -0.16714  , -0.43004  ,  0.060807 ,  0.13121  ,\n",
            "       -0.24112  ,  0.66554  ,  0.4453   , -0.18019  , -0.13919  ,\n",
            "        0.56252  ,  0.21457  , -0.46443  , -0.012211 ,  0.029988 ,\n",
            "       -0.051094 , -0.20135  ,  0.80788  ,  0.47377  , -0.057647 ,\n",
            "        0.46216  ,  0.16084  , -0.20954  , -0.05452  ,  0.15572  ,\n",
            "       -0.13712  ,  0.12972  , -0.011936 , -0.003378 , -0.13595  ,\n",
            "       -0.080711 ,  0.20065  ,  0.054056 ,  0.046816 ,  0.059539 ,\n",
            "        0.046265 ,  0.17754  , -0.31094  ,  0.28119  , -0.24355  ,\n",
            "        0.085252 , -0.21011  , -0.19472  ,  0.0027297, -0.46341  ,\n",
            "        0.14789  , -0.31517  , -0.065939 ,  0.036106 ,  0.42903  ,\n",
            "       -0.33759  ,  0.16432  ,  0.32568  , -0.050392 , -0.054297 ,\n",
            "        0.24074  ,  0.41923  ,  0.13012  , -0.17167  , -0.37808  ,\n",
            "       -0.23089  , -0.019477 , -0.29291  , -0.30824  ,  0.30297  ,\n",
            "       -0.22659  ,  0.081574 , -0.18516  , -0.21408  ,  0.40616  ,\n",
            "       -0.28974  ,  0.074174 , -0.17795  ,  0.28595  , -0.039626 ,\n",
            "       -0.2339   , -0.36054  , -0.067503 , -0.091065 ,  0.23438  ,\n",
            "       -0.0041331,  0.003232 ,  0.0072134,  0.008697 ,  0.21614  ,\n",
            "        0.049904 ,  0.35582  ,  0.13748  ,  0.073361 ,  0.14166  ,\n",
            "        0.2412   , -0.013322 ,  0.15613  ,  0.083381 ,  0.088146 ,\n",
            "       -0.019357 ,  0.43795  ,  0.083961 ,  0.45309  , -0.50489  ,\n",
            "       -0.10865  , -0.2527   , -0.18251  ,  0.20441  ,  0.13319  ,\n",
            "        0.1294   ,  0.050594 , -0.15612  , -0.39543  ,  0.12538  ,\n",
            "        0.24881  , -0.1927   , -0.31847  , -0.12719  ,  0.4341   ,\n",
            "        0.31177  , -0.0040946, -0.2094   , -0.079961 ,  0.1161   ,\n",
            "       -0.050794 ,  0.015266 , -0.2803   , -0.12486  ,  0.23587  ,\n",
            "        0.2339   , -0.14023  ,  0.028462 ,  0.56923  , -0.1649   ,\n",
            "       -0.036429 ,  0.010051 , -0.17107  , -0.042608 ,  0.044965 ,\n",
            "       -0.4393   , -0.26137  ,  0.30088  , -0.060772 , -0.45312  ,\n",
            "       -0.19076  , -0.20288  ,  0.27694  , -0.060888 ,  0.11944  ,\n",
            "        0.62206  , -0.19343  ,  0.47849  , -0.30113  ,  0.059389 ,\n",
            "        0.074901 ,  0.061068 , -0.4662   ,  0.40054  , -0.19099  ,\n",
            "       -0.14331  ,  0.018267 , -0.18643  ,  0.20709  , -0.35598  ,\n",
            "        0.05338  , -0.050821 , -0.1918   , -0.37846  , -0.06589  ],\n",
            "      dtype=float32)), ('.', array([ 0.012001 ,  0.20751  , -0.12578  , -0.59325  ,  0.12525  ,\n",
            "        0.15975  ,  0.13748  , -0.33157  , -0.13694  ,  1.7893   ,\n",
            "       -0.47094  ,  0.70434  ,  0.26673  , -0.089961 , -0.18168  ,\n",
            "        0.067226 ,  0.053347 ,  1.5595   , -0.2541   ,  0.038413 ,\n",
            "       -0.01409  ,  0.056774 ,  0.023434 ,  0.024042 ,  0.31703  ,\n",
            "        0.19025  , -0.37505  ,  0.035603 ,  0.1181   ,  0.012032 ,\n",
            "       -0.037566 , -0.5046   , -0.049261 ,  0.092351 ,  0.11031  ,\n",
            "       -0.073062 ,  0.33994  ,  0.28239  ,  0.13413  ,  0.070128 ,\n",
            "       -0.022099 , -0.28103  ,  0.49607  , -0.48693  , -0.090964 ,\n",
            "       -0.1538   , -0.38011  , -0.014228 , -0.19392  , -0.11068  ,\n",
            "       -0.014088 , -0.17906  ,  0.24509  , -0.16878  , -0.15351  ,\n",
            "       -0.13808  ,  0.02151  ,  0.13699  ,  0.0068061, -0.14915  ,\n",
            "       -0.38169  ,  0.12727  ,  0.44007  ,  0.32678  , -0.46117  ,\n",
            "        0.068687 ,  0.34747  ,  0.18827  , -0.31837  ,  0.4447   ,\n",
            "       -0.2095   , -0.26987  ,  0.48945  ,  0.15388  ,  0.05295  ,\n",
            "       -0.049831 ,  0.11207  ,  0.14881  , -0.37003  ,  0.30777  ,\n",
            "       -0.33865  ,  0.045149 , -0.18987  ,  0.26634  , -0.26401  ,\n",
            "       -0.47556  ,  0.68381  , -0.30653  ,  0.24606  ,  0.31611  ,\n",
            "       -0.071098 ,  0.030417 ,  0.088119 ,  0.045025 ,  0.20125  ,\n",
            "       -0.21618  , -0.36371  , -0.25948  , -0.42398  , -0.14305  ,\n",
            "       -0.10208  ,  0.21498  , -0.21924  , -0.17935  ,  0.21546  ,\n",
            "        0.13801  ,  0.24504  , -0.2559   ,  0.054815 ,  0.21307  ,\n",
            "        0.2564   , -0.25673  ,  0.17961  , -0.47638  , -0.25181  ,\n",
            "       -0.0091498, -0.054362 , -0.21007  ,  0.12597  , -0.40795  ,\n",
            "       -0.021164 ,  0.20585  ,  0.18925  , -0.0051896, -0.51394  ,\n",
            "        0.28862  , -0.077748 , -0.27676  ,  0.46567  , -0.14225  ,\n",
            "       -0.17879  , -0.4357   , -0.32481  ,  0.15034  , -0.058367 ,\n",
            "        0.49652  ,  0.20472  ,  0.019866 ,  0.13326  ,  0.12823  ,\n",
            "       -1.0177   ,  0.29007  ,  0.28995  ,  0.029994 , -0.10763  ,\n",
            "        0.28665  , -0.24387  ,  0.22905  , -0.26249  , -0.069269 ,\n",
            "       -0.17889  ,  0.21936  ,  0.15146  ,  0.04567  , -0.050497 ,\n",
            "        0.071482 , -0.1027   , -0.080705 ,  0.30296  ,  0.031302 ,\n",
            "        0.26613  , -0.0060951,  0.10313  , -0.39987  , -0.043945 ,\n",
            "       -0.057625 ,  0.08702  , -0.098152 ,  0.22835  , -0.005211 ,\n",
            "        0.038075 ,  0.01591  , -0.20622  ,  0.021853 ,  0.0040426,\n",
            "       -0.043063 , -0.002294 , -0.26097  , -0.25802  , -0.28158  ,\n",
            "       -0.23118  , -0.010404 , -0.30102  , -0.4042   ,  0.014653 ,\n",
            "       -0.10445  ,  0.30377  , -0.20957  ,  0.3119   ,  0.068272 ,\n",
            "        0.1008   ,  0.010423 ,  0.54011  ,  0.29865  ,  0.12653  ,\n",
            "        0.013761 ,  0.21738  , -0.39521  ,  0.066633 ,  0.50327  ,\n",
            "        0.14913  , -0.11554  ,  0.010042 ,  0.095698 ,  0.16607  ,\n",
            "       -0.18808  ,  0.055019 ,  0.026715 , -0.3164   , -0.046583 ,\n",
            "       -0.051591 ,  0.023475 , -0.11007  ,  0.085642 ,  0.28394  ,\n",
            "        0.040497 ,  0.071986 ,  0.14157  , -0.021199 ,  0.44718  ,\n",
            "        0.20088  , -0.12964  , -0.067183 ,  0.47614  ,  0.13394  ,\n",
            "       -0.17287  , -0.37324  , -0.17285  ,  0.02683  , -0.1316   ,\n",
            "        0.09116  , -0.46487  ,  0.1274   , -0.090159 , -0.10552  ,\n",
            "        0.068006 , -0.13381  ,  0.17056  ,  0.089509 , -0.23133  ,\n",
            "       -0.27572  ,  0.061534 , -0.051646 ,  0.28377  ,  0.25286  ,\n",
            "       -0.24139  , -0.19905  ,  0.12049  , -0.1011   ,  0.27392  ,\n",
            "        0.27843  ,  0.26449  , -0.18292  , -0.048961 ,  0.19198  ,\n",
            "        0.17192  ,  0.33659  , -0.20184  , -0.34305  , -0.24553  ,\n",
            "       -0.15399  ,  0.3945   ,  0.22839  , -0.25753  , -0.25675  ,\n",
            "       -0.37332  , -0.23884  , -0.048816 ,  0.78323  ,  0.18851  ,\n",
            "       -0.26477  ,  0.096566 ,  0.062658 , -0.30668  , -0.43334  ,\n",
            "        0.10006  ,  0.21136  ,  0.039459 , -0.11077  ,  0.24421  ,\n",
            "        0.60942  , -0.46646  ,  0.086385 , -0.39702  , -0.23363  ,\n",
            "        0.021307 , -0.10778  , -0.2281   ,  0.50803  ,  0.11567  ,\n",
            "        0.16165  , -0.066737 , -0.29556  ,  0.022612 , -0.28135  ,\n",
            "        0.0635   ,  0.14019  ,  0.13871  , -0.36049  , -0.035    ],\n",
            "      dtype=float32)), ('the', array([ 2.7204e-01, -6.2030e-02, -1.8840e-01,  2.3225e-02, -1.8158e-02,\n",
            "        6.7192e-03, -1.3877e-01,  1.7708e-01,  1.7709e-01,  2.5882e+00,\n",
            "       -3.5179e-01, -1.7312e-01,  4.3285e-01, -1.0708e-01,  1.5006e-01,\n",
            "       -1.9982e-01, -1.9093e-01,  1.1871e+00, -1.6207e-01, -2.3538e-01,\n",
            "        3.6640e-03, -1.9156e-01, -8.5662e-02,  3.9199e-02, -6.6449e-02,\n",
            "       -4.2090e-02, -1.9122e-01,  1.1679e-02, -3.7138e-01,  2.1886e-01,\n",
            "        1.1423e-03,  4.3190e-01, -1.4205e-01,  3.8059e-01,  3.0654e-01,\n",
            "        2.0167e-02, -1.8316e-01, -6.5186e-03, -8.0549e-03, -1.2063e-01,\n",
            "        2.7507e-02,  2.9839e-01, -2.2896e-01, -2.2882e-01,  1.4671e-01,\n",
            "       -7.6301e-02, -1.2680e-01, -6.6651e-03, -5.2795e-02,  1.4258e-01,\n",
            "        1.5610e-01,  5.5510e-02, -1.6149e-01,  9.6290e-02, -7.6533e-02,\n",
            "       -4.9971e-02, -1.0195e-02, -4.7641e-02, -1.6679e-01, -2.3940e-01,\n",
            "        5.0141e-03, -4.9175e-02,  1.3338e-02,  4.1923e-01, -1.0104e-01,\n",
            "        1.5111e-02, -7.7706e-02, -1.3471e-01,  1.1900e-01,  1.0802e-01,\n",
            "        2.1061e-01, -5.1904e-02,  1.8527e-01,  1.7856e-01,  4.1293e-02,\n",
            "       -1.4385e-02, -8.2567e-02, -3.5483e-02, -7.6173e-02, -4.5367e-02,\n",
            "        8.9281e-02,  3.3672e-01, -2.2099e-01, -6.7275e-03,  2.3983e-01,\n",
            "       -2.3147e-01, -8.8592e-01,  9.1297e-02, -1.2123e-02,  1.3233e-02,\n",
            "       -2.5799e-01, -2.9720e-02,  1.6754e-02,  1.3690e-02,  3.2377e-01,\n",
            "        3.9546e-02,  4.2114e-02, -8.8243e-02,  3.0318e-01,  8.7747e-02,\n",
            "        1.6346e-01, -4.0485e-01, -4.3845e-02, -4.0697e-02,  2.0936e-01,\n",
            "       -7.7795e-01,  2.9970e-01,  2.3340e-01,  1.4891e-01, -3.9037e-01,\n",
            "       -5.3086e-02,  6.2922e-02,  6.5663e-02, -1.3906e-01,  9.4193e-02,\n",
            "        1.0344e-01, -2.7970e-01,  2.8905e-01, -3.2161e-01,  2.0687e-02,\n",
            "        6.3254e-02, -2.3257e-01, -4.3520e-01, -1.7049e-02, -3.2744e-01,\n",
            "       -4.7064e-02, -7.5149e-02, -1.8788e-01, -1.5017e-02,  2.9342e-02,\n",
            "       -3.5270e-01, -4.4278e-02, -1.3507e-01, -1.1644e-01, -1.0430e-01,\n",
            "        1.3920e-01,  3.9199e-03,  3.7603e-01,  6.7217e-02, -3.7992e-01,\n",
            "       -1.1241e+00, -5.7357e-02, -1.6826e-01,  3.9410e-02,  2.6040e-01,\n",
            "       -2.3866e-02,  1.7963e-01,  1.3553e-01,  2.1390e-01,  5.2633e-02,\n",
            "       -2.5033e-01, -1.1307e-01,  2.2234e-01,  6.6597e-02, -1.1161e-01,\n",
            "        6.2438e-02, -2.7972e-01,  1.9878e-01, -3.6262e-01, -1.0006e-05,\n",
            "       -1.7262e-01,  2.9166e-01, -1.5723e-01,  5.4295e-02,  6.1010e-02,\n",
            "       -3.9165e-01,  2.7660e-01,  5.7816e-02,  3.9709e-01,  2.5229e-02,\n",
            "        2.4672e-01, -8.9050e-02,  1.5683e-01, -2.0960e-01, -2.2196e-01,\n",
            "        5.2394e-02, -1.1360e-02,  5.0417e-02, -1.4023e-01, -4.2825e-02,\n",
            "       -3.1931e-02, -2.1336e-01, -2.0402e-01, -2.3272e-01,  7.4490e-02,\n",
            "        8.8202e-02, -1.1063e-01, -3.3526e-01, -1.4028e-02, -2.9429e-01,\n",
            "       -8.6911e-02, -1.3210e-01, -4.3616e-01,  2.0513e-01,  7.9362e-03,\n",
            "        4.8505e-01,  6.4237e-02,  1.4261e-01, -4.3711e-01,  1.2783e-01,\n",
            "       -1.3111e-01,  2.4673e-01, -2.7496e-01,  1.5896e-01,  4.3314e-01,\n",
            "        9.0286e-02,  2.4662e-01,  6.6463e-02, -2.0099e-01,  1.1010e-01,\n",
            "        3.6440e-02,  1.7359e-01, -1.5689e-01, -8.6328e-02, -1.7316e-01,\n",
            "        3.6975e-01, -4.0317e-01, -6.4814e-02, -3.4166e-02, -1.3773e-02,\n",
            "        6.2854e-02, -1.7183e-01, -1.2366e-01, -3.4663e-02, -2.2793e-01,\n",
            "       -2.3172e-01,  2.3900e-01,  2.7473e-01,  1.5332e-01,  1.0661e-01,\n",
            "       -6.0982e-02, -2.4805e-02, -1.3478e-01,  1.7932e-01, -3.7374e-01,\n",
            "       -2.8930e-02, -1.1142e-01, -8.3890e-02, -5.5932e-02,  6.8039e-02,\n",
            "       -1.0783e-01,  1.4650e-01,  9.4617e-02, -8.4554e-02,  6.7429e-02,\n",
            "       -3.2910e-01,  3.4082e-02, -1.6747e-01, -2.5997e-01, -2.2917e-01,\n",
            "        2.0159e-02, -2.7580e-02,  1.6136e-01, -1.8538e-01,  3.7665e-02,\n",
            "        5.7603e-01,  2.0684e-01,  2.7941e-01,  1.6477e-01, -1.8769e-02,\n",
            "        1.2062e-01,  6.9648e-02,  5.9022e-02, -2.3154e-01,  2.4095e-01,\n",
            "       -3.4710e-01,  4.8540e-02, -5.6502e-02,  4.1566e-01, -4.3194e-01,\n",
            "        4.8230e-01, -5.1759e-02, -2.7285e-01, -2.5893e-01,  1.6555e-01,\n",
            "       -1.8310e-01, -6.7340e-02,  4.2457e-01,  1.0346e-02,  1.4237e-01,\n",
            "        2.5939e-01,  1.7123e-01, -1.3821e-01, -6.6846e-02,  1.5981e-02,\n",
            "       -3.0193e-01,  4.3579e-02, -4.3102e-02,  3.5025e-01, -1.9681e-01,\n",
            "       -4.2810e-01,  1.6899e-01,  2.2511e-01, -2.8557e-01, -1.0280e-01,\n",
            "       -1.8168e-02,  1.1407e-01,  1.3015e-01, -1.8317e-01,  1.3230e-01],\n",
            "      dtype=float32)), ('and', array([-1.8567e-01,  6.6008e-02, -2.5209e-01, -1.1725e-01,  2.6513e-01,\n",
            "        6.4908e-02,  1.2291e-01, -9.3979e-02,  2.4321e-02,  2.4926e+00,\n",
            "       -1.7916e-02, -7.1218e-02, -2.4782e-01, -2.6237e-01, -2.2460e-01,\n",
            "       -2.1961e-01, -1.2927e-01,  1.0867e+00, -6.6072e-01, -3.1617e-02,\n",
            "       -5.7328e-02,  5.6903e-02, -2.7939e-01, -3.9825e-01,  1.4251e-01,\n",
            "       -8.5146e-02, -1.4779e-01,  5.5067e-02, -2.8687e-03, -2.0917e-01,\n",
            "       -7.0735e-02,  2.2577e-01, -1.5881e-01, -1.0395e-01,  9.7110e-02,\n",
            "       -5.6251e-01, -3.2929e-01, -2.0853e-01,  9.8711e-03,  4.9777e-02,\n",
            "        1.4883e-03,  1.5884e-01,  4.2771e-02, -2.6956e-03, -2.4620e-02,\n",
            "       -1.9213e-01, -2.2556e-01,  1.0838e-01,  9.0086e-02, -1.3291e-01,\n",
            "        3.2559e-01, -1.7038e-01, -1.0990e-01, -2.3986e-01, -2.4289e-02,\n",
            "        1.4656e-02, -2.3700e-01,  8.4828e-02, -3.5982e-01, -7.6746e-02,\n",
            "        4.8909e-02,  1.1431e-01, -2.1013e-01,  2.4765e-01, -1.7531e-02,\n",
            "       -1.4028e-01,  4.6191e-02,  2.2972e-01,  1.1750e-01,  1.2724e-01,\n",
            "        1.2992e-02,  4.5870e-01,  4.1085e-01,  3.9106e-02,  1.5713e-01,\n",
            "       -1.8376e-01,  2.6834e-01,  5.6662e-02,  1.6844e-01, -5.3788e-02,\n",
            "       -9.1892e-02,  1.1193e-01, -8.6810e-02, -1.3324e-01,  1.5062e-01,\n",
            "       -3.1733e-01, -2.2078e-01,  2.5038e-01,  3.4131e-01,  3.6419e-01,\n",
            "       -8.9514e-02, -2.2193e-01,  2.4471e-01,  4.0091e-02,  4.7798e-01,\n",
            "       -2.9996e-02,  1.9212e-03,  6.3511e-02, -2.0417e-01, -2.6478e-01,\n",
            "        2.0649e-01,  1.5573e-02, -2.7722e-01, -1.8861e-01, -1.0289e-01,\n",
            "       -4.9773e-01,  1.4986e-01, -1.0877e-02,  2.5085e-01, -2.8117e-01,\n",
            "        1.8966e-01, -6.5879e-02,  9.4753e-02, -1.5338e-01, -5.5071e-02,\n",
            "       -3.6747e-01,  2.4993e-01,  9.6527e-02,  2.3538e-01,  1.8405e-01,\n",
            "        5.2859e-02,  2.2967e-01,  1.2582e-01,  1.5536e-01, -1.7275e-01,\n",
            "        3.3946e-01, -1.0049e-01,  7.4948e-02, -9.3575e-02, -4.0490e-02,\n",
            "       -1.6922e-02, -5.8039e-03, -1.8108e-01,  1.9537e-01,  4.5178e-01,\n",
            "        1.0965e-01,  2.3370e-01, -9.9050e-02, -7.8633e-02,  2.1678e-01,\n",
            "       -7.1231e-01, -9.9759e-02,  3.3333e-01, -1.6460e-01, -9.1688e-02,\n",
            "        2.1056e-01,  2.3669e-02,  2.8922e-02,  1.1990e-01, -1.2512e-01,\n",
            "       -2.6037e-02, -6.2217e-02,  5.5816e-01,  5.0273e-03, -3.0888e-01,\n",
            "        3.8611e-02,  1.7568e-01, -1.1163e-01, -1.0815e-01, -1.9444e-01,\n",
            "        2.9433e-01,  1.4519e-01, -4.2878e-02,  1.8534e-01,  1.8891e-02,\n",
            "       -6.1883e-01,  1.3352e-01,  3.6007e-02,  3.3995e-01,  2.2109e-01,\n",
            "       -7.9328e-02,  7.1319e-02,  1.7678e-01,  1.6378e-01, -2.3142e-01,\n",
            "       -1.4340e-01, -9.8122e-02, -1.9286e-02,  2.3560e-01, -3.4013e-01,\n",
            "       -6.1007e-02, -2.3208e-01, -3.1152e-01,  1.0063e-01, -1.5957e-01,\n",
            "        2.0183e-01, -1.6345e-02, -1.2303e-01,  2.2667e-02, -2.0986e-01,\n",
            "       -2.0127e-01, -8.7883e-02,  6.4731e-02,  1.0195e-01, -1.7860e-01,\n",
            "        3.3056e-01,  2.1407e-01, -3.2165e-01, -1.7106e-01,  1.9407e-01,\n",
            "       -3.8618e-01, -2.1480e-01, -5.2254e-02,  2.3175e-02,  4.7389e-01,\n",
            "        1.8612e-01,  1.2711e-01,  2.0855e-01, -1.0256e-01, -1.2016e-01,\n",
            "       -4.0488e-01,  2.9695e-02, -2.7419e-02, -8.5227e-03, -1.1415e-01,\n",
            "        8.1134e-02, -1.7228e-01,  1.9142e-01,  2.6514e-02,  4.3789e-02,\n",
            "       -1.2399e-01,  1.3354e-01,  1.0112e-01,  8.1682e-02, -1.5085e-01,\n",
            "        7.5806e-03, -1.8971e-01,  2.4669e-01,  2.2491e-01,  3.5553e-01,\n",
            "       -3.2770e-01, -2.1821e-01,  1.4020e-01,  2.8604e-01,  5.5226e-02,\n",
            "       -8.6544e-02,  2.1110e-02, -1.9236e-01,  7.4245e-02,  7.6782e-02,\n",
            "        8.1666e-04,  3.4097e-02, -5.7719e-01,  1.0657e-01,  2.8134e-01,\n",
            "       -1.1964e-01, -6.8281e-01, -3.2893e-01, -2.4442e-01, -2.5847e-02,\n",
            "        9.1273e-03,  2.0250e-01, -5.0959e-02, -1.1042e-01,  1.0962e-02,\n",
            "        7.6773e-02,  4.0048e-01, -4.0739e-01, -4.4773e-01,  3.1954e-01,\n",
            "       -3.6326e-02, -1.2789e-02, -1.7282e-01,  1.4760e-01,  2.3560e-01,\n",
            "        8.0642e-02, -3.6528e-01, -8.3443e-03,  6.2390e-01, -2.4379e-01,\n",
            "        1.9917e-02, -2.8803e-01, -1.0494e-02,  3.8412e-02, -1.1718e-01,\n",
            "       -7.2462e-02,  1.6381e-01,  3.8488e-01, -2.9783e-02,  2.3444e-01,\n",
            "        4.5320e-01,  1.4815e-01, -2.7021e-02, -7.3181e-02, -1.1470e-01,\n",
            "       -5.4545e-03,  4.7796e-01,  9.0912e-02,  9.4489e-02, -3.6882e-01,\n",
            "       -5.9396e-01, -9.7729e-02,  2.0072e-01,  1.7055e-01, -4.7356e-03,\n",
            "       -3.9709e-02,  3.2498e-01, -2.3452e-02,  1.2302e-01,  3.3120e-01],\n",
            "      dtype=float32)), ('to', array([ 3.1924e-01,  6.3160e-02, -2.7858e-01,  2.6120e-01,  7.9248e-02,\n",
            "       -2.1462e-01, -1.0495e-01,  1.5495e-01, -3.3530e-02,  2.4834e+00,\n",
            "       -5.0904e-01,  8.7490e-02,  2.1426e-01,  2.2151e-01, -2.5234e-01,\n",
            "       -9.7544e-02, -1.9270e-01,  1.3606e+00, -1.1592e-01, -1.0383e-01,\n",
            "        2.1929e-01,  1.1997e-01, -1.1063e-01,  1.4212e-01, -1.6643e-01,\n",
            "        2.1815e-01,  4.2086e-03, -7.0012e-02, -2.3532e-01, -2.6518e-01,\n",
            "        3.1248e-02,  1.6669e-01, -8.9777e-02,  2.0059e-01,  3.1614e-01,\n",
            "       -5.5830e-01,  7.5735e-02,  2.7635e-01,  1.2741e-01, -1.8185e-01,\n",
            "       -1.2722e-01,  2.4686e-02, -7.7233e-02, -4.8998e-01,  2.0355e-02,\n",
            "        3.9164e-03,  1.2150e-01,  8.9723e-02, -7.8975e-02,  8.1443e-02,\n",
            "       -9.9087e-02, -5.5621e-02,  1.0737e-01, -4.4042e-03,  4.8496e-01,\n",
            "        1.1717e-01, -1.7329e-02,  1.0900e-01, -3.5558e-01,  5.1084e-02,\n",
            "        1.5714e-01,  1.7961e-01, -2.9711e-01,  3.3645e-02, -2.5792e-02,\n",
            "       -1.3931e-02, -2.3000e-01, -4.0306e-02,  2.2282e-01, -1.3544e-02,\n",
            "        1.1554e-02,  3.9110e-01,  2.6533e-01, -3.1012e-01,  4.0539e-01,\n",
            "       -4.2975e-02,  2.0811e-02, -3.3033e-01,  1.9573e-01, -3.7958e-02,\n",
            "        1.0274e-01, -1.3581e-03, -4.4505e-01,  7.7886e-02,  8.5110e-02,\n",
            "       -2.0285e-01, -1.9481e-01,  5.6933e-02,  5.3105e-01,  3.4154e-02,\n",
            "       -5.6996e-01, -1.8469e-01,  9.3403e-02,  2.8044e-01, -2.3349e-01,\n",
            "        1.0938e-01, -1.4288e-02, -2.7400e-01,  3.4196e-02, -9.8479e-02,\n",
            "        1.3268e-01,  1.9437e-01,  1.3463e-01, -9.9059e-02,  4.0324e-02,\n",
            "       -6.6272e-01,  3.5710e-01,  1.5429e-01,  1.8598e-01,  8.7542e-02,\n",
            "        8.0538e-02, -2.5121e-01,  2.4155e-01,  1.7830e-01,  3.6011e-02,\n",
            "       -2.7677e-02,  2.1161e-01, -2.9107e-01, -8.3456e-03,  1.1317e-01,\n",
            "        3.1064e-01, -1.0693e-01, -2.7367e-01, -3.9785e-02,  3.9881e-02,\n",
            "        3.4462e-02, -1.6518e-01,  1.6115e-01,  6.0826e-02,  3.0750e-01,\n",
            "       -2.2398e-01,  1.4619e-01, -2.6610e-01,  4.9732e-01, -1.3996e-01,\n",
            "       -2.4287e-01,  3.9469e-02, -8.4495e-02, -2.4315e-01,  7.0701e-02,\n",
            "       -1.0136e+00, -2.1733e-01, -3.6878e-01, -2.4973e-01,  1.7472e-01,\n",
            "       -1.1592e-02,  6.8561e-02, -9.0411e-02,  2.1878e-01, -2.6390e-01,\n",
            "        1.1904e-01,  1.4285e-01, -1.8707e-01, -1.3474e-01, -1.3232e-01,\n",
            "       -2.6553e-01,  2.2947e-01, -1.8215e-02,  6.7383e-03, -1.0190e-01,\n",
            "        1.0053e-01, -1.1270e-01, -1.3295e-01,  1.5951e-01,  1.4906e-01,\n",
            "       -9.5578e-02,  2.6992e-01,  1.1057e-02,  5.6568e-02,  2.1386e-02,\n",
            "        2.0215e-01,  4.8589e-04,  5.3360e-01, -2.2947e-01,  2.9275e-01,\n",
            "        1.7378e-01,  2.5423e-01, -1.0976e-01,  5.8816e-02,  1.4616e-02,\n",
            "       -4.3060e-02,  1.0732e-01, -2.8149e-02, -1.9181e-01,  1.0250e-01,\n",
            "       -6.3892e-02,  1.2737e-02, -1.2913e-01,  1.5037e-02,  2.6562e-01,\n",
            "       -1.7049e-02, -6.0716e-02, -9.4919e-02,  1.7775e-02,  1.3221e-01,\n",
            "        1.6830e-01, -1.9323e-01, -1.7612e-01,  7.5506e-02,  1.8939e-01,\n",
            "        1.2508e-01, -1.9880e-01, -1.6017e-01, -2.1092e-01,  4.6933e-01,\n",
            "        4.4747e-02,  9.8349e-02,  1.1637e-02,  2.2281e-01, -1.0837e-02,\n",
            "       -4.8330e-02, -4.7335e-01, -3.6811e-01, -1.3592e-01, -1.5086e-01,\n",
            "        2.5416e-01,  6.9531e-02,  1.4211e-01, -2.6703e-01, -1.2590e-01,\n",
            "        1.2076e-01, -2.6117e-01,  3.3024e-02, -3.4398e-02, -1.3968e-01,\n",
            "        1.3446e-01, -1.6709e-01,  1.5002e-01, -1.3724e-01,  9.1226e-02,\n",
            "       -2.7718e-01,  2.0098e-02,  2.6919e-01,  4.3016e-01,  9.4019e-02,\n",
            "       -8.5496e-02, -2.5192e-01, -1.1645e-01, -3.9734e-02,  4.6738e-03,\n",
            "        5.4178e-01, -1.6636e-01,  3.4546e-01,  9.8501e-02,  4.7819e-01,\n",
            "       -3.8428e-01, -3.2380e-01, -1.4822e-01, -4.7817e-01,  1.6704e-01,\n",
            "       -6.4505e-02,  1.1834e-01, -3.4480e-01,  9.6891e-02,  3.2309e-01,\n",
            "        4.1471e-01,  1.9463e-01, -2.0891e-01, -1.2223e-01, -5.8298e-02,\n",
            "       -2.0268e-01,  2.9480e-01,  4.3397e-02,  1.0112e-01,  2.7177e-01,\n",
            "       -5.2124e-01, -7.3794e-02,  4.4808e-02,  4.1388e-01,  8.8782e-02,\n",
            "        6.2255e-01, -7.2391e-02,  9.0129e-02,  1.5428e-01,  2.3163e-02,\n",
            "       -1.3028e-01,  6.1762e-02,  3.3803e-01, -9.1581e-02,  2.1039e-01,\n",
            "        5.1080e-02,  1.9184e-01,  1.0444e-01,  2.1380e-01, -3.5091e-01,\n",
            "       -2.3702e-01,  3.8399e-02, -1.0031e-01,  1.8359e-01,  2.5178e-02,\n",
            "       -1.2977e-01,  3.7130e-01,  1.8888e-01, -4.2738e-03, -1.0645e-01,\n",
            "       -2.5810e-01, -4.4629e-02,  8.2745e-02,  9.7801e-02,  2.5045e-01],\n",
            "      dtype=float32))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_index.get('society'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FXbqdDdH2O5",
        "outputId": "4b75dc50-33b9-49b4-fdc7-af9b382574fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JtsYXYgHXV5",
        "outputId": "6250f005-f0ee-4c62-af1c-8ef8d3287902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.27204001, -0.06203   , -0.1884    , ...,  0.13015001,\n",
              "        -0.18317001,  0.1323    ],\n",
              "       [ 0.31924   ,  0.06316   , -0.27858001, ...,  0.082745  ,\n",
              "         0.097801  ,  0.25044999],\n",
              "       [ 0.043798  ,  0.024779  , -0.20937   , ..., -0.30098999,\n",
              "        -0.14584   ,  0.28187999],\n",
              "       [-0.18567   ,  0.066008  , -0.25209001, ..., -0.023452  ,\n",
              "         0.12302   ,  0.3312    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2wdBZkUXXcX",
        "outputId": "2784ca3b-5490-4611-8753-4d3a61102d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10)\n",
        "cvscores = []\n",
        "accscores = []\n",
        "rocscores = []\n",
        "\n",
        "for train, test in kfold.split(train_padding, y):\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    output = Dense(6, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "\n",
        "    saved_model = \"model.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(train_padding, y, batch_size=32, epochs=5, callbacks=[checkpoint], validation_split=0.1)\n",
        "\n",
        "    scores = model.evaluate(train_padding[test], y[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    y_pred = model.predict(test_padding)\n",
        "\n",
        "    y_int = np.zeros_like(y_pred)\n",
        "    y_int[y_pred > 0.5] = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_int)\n",
        "    print('Accuracy is {}'.format(accuracy))\n",
        "    accscores.append(accuracy)\n",
        "    \n",
        "    rocauc = roc_auc_score(y_test, y_pred)\n",
        "    print('Roc-auc score is {}'.format(rocauc))\n",
        "    rocscores.append(rocauc)\n",
        "    \n",
        "    print('Classification report {}'.format(classification_report(y_test, y_int, zero_division=0)))\n",
        "    print('Confusion matrix {}'.format(multilabel_confusion_matrix(y_test, y_int)))\n",
        "        \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"Test accuracy is: {} %.2f (+/- %.2f)\" %  (np.mean(accscores), np.std(accscores)))\n",
        "print(\"Test roc-auc is: {} %.2f (+/- %.2f)\" % (np.mean(rocscores), np.std(rocscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCce4Qc4YdDJ",
        "outputId": "0a0e9d56-a166-40d3-e5c5-90e5b861518c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 90000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.8803\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 10s 8ms/step - loss: 0.2376 - acc: 0.8803 - val_loss: 0.2320 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.8830\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1764 - acc: 0.8830 - val_loss: 0.2530 - val_acc: 0.8716\n",
            "Epoch 3/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1026 - acc: 0.9045\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1026 - acc: 0.9045 - val_loss: 0.3333 - val_acc: 0.8482\n",
            "Epoch 4/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9183\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0785 - acc: 0.9181 - val_loss: 0.4123 - val_acc: 0.8416\n",
            "Epoch 5/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9278\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0688 - acc: 0.9278 - val_loss: 0.4577 - val_acc: 0.8290\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0575 - acc: 0.9339\n",
            "acc: 93.39%\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Accuracy is 0.8191475907423802\n",
            "Roc-auc score is 0.6236606784518794\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.04      0.06       565\n",
            "           1       0.91      0.95      0.93      7108\n",
            "           2       0.20      0.07      0.10       549\n",
            "           3       0.15      0.03      0.05       498\n",
            "           4       0.15      0.02      0.04       393\n",
            "           5       0.09      0.02      0.03       397\n",
            "\n",
            "   micro avg       0.85      0.72      0.78      9510\n",
            "   macro avg       0.27      0.19      0.20      9510\n",
            "weighted avg       0.71      0.72      0.71      9510\n",
            " samples avg       0.85      0.85      0.85      9510\n",
            "\n",
            "Confusion matrix [[[7197  145]\n",
            "  [ 542   23]]\n",
            "\n",
            " [[ 102  697]\n",
            "  [ 351 6757]]\n",
            "\n",
            " [[7213  145]\n",
            "  [ 513   36]]\n",
            "\n",
            " [[7327   82]\n",
            "  [ 484   14]]\n",
            "\n",
            " [[7468   46]\n",
            "  [ 385    8]]\n",
            "\n",
            " [[7451   59]\n",
            "  [ 391    6]]]\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.8812\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2395 - acc: 0.8812 - val_loss: 0.2227 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "883/890 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.8830\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.1762 - acc: 0.8830 - val_loss: 0.2529 - val_acc: 0.8603\n",
            "Epoch 3/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9042\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1027 - acc: 0.9043 - val_loss: 0.3527 - val_acc: 0.8599\n",
            "Epoch 4/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9170\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0807 - acc: 0.9173 - val_loss: 0.3793 - val_acc: 0.8416\n",
            "Epoch 5/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9273\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0687 - acc: 0.9273 - val_loss: 0.4606 - val_acc: 0.8271\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0591 - acc: 0.9418\n",
            "acc: 94.18%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8100417351713671\n",
            "Roc-auc score is 0.615139339995194\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.07      0.09       565\n",
            "           1       0.90      0.95      0.92      7108\n",
            "           2       0.20      0.06      0.09       549\n",
            "           3       0.20      0.05      0.08       498\n",
            "           4       0.17      0.03      0.05       393\n",
            "           5       0.13      0.03      0.05       397\n",
            "\n",
            "   micro avg       0.83      0.72      0.77      9510\n",
            "   macro avg       0.29      0.20      0.21      9510\n",
            "weighted avg       0.72      0.72      0.71      9510\n",
            " samples avg       0.85      0.84      0.84      9510\n",
            "\n",
            "Confusion matrix [[[7002  340]\n",
            "  [ 523   42]]\n",
            "\n",
            " [[  92  707]\n",
            "  [ 384 6724]]\n",
            "\n",
            " [[7219  139]\n",
            "  [ 515   34]]\n",
            "\n",
            " [[7302  107]\n",
            "  [ 472   26]]\n",
            "\n",
            " [[7460   54]\n",
            "  [ 382   11]]\n",
            "\n",
            " [[7439   71]\n",
            "  [ 386   11]]]\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2387 - acc: 0.8809\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2387 - acc: 0.8809 - val_loss: 0.2369 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.8830\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.1758 - acc: 0.8830 - val_loss: 0.2836 - val_acc: 0.8656\n",
            "Epoch 3/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9035\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1013 - acc: 0.9038 - val_loss: 0.3401 - val_acc: 0.8580\n",
            "Epoch 4/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9160\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0786 - acc: 0.9160 - val_loss: 0.3948 - val_acc: 0.8245\n",
            "Epoch 5/5\n",
            "887/890 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9255\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 7ms/step - loss: 0.0703 - acc: 0.9253 - val_loss: 0.5143 - val_acc: 0.8403\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0609 - acc: 0.9267\n",
            "acc: 92.67%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8247122802579993\n",
            "Roc-auc score is 0.6199463981266985\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.01      0.02       565\n",
            "           1       0.91      0.95      0.93      7108\n",
            "           2       0.22      0.06      0.09       549\n",
            "           3       0.15      0.02      0.04       498\n",
            "           4       0.12      0.02      0.03       393\n",
            "           5       0.12      0.02      0.04       397\n",
            "\n",
            "   micro avg       0.86      0.72      0.78      9510\n",
            "   macro avg       0.27      0.18      0.19      9510\n",
            "weighted avg       0.71      0.72      0.70      9510\n",
            " samples avg       0.86      0.84      0.85      9510\n",
            "\n",
            "Confusion matrix [[[7272   70]\n",
            "  [ 559    6]]\n",
            "\n",
            " [[  95  704]\n",
            "  [ 355 6753]]\n",
            "\n",
            " [[7240  118]\n",
            "  [ 516   33]]\n",
            "\n",
            " [[7343   66]\n",
            "  [ 486   12]]\n",
            "\n",
            " [[7461   53]\n",
            "  [ 386    7]]\n",
            "\n",
            " [[7446   64]\n",
            "  [ 388    9]]]\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2398 - acc: 0.8810\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2398 - acc: 0.8810 - val_loss: 0.2333 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.8819\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1753 - acc: 0.8820 - val_loss: 0.2519 - val_acc: 0.8625\n",
            "Epoch 3/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9026\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1058 - acc: 0.9026 - val_loss: 0.3775 - val_acc: 0.8603\n",
            "Epoch 4/5\n",
            "887/890 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9144\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0820 - acc: 0.9143 - val_loss: 0.3801 - val_acc: 0.8267\n",
            "Epoch 5/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9249\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0698 - acc: 0.9249 - val_loss: 0.4743 - val_acc: 0.8343\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0638 - acc: 0.9301\n",
            "acc: 93.01%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.820791703553813\n",
            "Roc-auc score is 0.6283821222984962\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.03      0.05       565\n",
            "           1       0.91      0.95      0.93      7108\n",
            "           2       0.25      0.08      0.13       549\n",
            "           3       0.21      0.03      0.05       498\n",
            "           4       0.11      0.01      0.01       393\n",
            "           5       0.11      0.01      0.01       397\n",
            "\n",
            "   micro avg       0.86      0.72      0.78      9510\n",
            "   macro avg       0.28      0.18      0.20      9510\n",
            "weighted avg       0.72      0.72      0.71      9510\n",
            " samples avg       0.86      0.84      0.85      9510\n",
            "\n",
            "Confusion matrix [[[7200  142]\n",
            "  [ 547   18]]\n",
            "\n",
            " [[  98  701]\n",
            "  [ 358 6750]]\n",
            "\n",
            " [[7218  140]\n",
            "  [ 503   46]]\n",
            "\n",
            " [[7355   54]\n",
            "  [ 484   14]]\n",
            "\n",
            " [[7490   24]\n",
            "  [ 390    3]]\n",
            "\n",
            " [[7486   24]\n",
            "  [ 394    3]]]\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.8807\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2399 - acc: 0.8806 - val_loss: 0.2234 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.8832\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1761 - acc: 0.8832 - val_loss: 0.2607 - val_acc: 0.8707\n",
            "Epoch 3/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1047 - acc: 0.9037\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1047 - acc: 0.9037 - val_loss: 0.3369 - val_acc: 0.8514\n",
            "Epoch 4/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9160\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0794 - acc: 0.9161 - val_loss: 0.3987 - val_acc: 0.8113\n",
            "Epoch 5/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9252\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0691 - acc: 0.9253 - val_loss: 0.4934 - val_acc: 0.8426\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0529 - acc: 0.9314\n",
            "acc: 93.14%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8328063740988997\n",
            "Roc-auc score is 0.6219619673232062\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.05      0.07       565\n",
            "           1       0.90      0.97      0.93      7108\n",
            "           2       0.25      0.06      0.10       549\n",
            "           3       0.24      0.04      0.07       498\n",
            "           4       0.16      0.03      0.05       393\n",
            "           5       0.19      0.03      0.06       397\n",
            "\n",
            "   micro avg       0.85      0.73      0.79      9510\n",
            "   macro avg       0.31      0.20      0.21      9510\n",
            "weighted avg       0.72      0.73      0.72      9510\n",
            " samples avg       0.87      0.86      0.86      9510\n",
            "\n",
            "Confusion matrix [[[7141  201]\n",
            "  [ 538   27]]\n",
            "\n",
            " [[  73  726]\n",
            "  [ 243 6865]]\n",
            "\n",
            " [[7256  102]\n",
            "  [ 515   34]]\n",
            "\n",
            " [[7338   71]\n",
            "  [ 476   22]]\n",
            "\n",
            " [[7452   62]\n",
            "  [ 381   12]]\n",
            "\n",
            " [[7456   54]\n",
            "  [ 384   13]]]\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.8804\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2394 - acc: 0.8804 - val_loss: 0.2237 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.8839\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1743 - acc: 0.8839 - val_loss: 0.2722 - val_acc: 0.8612\n",
            "Epoch 3/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9036\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1023 - acc: 0.9035 - val_loss: 0.3243 - val_acc: 0.8432\n",
            "Epoch 4/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9180\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0785 - acc: 0.9181 - val_loss: 0.4380 - val_acc: 0.8603\n",
            "Epoch 5/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9269\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0671 - acc: 0.9269 - val_loss: 0.5224 - val_acc: 0.8347\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0588 - acc: 0.9285\n",
            "acc: 92.85%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.820665233337549\n",
            "Roc-auc score is 0.6178897699460294\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.06      0.08       565\n",
            "           1       0.90      0.95      0.93      7108\n",
            "           2       0.19      0.08      0.11       549\n",
            "           3       0.16      0.05      0.07       498\n",
            "           4       0.16      0.04      0.07       393\n",
            "           5       0.13      0.04      0.06       397\n",
            "\n",
            "   micro avg       0.83      0.73      0.77      9510\n",
            "   macro avg       0.28      0.20      0.22      9510\n",
            "weighted avg       0.72      0.73      0.71      9510\n",
            " samples avg       0.86      0.85      0.85      9510\n",
            "\n",
            "Confusion matrix [[[7091  251]\n",
            "  [ 530   35]]\n",
            "\n",
            " [[  86  713]\n",
            "  [ 338 6770]]\n",
            "\n",
            " [[7175  183]\n",
            "  [ 506   43]]\n",
            "\n",
            " [[7284  125]\n",
            "  [ 474   24]]\n",
            "\n",
            " [[7426   88]\n",
            "  [ 376   17]]\n",
            "\n",
            " [[7420   90]\n",
            "  [ 383   14]]]\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.8799\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2386 - acc: 0.8800 - val_loss: 0.2277 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.8817\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1770 - acc: 0.8817 - val_loss: 0.2554 - val_acc: 0.8697\n",
            "Epoch 3/5\n",
            "883/890 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9026\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1058 - acc: 0.9026 - val_loss: 0.3324 - val_acc: 0.8587\n",
            "Epoch 4/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9158\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0807 - acc: 0.9159 - val_loss: 0.4389 - val_acc: 0.8561\n",
            "Epoch 5/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9277\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0694 - acc: 0.9276 - val_loss: 0.4356 - val_acc: 0.8214\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0664 - acc: 0.9355\n",
            "acc: 93.55%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.7927153155431895\n",
            "Roc-auc score is 0.6185268865019234\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.08      0.10       565\n",
            "           1       0.91      0.94      0.92      7108\n",
            "           2       0.19      0.10      0.13       549\n",
            "           3       0.16      0.06      0.09       498\n",
            "           4       0.15      0.05      0.08       393\n",
            "           5       0.14      0.05      0.07       397\n",
            "\n",
            "   micro avg       0.81      0.72      0.76      9510\n",
            "   macro avg       0.28      0.21      0.23      9510\n",
            "weighted avg       0.72      0.72      0.71      9510\n",
            " samples avg       0.84      0.84      0.83      9510\n",
            "\n",
            "Confusion matrix [[[7044  298]\n",
            "  [ 519   46]]\n",
            "\n",
            " [[ 120  679]\n",
            "  [ 460 6648]]\n",
            "\n",
            " [[7133  225]\n",
            "  [ 496   53]]\n",
            "\n",
            " [[7248  161]\n",
            "  [ 467   31]]\n",
            "\n",
            " [[7404  110]\n",
            "  [ 373   20]]\n",
            "\n",
            " [[7388  122]\n",
            "  [ 377   20]]]\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.8807\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2386 - acc: 0.8808 - val_loss: 0.2301 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.8832\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1762 - acc: 0.8831 - val_loss: 0.2523 - val_acc: 0.8701\n",
            "Epoch 3/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9039\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1042 - acc: 0.9038 - val_loss: 0.3534 - val_acc: 0.8426\n",
            "Epoch 4/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9162\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0811 - acc: 0.9163 - val_loss: 0.4490 - val_acc: 0.8631\n",
            "Epoch 5/5\n",
            "887/890 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9214\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0715 - acc: 0.9215 - val_loss: 0.4761 - val_acc: 0.8479\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0668 - acc: 0.9216\n",
            "acc: 92.16%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8381181231819906\n",
            "Roc-auc score is 0.6223506865172937\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.01      0.02       565\n",
            "           1       0.91      0.96      0.93      7108\n",
            "           2       0.23      0.06      0.09       549\n",
            "           3       0.21      0.03      0.05       498\n",
            "           4       0.21      0.03      0.05       393\n",
            "           5       0.17      0.03      0.05       397\n",
            "\n",
            "   micro avg       0.87      0.73      0.79      9510\n",
            "   macro avg       0.30      0.19      0.20      9510\n",
            "weighted avg       0.72      0.73      0.71      9510\n",
            " samples avg       0.87      0.85      0.86      9510\n",
            "\n",
            "Confusion matrix [[[7280   62]\n",
            "  [ 558    7]]\n",
            "\n",
            " [[  83  716]\n",
            "  [ 267 6841]]\n",
            "\n",
            " [[7250  108]\n",
            "  [ 517   32]]\n",
            "\n",
            " [[7354   55]\n",
            "  [ 483   15]]\n",
            "\n",
            " [[7468   46]\n",
            "  [ 381   12]]\n",
            "\n",
            " [[7456   54]\n",
            "  [ 386   11]]]\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2379 - acc: 0.8801\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 9s 9ms/step - loss: 0.2379 - acc: 0.8801 - val_loss: 0.2272 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.8840\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1742 - acc: 0.8839 - val_loss: 0.2617 - val_acc: 0.8587\n",
            "Epoch 3/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9030\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1057 - acc: 0.9031 - val_loss: 0.3173 - val_acc: 0.8549\n",
            "Epoch 4/5\n",
            "889/890 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9168\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0801 - acc: 0.9168 - val_loss: 0.4033 - val_acc: 0.8255\n",
            "Epoch 5/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9262\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0708 - acc: 0.9262 - val_loss: 0.4770 - val_acc: 0.8305\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0623 - acc: 0.9323\n",
            "acc: 93.23%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8020741115467307\n",
            "Roc-auc score is 0.6139263416665174\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.10      0.11       565\n",
            "           1       0.90      0.97      0.93      7108\n",
            "           2       0.20      0.03      0.06       549\n",
            "           3       0.16      0.02      0.04       498\n",
            "           4       0.15      0.01      0.02       393\n",
            "           5       0.07      0.01      0.01       397\n",
            "\n",
            "   micro avg       0.83      0.73      0.78      9510\n",
            "   macro avg       0.27      0.19      0.19      9510\n",
            "weighted avg       0.71      0.73      0.71      9510\n",
            " samples avg       0.85      0.86      0.85      9510\n",
            "\n",
            "Confusion matrix [[[6883  459]\n",
            "  [ 508   57]]\n",
            "\n",
            " [[  53  746]\n",
            "  [ 214 6894]]\n",
            "\n",
            " [[7285   73]\n",
            "  [ 531   18]]\n",
            "\n",
            " [[7357   52]\n",
            "  [ 488   10]]\n",
            "\n",
            " [[7486   28]\n",
            "  [ 388    5]]\n",
            "\n",
            " [[7473   37]\n",
            "  [ 394    3]]]\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 300, 300)          6000000   \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 90000)             0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 32)                2880032   \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,925,030\n",
            "Trainable params: 8,925,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "884/890 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.8803\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to model.hdf5\n",
            "890/890 [==============================] - 8s 8ms/step - loss: 0.2406 - acc: 0.8804 - val_loss: 0.2312 - val_acc: 0.8751\n",
            "Epoch 2/5\n",
            "885/890 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1763 - acc: 0.8827 - val_loss: 0.2744 - val_acc: 0.8678\n",
            "Epoch 3/5\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1025 - acc: 0.9038\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.1025 - acc: 0.9038 - val_loss: 0.3671 - val_acc: 0.8622\n",
            "Epoch 4/5\n",
            "888/890 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9181\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0778 - acc: 0.9180 - val_loss: 0.4171 - val_acc: 0.8337\n",
            "Epoch 5/5\n",
            "886/890 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9273\n",
            "Epoch 5: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 7s 8ms/step - loss: 0.0672 - acc: 0.9273 - val_loss: 0.4265 - val_acc: 0.8141\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.4267 - acc: 0.8140\n",
            "acc: 81.40%\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Accuracy is 0.8010623498166182\n",
            "Roc-auc score is 0.625649020960439\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.04      0.07       565\n",
            "           1       0.91      0.93      0.92      7108\n",
            "           2       0.20      0.09      0.13       549\n",
            "           3       0.16      0.05      0.07       498\n",
            "           4       0.14      0.03      0.04       393\n",
            "           5       0.06      0.01      0.02       397\n",
            "\n",
            "   micro avg       0.84      0.71      0.77      9510\n",
            "   macro avg       0.27      0.19      0.21      9510\n",
            "weighted avg       0.71      0.71      0.70      9510\n",
            " samples avg       0.84      0.83      0.83      9510\n",
            "\n",
            "Confusion matrix [[[7195  147]\n",
            "  [ 541   24]]\n",
            "\n",
            " [[ 129  670]\n",
            "  [ 504 6604]]\n",
            "\n",
            " [[7154  204]\n",
            "  [ 498   51]]\n",
            "\n",
            " [[7284  125]\n",
            "  [ 475   23]]\n",
            "\n",
            " [[7450   64]\n",
            "  [ 383   10]]\n",
            "\n",
            " [[7438   72]\n",
            "  [ 392    5]]]\n",
            "91.96% (+/- 3.56%)\n",
            "Test accuracy is: {} 0.82 (+/- 0.01)\n",
            "Test roc-auc is: {} 0.62 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}