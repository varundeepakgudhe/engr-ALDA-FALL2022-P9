{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MmfhxkfM9S6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/unhealthy_full.csv\")\n",
        "\n",
        "data_csv = pd.read_csv(url_data)"
      ],
      "metadata": {
        "id": "NT6AepL6BX9Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "LeCtp8vgBYAK",
        "outputId": "a77140c5-a4a3-4a12-e4e7-f0da2c86a4b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46000575-774b-4af0-ad21-78b03cc3c177\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46000575-774b-4af0-ad21-78b03cc3c177')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46000575-774b-4af0-ad21-78b03cc3c177 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46000575-774b-4af0-ad21-78b03cc3c177');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7mQ2QVRBYCV",
        "outputId": "44ee764a-2ea3-457b-a31a-69b57e008007"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227975, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAPMmCI4aH1U",
        "outputId": "ba7a3b32-46cd-4f53-b9f7-0bc3f5ea82d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NnokaXvasZa",
        "outputId": "25ad2b96-7454-4f79-b1e0-a4f80455a9e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MUQZC1YYaHtm",
        "outputId": "1a3fe705-98cd-4911-b5e5-04d6a7528d58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        _unit_id  comment  _trust  _worker_id  antagonize  condescending  \\\n",
              "0          False    False   False       False       False          False   \n",
              "1          False    False   False       False       False          False   \n",
              "2          False    False   False       False       False          False   \n",
              "3          False    False   False       False       False          False   \n",
              "4          False    False   False       False       False          False   \n",
              "...          ...      ...     ...         ...         ...            ...   \n",
              "227970     False    False   False       False       False          False   \n",
              "227971     False    False   False       False       False          False   \n",
              "227972     False    False   False       False       False          False   \n",
              "227973     False    False   False       False       False          False   \n",
              "227974     False    False   False       False       False          False   \n",
              "\n",
              "        dismissive  generalisation  generalisation_unfair  healthy  hostile  \\\n",
              "0            False           False                  False    False    False   \n",
              "1            False           False                  False    False    False   \n",
              "2            False           False                  False    False    False   \n",
              "3            False           False                  False    False    False   \n",
              "4            False           False                  False    False    False   \n",
              "...            ...             ...                    ...      ...      ...   \n",
              "227970       False           False                  False    False    False   \n",
              "227971       False           False                  False    False    False   \n",
              "227972       False           False                  False    False    False   \n",
              "227973       False           False                  False    False    False   \n",
              "227974       False           False                  False    False    False   \n",
              "\n",
              "        sarcastic  \n",
              "0           False  \n",
              "1           False  \n",
              "2           False  \n",
              "3           False  \n",
              "4           False  \n",
              "...           ...  \n",
              "227970      False  \n",
              "227971      False  \n",
              "227972      False  \n",
              "227973      False  \n",
              "227974      False  \n",
              "\n",
              "[227975 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69c53442-c470-47ca-97cf-b43340202f67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227970</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227971</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227972</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227973</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227974</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>227975 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69c53442-c470-47ca-97cf-b43340202f67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69c53442-c470-47ca-97cf-b43340202f67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69c53442-c470-47ca-97cf-b43340202f67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jBui5D9aHhJ",
        "outputId": "470e19cf-b024-4799-ebba-db606c70c14d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_unit_id                 False\n",
              "comment                   True\n",
              "_trust                   False\n",
              "_worker_id               False\n",
              "antagonize               False\n",
              "condescending            False\n",
              "dismissive               False\n",
              "generalisation           False\n",
              "generalisation_unfair    False\n",
              "healthy                  False\n",
              "hostile                  False\n",
              "sarcastic                False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop=data_csv.drop_duplicates(subset=\"comment\")"
      ],
      "metadata": {
        "id": "AyWmGYEaJN3J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv[\"comment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyUo0Kw5p-L",
        "outputId": "5261b03e-6030-40f8-fccf-16e3261259ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Moon, Do you *really* need it spelled out to you?\n",
              "1         It means you can ask the values questions, but...\n",
              "2                                           To you perhaps.\n",
              "3         I don't want to put words in your mouth, but a...\n",
              "4         perhaps this is not a problem seeing as how ev...\n",
              "                                ...                        \n",
              "227970    In 2001 the price of oil was around $25 a barr...\n",
              "227971    How about answering the question asked rather ...\n",
              "227972    Re: 'he is not a war mugger' [sic]You seem to ...\n",
              "227973    At last someone trotting out facts instead of ...\n",
              "227974    why should I care what the catholic dinosaurs ...\n",
              "Name: comment, Length: 227975, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oSWbI9oLt4Z",
        "outputId": "a2e16f1b-c8d9-49a8-cd83-cc13258987e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44355, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull= data_csv_drop.dropna()\n",
        "data_del_ind= data_cnull[(data_cnull[\"sarcastic\"]==0) & (data_cnull[\"healthy\"]==0) & (data_cnull[\"antagonize\"]==0) & (data_cnull[\"condescending\"]==0) & (data_cnull[\"dismissive\"]==0) & (data_cnull[\"hostile\"]==0)].index\n",
        "data_pnull = data_cnull.drop(data_del_ind)\n",
        "data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n",
        "data_wnull = data_pnull.drop(data_wnull_ind)\n",
        "data_wnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlg427rbxEDi",
        "outputId": "c24a5dbd-91b8-47b6-ab1f-b5f0c4b7247e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9f9d33e04fea>:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39533, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_test= train_test_split(data_wnull, test_size=0.5, random_state=42)\n",
        "print(data_train.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnst4mR9w3uM",
        "outputId": "98c6d63a-8fae-4259-ba42-4c30c0c22f80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19766, 12) (19767, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgEKZzkNVe-",
        "outputId": "8f8bc943-b900-4d8f-b19d-275a975ac006"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "embed_size = 200\n",
        "max_features = 20000 \n",
        "maxlen = 200 \n",
        "\n",
        "print('Loading data...')\n",
        "\n",
        "classes = [\"sarcastic\", \"healthy\", \"antagonize\", \"condescending\", \"dismissive\", \"hostile\"]\n",
        "y = data_train[classes].values\n",
        "y_test = data_test[classes].values\n",
        "\n",
        "train_sentences = data_train[\"comment\"]\n",
        "test_sentences = data_test[\"comment\"]\n",
        "\n",
        "print('Preprocessing train') \n",
        "train = list()\n",
        "for i in train_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    train.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "print('Preprocessing test')\n",
        "test = list()\n",
        "for i in test_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    test.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-TA7_2mZX0g",
        "outputId": "7db0a2d4-7c85-48bd-847e-c522cf023666"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing train\n",
            "Preprocessing test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['there',\n",
              "  'pragmatic',\n",
              "  'conservative',\n",
              "  'voice',\n",
              "  'either',\n",
              "  'side',\n",
              "  'border',\n",
              "  '40',\n",
              "  'years'],\n",
              " ['canada', 'first', 'make', 'canada', 'better', 'making', 'else'],\n",
              " ['just',\n",
              "  'keep',\n",
              "  'blaming',\n",
              "  'others',\n",
              "  'fact',\n",
              "  'cpc',\n",
              "  'forward',\n",
              "  'looking',\n",
              "  'backward',\n",
              "  'looking',\n",
              "  'the',\n",
              "  'strategy',\n",
              "  'really',\n",
              "  'working',\n",
              "  'ontario',\n",
              "  'pcs',\n",
              "  'reduced',\n",
              "  'nothing',\n",
              "  'rural',\n",
              "  'rump',\n",
              "  'party',\n",
              "  'grumpy',\n",
              "  'old',\n",
              "  'people'],\n",
              " ['oh',\n",
              "  'conservatives',\n",
              "  'literally',\n",
              "  'knots',\n",
              "  'people',\n",
              "  'canada',\n",
              "  'spoken',\n",
              "  'swept',\n",
              "  'power',\n",
              "  'federally',\n",
              "  'ab',\n",
              "  'heartland',\n",
              "  'that',\n",
              "  'populism',\n",
              "  'action'],\n",
              " ['again',\n",
              "  'jack',\n",
              "  'embarrassing',\n",
              "  'commentary',\n",
              "  'you',\n",
              "  'bring',\n",
              "  'nothing',\n",
              "  'conversation',\n",
              "  'value',\n",
              "  'please',\n",
              "  'either',\n",
              "  'game',\n",
              "  'stay',\n",
              "  'home']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqtCIizkYQ25",
        "outputId": "e10b3174-8409-47de-da8d-52cbaf0edcce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, BatchNormalization, SpatialDropout1D, GlobalAveragePooling1D, concatenate, Activation, LSTM, Bidirectional\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import tensorflow\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, multilabel_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "EMBEDDING_FILE = f'/content/drive/MyDrive/glove.twitter.27B.200d.txt'  # or glove.840B.300d.txt or fasttext_wiki.vec\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "tokenized_train_sentences = tokenizer.texts_to_sequences(train)\n",
        "tokenized_test_sentences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_train_sentences, maxlen)\n",
        "test_padding = pad_sequences(tokenized_test_sentences, maxlen)\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "# cross validation        \n",
        "kfold = KFold(n_splits=3)\n",
        "cvscores = []\n",
        "accscores = []\n",
        "rocscores = []\n",
        "\n",
        "for train, test in kfold.split(train_padding, y):\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1)(x)\n",
        "    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(6, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "\n",
        "    saved_model = \"model_glovePP.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(train_padding, y, batch_size=32, epochs=5, callbacks=[checkpoint], validation_split=0.1)\n",
        "\n",
        "    scores = model.evaluate(train_padding[test], y[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    print(\"Loading model....\")\n",
        "    model = load_model('model_glovePP.hdf5')\n",
        "    y_pred = model.predict(test_padding)\n",
        "\n",
        "    y_int = np.zeros_like(y_pred)\n",
        "    y_int[y_pred > 0.5] = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_int)\n",
        "    print('Accuracy is {}'.format(accuracy))\n",
        "    accscores.append(accuracy)\n",
        "    \n",
        "    rocauc = roc_auc_score(y_test, y_pred)\n",
        "    print('Roc-auc score is {}'.format(rocauc))\n",
        "    rocscores.append(rocauc)\n",
        "    \n",
        "    print('Classification report {}'.format(classification_report(y_test, y_int, zero_division=0)))\n",
        "    print('Confusion matrix {}'.format(multilabel_confusion_matrix(y_test, y_int)))\n",
        "        \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"Test accuracy is: {} %.2f (+/- %.2f)\" %  (np.mean(accscores), np.std(accscores)))\n",
        "print(\"Test roc-auc is: {} %.2f (+/- %.2f)\" % (np.mean(rocscores), np.std(rocscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7GdRC8zTY8i",
        "outputId": "1fbe0152-9e51-4da5-db2f-565a41023d53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 200, 200)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 200, 200)    0           ['embedding[0][0]']              \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 200, 128)     168448      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 198, 64)      24640       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 , 'global_max_pooling1d[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6)            390         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,201,734\n",
            "Trainable params: 4,201,734\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2448 - acc: 0.8811\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to model_glovePP.hdf5\n",
            "556/556 [==============================] - 489s 872ms/step - loss: 0.2448 - acc: 0.8811 - val_loss: 0.2415 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2157 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 477s 859ms/step - loss: 0.2157 - acc: 0.8826 - val_loss: 0.2383 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1819 - acc: 0.8813\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 478s 860ms/step - loss: 0.1819 - acc: 0.8813 - val_loss: 0.2832 - val_acc: 0.8609\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1481 - acc: 0.8853\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 466s 839ms/step - loss: 0.1481 - acc: 0.8853 - val_loss: 0.3028 - val_acc: 0.8629\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1212 - acc: 0.8939\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 465s 837ms/step - loss: 0.1212 - acc: 0.8939 - val_loss: 0.3989 - val_acc: 0.8594\n",
            "206/206 [==============================] - 23s 113ms/step - loss: 0.0806 - acc: 0.9136\n",
            "acc: 91.36%\n",
            "Loading model....\n",
            "618/618 [==============================] - 64s 103ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.6596434445648269\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 200, 200)     4000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_1 (SpatialDr  (None, 200, 200)    0           ['embedding_1[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 200, 128)     168448      ['spatial_dropout1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 198, 64)      24640       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,201,734\n",
            "Trainable params: 4,201,734\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2452 - acc: 0.8790\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to model_glovePP.hdf5\n",
            "556/556 [==============================] - 484s 862ms/step - loss: 0.2452 - acc: 0.8790 - val_loss: 0.2368 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2164 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 482s 867ms/step - loss: 0.2164 - acc: 0.8826 - val_loss: 0.2407 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1845 - acc: 0.8816\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 482s 868ms/step - loss: 0.1845 - acc: 0.8816 - val_loss: 0.2549 - val_acc: 0.8690\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1491 - acc: 0.8835\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 475s 855ms/step - loss: 0.1491 - acc: 0.8835 - val_loss: 0.3151 - val_acc: 0.8493\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.8930\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 473s 850ms/step - loss: 0.1224 - acc: 0.8930 - val_loss: 0.3678 - val_acc: 0.8392\n",
            "206/206 [==============================] - 21s 103ms/step - loss: 0.0977 - acc: 0.9018\n",
            "acc: 90.18%\n",
            "Loading model....\n",
            "618/618 [==============================] - 66s 106ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.6661008684926948\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 200, 200)     4000000     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_2 (SpatialDr  (None, 200, 200)    0           ['embedding_2[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 200, 128)     168448      ['spatial_dropout1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 198, 64)      24640       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 6)            390         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,201,734\n",
            "Trainable params: 4,201,734\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2452 - acc: 0.8816\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to model_glovePP.hdf5\n",
            "556/556 [==============================] - 487s 869ms/step - loss: 0.2452 - acc: 0.8816 - val_loss: 0.2366 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2168 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 480s 862ms/step - loss: 0.2168 - acc: 0.8826 - val_loss: 0.2345 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1838 - acc: 0.8817\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 480s 863ms/step - loss: 0.1838 - acc: 0.8817 - val_loss: 0.2700 - val_acc: 0.8690\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1486 - acc: 0.8854\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 482s 866ms/step - loss: 0.1486 - acc: 0.8854 - val_loss: 0.3393 - val_acc: 0.8442\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.8945\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 488s 877ms/step - loss: 0.1221 - acc: 0.8945 - val_loss: 0.3737 - val_acc: 0.8488\n",
            "206/206 [==============================] - 23s 112ms/step - loss: 0.1805 - acc: 0.8892\n",
            "acc: 88.92%\n",
            "Loading model....\n",
            "618/618 [==============================] - 68s 110ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.6563883827365119\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "90.15% (+/- 1.00%)\n",
            "Test accuracy is: {} 0.88 (+/- 0.00)\n",
            "Test roc-auc is: {} 0.66 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}