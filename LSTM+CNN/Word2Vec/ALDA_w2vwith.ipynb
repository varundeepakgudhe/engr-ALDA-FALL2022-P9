{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MmfhxkfM9S6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/unhealthy_full.csv\")\n",
        "\n",
        "data_csv = pd.read_csv(url_data)"
      ],
      "metadata": {
        "id": "NT6AepL6BX9Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "LeCtp8vgBYAK",
        "outputId": "f59b51c6-9bba-4e85-f878-0feb938dca68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edc7baae-6316-4f8d-bdfc-a4fdf692cdd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edc7baae-6316-4f8d-bdfc-a4fdf692cdd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edc7baae-6316-4f8d-bdfc-a4fdf692cdd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edc7baae-6316-4f8d-bdfc-a4fdf692cdd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7mQ2QVRBYCV",
        "outputId": "737b9fc4-7102-4b92-86db-d251ea34b8ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227975, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAPMmCI4aH1U",
        "outputId": "875adef2-4598-47f9-c7ad-e170f20b3bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NnokaXvasZa",
        "outputId": "a5fb83e2-38b8-45da-c4b9-c086eb0f006f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MUQZC1YYaHtm",
        "outputId": "cc488aa3-0391-41fe-c0d2-1478fee44be8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        _unit_id  comment  _trust  _worker_id  antagonize  condescending  \\\n",
              "0          False    False   False       False       False          False   \n",
              "1          False    False   False       False       False          False   \n",
              "2          False    False   False       False       False          False   \n",
              "3          False    False   False       False       False          False   \n",
              "4          False    False   False       False       False          False   \n",
              "...          ...      ...     ...         ...         ...            ...   \n",
              "227970     False    False   False       False       False          False   \n",
              "227971     False    False   False       False       False          False   \n",
              "227972     False    False   False       False       False          False   \n",
              "227973     False    False   False       False       False          False   \n",
              "227974     False    False   False       False       False          False   \n",
              "\n",
              "        dismissive  generalisation  generalisation_unfair  healthy  hostile  \\\n",
              "0            False           False                  False    False    False   \n",
              "1            False           False                  False    False    False   \n",
              "2            False           False                  False    False    False   \n",
              "3            False           False                  False    False    False   \n",
              "4            False           False                  False    False    False   \n",
              "...            ...             ...                    ...      ...      ...   \n",
              "227970       False           False                  False    False    False   \n",
              "227971       False           False                  False    False    False   \n",
              "227972       False           False                  False    False    False   \n",
              "227973       False           False                  False    False    False   \n",
              "227974       False           False                  False    False    False   \n",
              "\n",
              "        sarcastic  \n",
              "0           False  \n",
              "1           False  \n",
              "2           False  \n",
              "3           False  \n",
              "4           False  \n",
              "...           ...  \n",
              "227970      False  \n",
              "227971      False  \n",
              "227972      False  \n",
              "227973      False  \n",
              "227974      False  \n",
              "\n",
              "[227975 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f910333b-6605-4133-bc2d-ef8188c245b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227970</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227971</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227972</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227973</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227974</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>227975 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f910333b-6605-4133-bc2d-ef8188c245b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f910333b-6605-4133-bc2d-ef8188c245b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f910333b-6605-4133-bc2d-ef8188c245b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jBui5D9aHhJ",
        "outputId": "8c14ed84-bd4b-4e97-e149-3d5987bf2670"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_unit_id                 False\n",
              "comment                   True\n",
              "_trust                   False\n",
              "_worker_id               False\n",
              "antagonize               False\n",
              "condescending            False\n",
              "dismissive               False\n",
              "generalisation           False\n",
              "generalisation_unfair    False\n",
              "healthy                  False\n",
              "hostile                  False\n",
              "sarcastic                False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop=data_csv.drop_duplicates(subset=\"comment\")"
      ],
      "metadata": {
        "id": "AyWmGYEaJN3J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv[\"comment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyUo0Kw5p-L",
        "outputId": "247beeb5-bf35-4e07-f698-80f27a4a67ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Moon, Do you *really* need it spelled out to you?\n",
              "1         It means you can ask the values questions, but...\n",
              "2                                           To you perhaps.\n",
              "3         I don't want to put words in your mouth, but a...\n",
              "4         perhaps this is not a problem seeing as how ev...\n",
              "                                ...                        \n",
              "227970    In 2001 the price of oil was around $25 a barr...\n",
              "227971    How about answering the question asked rather ...\n",
              "227972    Re: 'he is not a war mugger' [sic]You seem to ...\n",
              "227973    At last someone trotting out facts instead of ...\n",
              "227974    why should I care what the catholic dinosaurs ...\n",
              "Name: comment, Length: 227975, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oSWbI9oLt4Z",
        "outputId": "8af57863-e611-4b84-e9bd-b0395ebe7c8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44355, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_wnull= data_csv_drop.dropna()\n",
        "data_wnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlg427rbxEDi",
        "outputId": "a621b634-7e02-4481-b03a-e73c84b593e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44354, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_test= train_test_split(data_wnull, test_size=0.5, random_state=42)\n",
        "print(data_train.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnst4mR9w3uM",
        "outputId": "3d3087c9-b4ba-498e-cb4f-5447aa74b287"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22177, 12) (22177, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgEKZzkNVe-",
        "outputId": "964ba146-fc1a-4148-e3df-78da5c42c308"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tables.file import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "d=defaultdict(int)"
      ],
      "metadata": {
        "id": "AWfl7ZO105a_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer=TweetTokenizer()\n",
        "for i in data_csv_drop[\"comment\"]:\n",
        "    i=tokenizer.tokenize(str(i))\n",
        "    for j in i:\n",
        "      if j in stop_words:\n",
        "        d[j]+=1\n",
        "print(d)        \n",
        "wordcount=sorted(d.items(),key=lambda x:x[1],reverse=True)[:15]    \n",
        "x,y=zip(*wordcount)\n",
        "plt.bar(x,y)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "GT_UYOk405SB",
        "outputId": "8c37563d-36ae-4fd6-f0f4-d035996efdf9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'you': 11469, 'it': 7588, 'out': 1986, 'to': 21816, 'can': 2165, 'the': 38320, 'but': 2831, 'be': 5921, 'what': 2942, 'do': 3075, 'we': 2670, 'while': 380, 'is': 15506, 'a': 17754, 'of': 17354, \"don't\": 2233, 'in': 11457, 'your': 3945, 'are': 7470, 'this': 4386, 'not': 6374, 'as': 3924, 'how': 1498, 'up': 1985, 'have': 5624, 'an': 2543, 'who': 2640, 'he': 2582, 'his': 2086, 'these': 734, 'with': 4980, 'and': 15852, 'were': 1173, 'at': 2463, 'when': 1558, 'they': 3797, 'themselves': 280, 'their': 2453, 'if': 2112, 'some': 1158, 'against': 474, 'from': 2847, 'being': 1014, 'on': 5444, 'has': 2995, 'no': 2284, 'that': 10496, \"wasn't\": 176, 'about': 3123, 'for': 8233, 'was': 3495, \"you've\": 133, 'there': 1713, 'under': 396, 'most': 846, \"doesn't\": 757, 'does': 1081, 'more': 2336, 'whom': 64, 'will': 3222, 'such': 529, 'or': 2851, 'himself': 150, 'both': 370, 'same': 934, \"you're\": 597, 'again': 513, 'after': 513, 'so': 2370, 'should': 2042, 'me': 1156, 'now': 1056, 'until': 253, \"hasn't\": 84, 'then': 1104, 'him': 878, 'won': 123, 'just': 2443, 'our': 1326, 'its': 766, 'am': 512, 'doing': 421, \"haven't\": 142, 'had': 963, 'those': 993, 'before': 593, 'which': 746, 'down': 712, 'here': 826, 'by': 2622, 'them': 1641, 'been': 1456, 'why': 1073, 'where': 692, 'because': 1121, 'each': 169, \"didn't\": 610, 'over': 981, 'too': 1065, \"wouldn't\": 228, 'own': 678, 'once': 201, 'her': 908, 'few': 349, 'very': 989, \"you'd\": 81, 'other': 1155, 'all': 3085, \"you'll\": 83, \"it's\": 1049, 'only': 1379, 'into': 754, 'having': 272, 'off': 578, 's': 353, 'wouldn': 6, 't': 115, 'my': 1298, 'above': 119, 'than': 1691, 'any': 1332, \"weren't\": 55, \"aren't\": 263, 'myself': 61, 'aren': 1, 'below': 49, 'between': 261, \"isn't\": 492, 'she': 766, 'd': 16, 'yours': 87, 'further': 86, 'm': 26, \"that'll\": 4, 'did': 1121, 'yourself': 305, \"she's\": 87, \"won't\": 344, 'during': 194, \"couldn't\": 117, 'through': 297, 're': 62, 'ourselves': 40, 'i': 253, 'herself': 28, \"shouldn't\": 108, 'don': 28, 'o': 17, 'itself': 120, 'nor': 85, 've': 12, 'yourselves': 15, 'ours': 13, \"hadn't\": 31, 'haven': 6, 'isn': 7, 'shouldn': 2, \"should've\": 5, 'wasn': 4, 'didn': 5, 'll': 15, 'hasn': 1, 'doesn': 6, 'y': 4, 'theirs': 19, 'hers': 2, \"needn't\": 3, 'couldn': 1, 'needn': 1, \"mustn't\": 1, \"shan't\": 1})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 15 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import seaborn as sns\n",
        "counter=collections.Counter(d)\n",
        "most=counter.most_common()\n",
        "x=[]\n",
        "y=[]\n",
        "for word,count in most[:30]:\n",
        "  if (word in stop_words):\n",
        "    x.append(word)\n",
        "    y.append(count)\n",
        "sns.barplot(x=y,y=x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "U-DwUl5605F5",
        "outputId": "e13eb6d5-9bd1-42b9-e1ee-d787bd8cc466"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8f780d2700>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "embed_size = 300\n",
        "max_features = 20000 \n",
        "maxlen = 200 \n",
        "\n",
        "print('Loading data...')\n",
        "\n",
        "classes = [\"sarcastic\", \"healthy\", \"antagonize\", \"condescending\", \"dismissive\", \"hostile\"]\n",
        "y = data_train[classes].values\n",
        "y_test = data_test[classes].values\n",
        "\n",
        "train_sentences = data_train[\"comment\"]\n",
        "test_sentences = data_test[\"comment\"]\n",
        "\n",
        "print('Preprocessing train') \n",
        "train = list()\n",
        "for i in train_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    train.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "print('Preprocessing test')\n",
        "test = list()\n",
        "for i in test_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    test.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-TA7_2mZX0g",
        "outputId": "d7d0f25c-7d96-4370-a8d1-752aa45601b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing train\n",
            "Preprocessing test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'ericka', 'ignore', 'she', 'total', 'waste', 'electrons'],\n",
              " ['not', 'cake', 'pizza', 'get', 'right'],\n",
              " ['they', 'get', 'bed', 'noon'],\n",
              " ['stand',\n",
              "  'firm',\n",
              "  'prime',\n",
              "  'minister',\n",
              "  'harper',\n",
              "  'give',\n",
              "  'welfare',\n",
              "  'blackmail',\n",
              "  'throwing',\n",
              "  'money',\n",
              "  'worked',\n",
              "  'past',\n",
              "  'support',\n",
              "  'corruption'],\n",
              " ['the',\n",
              "  'ndp',\n",
              "  'going',\n",
              "  'win',\n",
              "  'i',\n",
              "  'hope',\n",
              "  'put',\n",
              "  'house',\n",
              "  'market',\n",
              "  'may',\n",
              "  '15th',\n",
              "  'bye',\n",
              "  'bye',\n",
              "  '4',\n",
              "  'years',\n",
              "  'least',\n",
              "  'perhaps',\n",
              "  'longer']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. create custom embeddings \n",
        "words = list()\n",
        "for i in train_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(i) # word tokenizacia\n",
        "    words.append(tokens) # pridá výsledné slová do prázdneho listu, ktorý sme na začiatku vytvorili\n",
        "print('Word2Vec...')\n",
        "print(words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGJulBTXbIKQ",
        "outputId": "8773ed4f-4a73-433d-bada-e76aa73a2c4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec...\n",
            "[['I', 'have', 'Ericka', 'on', 'ignore', 'She', 'is', 'a', 'total', 'waste', 'of', 'electrons'], ['Not', 'cake', 'Pizza', 'Get', 'it', 'right'], ['They', 'don', 't', 'get', 'out', 'of', 'bed', 'before', 'noon'], ['Stand', 'firm', 'Prime', 'Minister', 'Harper', 'don', 't', 'give', 'in', 'to', 'this', 'welfare', 'blackmail', 'throwing', 'money', 'at', 'this', 'has', 'not', 'worked', 'in', 'the', 'past', 'only', 'support', 'the', 'corruption', 'there'], ['The', 'NDP', 'is', 'going', 'to', 'win', 'so', 'I', 'hope', 'you', 'put', 'your', 'house', 'on', 'the', 'market', 'on', 'May', '15th', 'bye', 'bye', 'for', '4', 'years', 'at', 'least', 'and', 'perhaps', 'longer'], ['It', 'must', 'really', 'make', 'you', 'Cons', 'proud', 'when', 'after', 'being', 'unable', 'for', 'decades', 'to', 'grasp', 'the', 'concept', 'of', 'multiculturalism', 'you', 'stumble', 'across', 'the', 'crassest', 'possible', 'version', 'of', 'it', 'and', 'run', 'with', 'it', 'to', 'extremes'], ['You', 'get', 'to', 'vote', 'somewhere', 'they', 'should', 'get', 'to', 'vote', 'somewhere', 'too'], ['I', 'suspect', 'they', 'will', 'endorse', 'Trudeau', 'this', 'time', 'Just', 'a', 'gut', 'feel'], ['You', 'endorsed', 'Frod', 'too', 'as', 'I', 'recall'], ['Eliminate', 'the', 'Partys', 'and', 'force', 'PMs', 'to', 'serve', 'their', 'constituents', 'The', 'problem', 'IS', 'the', 'Party', 'system']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding\n",
        "\n",
        "model = Word2Vec(words, min_count = 1, size = 300) #word to vector, implementacia z kniznice gensim\n",
        "vocabulary = model.wv.vocab #slovnik\n",
        "name = 'w2vPP.txt'\n",
        "model.wv.save_word2vec_format(name, binary = False)\n",
        "\n",
        "EMBEDDING_FILE = 'w2vPP.txt' "
      ],
      "metadata": {
        "id": "IB9D24gEZXxB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, BatchNormalization, SpatialDropout1D, GlobalAveragePooling1D, concatenate, Activation, LSTM, Bidirectional\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, multilabel_confusion_matrix"
      ],
      "metadata": {
        "id": "wnOXA-OGZwmE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "tokenized_train_sentences = tokenizer.texts_to_sequences(train)\n",
        "tokenized_test_sentences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_train_sentences, maxlen)\n",
        "test_padding = pad_sequences(tokenized_test_sentences, maxlen)\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "\n",
        "print(list(embeddings_index.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeNcSo9UZwih",
        "outputId": "bf26a0af-ad75-4787-e72e-9814938d5bdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('30081', array([300.], dtype=float32)), ('the', array([-3.78899992e-01, -7.17111230e-01,  3.31623793e-01, -1.10525377e-01,\n",
            "        3.22022229e-01,  1.28863752e-01,  1.83253348e-01, -2.15110809e-01,\n",
            "       -7.68772602e-01,  5.33646755e-02, -7.01583445e-01, -5.74193835e-01,\n",
            "        4.69925791e-01,  1.81132972e-01, -4.11200300e-02, -6.14199042e-01,\n",
            "       -7.80025423e-02, -5.18885255e-01,  1.47460982e-01,  1.46978013e-02,\n",
            "       -3.10844928e-01,  1.10163224e+00,  9.80180427e-02, -2.15881288e-01,\n",
            "        2.60331094e-01,  5.11384249e-01,  3.86951536e-01, -9.67196226e-02,\n",
            "        1.81377098e-01, -8.63700867e-01, -3.20828557e-01,  5.58661580e-01,\n",
            "       -7.89983347e-02,  3.72787595e-01,  2.44745716e-01, -9.04668197e-02,\n",
            "       -3.27450246e-01, -2.86091566e-01, -5.64209186e-03,  3.29528362e-01,\n",
            "       -6.48283541e-01, -3.51192355e-02,  1.80912137e-01, -2.15328544e-01,\n",
            "        2.10701525e-01, -3.13358158e-01,  1.13755953e+00,  1.68508485e-01,\n",
            "       -2.49814522e-03,  3.80691379e-01,  2.22832933e-01, -2.95292377e-01,\n",
            "        2.20271781e-01, -6.91785812e-01, -7.12363720e-01, -3.27803157e-02,\n",
            "       -1.79708242e-01,  4.46733385e-01,  4.02872384e-01,  5.88550642e-02,\n",
            "       -4.41130877e-01,  2.01852396e-01,  2.67296582e-01,  2.27831885e-01,\n",
            "        1.91165730e-01, -1.03044964e-01, -8.56592506e-02, -1.81610852e-01,\n",
            "       -2.49230504e-01, -6.69854164e-01,  2.91950464e-01, -5.66932499e-01,\n",
            "        1.70129001e-01, -8.86033177e-02,  2.41675582e-02,  4.19421881e-01,\n",
            "       -5.05655825e-01,  7.46352002e-02,  7.89684176e-01, -3.17373693e-01,\n",
            "        5.73959529e-01, -4.84990358e-01, -4.83350545e-01, -6.90970048e-02,\n",
            "       -4.63732541e-01,  6.31878436e-01,  5.34935474e-01,  7.59339511e-01,\n",
            "        1.56934753e-01, -5.22624373e-01,  2.20771646e-03,  5.11556923e-01,\n",
            "       -3.99055742e-02, -3.57376784e-01,  8.43873084e-01,  4.31404412e-01,\n",
            "       -1.73461616e-01,  1.11528700e-02, -3.30296725e-01,  4.83881645e-02,\n",
            "        1.31252157e-02,  3.75789672e-01, -2.38046780e-01,  8.96592289e-02,\n",
            "        2.42528975e-01, -4.49827224e-01, -5.07734656e-01, -5.95944747e-02,\n",
            "       -7.78422207e-02,  1.03945769e-01,  3.09645869e-02,  1.36196017e-01,\n",
            "        4.74864930e-01, -2.91852087e-01,  1.26232505e-01, -1.19549954e+00,\n",
            "       -1.80047214e-01, -1.27046615e-01, -6.47470176e-01, -3.98242742e-01,\n",
            "       -3.84058744e-01,  3.23233157e-01, -7.36114919e-01, -6.28365993e-01,\n",
            "       -5.96306741e-01, -3.99107903e-01,  1.03403023e-02,  2.47693270e-01,\n",
            "       -1.82526737e-01, -2.56840378e-01,  4.52086449e-01,  4.51028526e-01,\n",
            "       -4.48620975e-01, -1.29532009e-01, -3.35051984e-01,  5.15021324e-01,\n",
            "        1.55884817e-01,  1.15642445e-02,  5.08088887e-01, -5.34420729e-01,\n",
            "       -2.23027110e-01,  1.01321980e-01,  1.73039101e-02, -6.46992385e-01,\n",
            "        3.09183020e-02,  5.39599992e-02,  1.90999433e-01, -2.73029625e-01,\n",
            "       -4.16123092e-01,  4.41790789e-01, -4.22861218e-01,  1.15704119e+00,\n",
            "       -4.02201593e-01,  3.14318568e-01, -7.75518268e-02,  1.48936570e-01,\n",
            "        3.52534026e-01, -5.72387800e-02,  5.35232008e-01, -2.90203959e-01,\n",
            "        7.30108917e-02,  4.00144249e-01, -6.25429034e-01, -2.17211127e-01,\n",
            "        7.64706850e-01, -1.53893501e-01, -1.52030230e-01, -4.23465401e-01,\n",
            "       -3.22028100e-01,  8.09393451e-02,  4.85993028e-02,  1.76735893e-01,\n",
            "        4.52405602e-01, -7.23126590e-01,  2.63664067e-01, -2.67817080e-01,\n",
            "        5.28971493e-01,  4.31182355e-01, -2.59816587e-01,  2.22746119e-01,\n",
            "        6.26999676e-01,  3.58020037e-01,  1.09312856e+00,  5.14303684e-01,\n",
            "       -2.75973737e-01, -2.48568058e-01,  7.78027177e-02,  8.95373046e-01,\n",
            "        1.32104725e-01, -8.53045464e-01,  4.49851424e-01,  4.55847800e-01,\n",
            "       -4.43526693e-02, -8.59595180e-01,  2.59473354e-01, -5.37797153e-01,\n",
            "       -5.20239174e-01,  7.22342551e-01, -6.40910640e-02, -1.78975761e-01,\n",
            "       -1.51669845e-01,  2.61688977e-01,  2.94477314e-01, -5.14254384e-02,\n",
            "        6.12807930e-01,  1.09832160e-01,  1.06419995e-01, -1.10362716e-01,\n",
            "        6.61774166e-03, -3.58962983e-01, -2.70160198e-01,  2.70574719e-01,\n",
            "        7.69897580e-01,  1.83246598e-01, -3.12433004e-01,  1.96812543e-04,\n",
            "        4.88401741e-01, -6.20583057e-01,  5.04071116e-01, -2.39108384e-01,\n",
            "       -3.82418036e-01, -1.04993093e+00,  4.65633035e-01,  7.82891631e-01,\n",
            "        4.95400310e-01, -3.64405066e-01, -1.88811943e-01, -1.59530848e-01,\n",
            "       -8.48898217e-02, -2.60574013e-01,  3.73243719e-01, -6.79026723e-01,\n",
            "        2.92345613e-01,  6.61068022e-01,  9.70925272e-01,  2.18383446e-01,\n",
            "       -9.72179249e-02,  1.16779499e-01, -4.18246657e-01, -2.97367871e-01,\n",
            "       -9.70771983e-02,  3.66201073e-01, -6.13628468e-03, -1.09243840e-01,\n",
            "        6.61642849e-01,  6.74174652e-02,  1.94333959e-02, -5.91114573e-02,\n",
            "        3.30355987e-02,  5.33189476e-01,  3.41124266e-01, -5.49432397e-01,\n",
            "        2.12904677e-01,  3.45947266e-01, -3.22259888e-02,  3.83658141e-01,\n",
            "        1.52299792e-01,  3.80699188e-01,  4.77494895e-01, -5.21420836e-01,\n",
            "       -7.88669288e-01,  9.69614163e-02, -2.51261652e-01,  9.78257060e-02,\n",
            "        7.60493875e-02, -3.90916318e-01,  1.72823519e-01,  3.81407827e-01,\n",
            "       -8.92227069e-02,  2.23974437e-01, -1.07906032e+00, -8.57450545e-01,\n",
            "       -3.99291724e-01, -1.10386036e-01,  2.95500189e-01,  6.27418876e-01,\n",
            "       -7.98142493e-01, -5.32985516e-02,  4.63617921e-01, -5.20267725e-01,\n",
            "       -1.39033943e-01,  1.40845925e-01, -7.00941086e-01, -2.80987471e-01,\n",
            "       -4.19356465e-01, -7.15785742e-01, -3.17209274e-01, -2.01651484e-01,\n",
            "        5.64000368e-01,  3.76642682e-02,  1.24699163e+00, -5.70642808e-03,\n",
            "        3.65158051e-01,  3.69006306e-01,  7.01921046e-01, -6.75200999e-01,\n",
            "        7.65426874e-01,  4.44789261e-01,  2.82683551e-01, -3.85473251e-01],\n",
            "      dtype=float32)), ('to', array([-7.76227534e-01, -7.36799121e-01,  2.14582235e-01, -4.17641431e-01,\n",
            "        4.49630141e-01, -3.79267856e-02,  3.51988226e-01, -2.08517954e-01,\n",
            "        2.07181692e-01, -1.42691731e-01, -3.94673258e-01, -1.68759480e-01,\n",
            "       -3.49762976e-01,  6.77569658e-02, -6.90425560e-02, -4.37594205e-01,\n",
            "       -3.54874492e-01,  5.95832840e-02, -3.40588570e-01,  5.97184122e-01,\n",
            "       -3.16769183e-02,  6.77074134e-01,  5.73905967e-02, -2.86212862e-01,\n",
            "       -1.90704428e-02,  4.32734303e-02,  3.62143070e-01,  2.19334252e-02,\n",
            "       -2.22233787e-01, -5.70476651e-01, -4.61562157e-01,  8.46623659e-01,\n",
            "        5.09016998e-02,  8.12511370e-02,  6.76461995e-01, -9.58544135e-01,\n",
            "       -2.95308471e-01, -8.82761061e-01, -1.02670632e-01, -3.12943533e-02,\n",
            "       -7.54674733e-01,  2.18289286e-01,  9.13982168e-02,  5.86393364e-02,\n",
            "       -2.07202852e-01, -1.56513661e-01,  1.27061701e+00, -3.02588910e-01,\n",
            "        2.79069930e-01,  1.57493126e+00,  9.78004515e-01, -1.07644594e+00,\n",
            "        4.70551759e-01, -3.90957743e-01, -9.96679425e-01,  7.94015527e-01,\n",
            "        1.58304796e-01,  3.06581736e-01,  6.42561615e-01, -7.23219633e-01,\n",
            "       -6.96242750e-01,  1.39230728e-01,  7.21710742e-01,  6.15234911e-01,\n",
            "       -3.54590751e-02,  4.21424150e-01, -8.13158095e-01,  1.22906327e-01,\n",
            "       -5.88371754e-01, -5.91577329e-02,  9.54385459e-01, -2.44179592e-01,\n",
            "        9.32670653e-01, -1.98887482e-01,  1.07747585e-01, -1.11763455e-01,\n",
            "       -2.84410298e-01, -1.04107067e-01, -3.36368307e-02, -6.05479777e-01,\n",
            "        2.15197995e-01, -1.51210904e-01,  3.63881111e-01,  1.30299836e-01,\n",
            "       -1.25573516e-01,  1.65600270e-01,  4.59121495e-01,  1.68883830e-01,\n",
            "       -2.43279859e-01,  2.27572337e-01, -3.33356768e-01,  4.70868289e-01,\n",
            "       -4.67920676e-02, -5.97329259e-01,  8.63537133e-01,  6.92304552e-01,\n",
            "       -1.62530616e-01, -1.44385351e-02, -2.47518957e-01,  2.54284203e-01,\n",
            "        2.75420666e-01,  1.75778225e-01, -4.09169376e-01, -4.04739976e-01,\n",
            "        5.38010597e-01, -1.71766907e-01, -1.13893652e+00, -9.90791097e-02,\n",
            "       -9.22973305e-02, -6.57411575e-01,  2.21899357e-02, -2.44547635e-01,\n",
            "        4.05657431e-03, -3.13117653e-01,  6.08873367e-01, -6.47572458e-01,\n",
            "        1.61521547e-02, -4.52389956e-01, -1.96445882e-02, -8.38098109e-01,\n",
            "       -6.38792887e-02,  7.86296546e-01, -5.33442318e-01, -5.50448656e-01,\n",
            "       -7.60694802e-01,  7.22759739e-02,  1.63374156e-01,  2.62253523e-01,\n",
            "       -5.15212357e-01, -4.70959097e-01, -2.31366977e-01,  5.27808785e-01,\n",
            "       -5.90004623e-01, -1.24324873e-01, -4.09870028e-01,  2.73468733e-01,\n",
            "        2.88897365e-01,  1.42186105e-01,  4.16737139e-01, -7.90551722e-01,\n",
            "        6.23312704e-02,  4.44555618e-02,  3.22424501e-01, -9.45344567e-01,\n",
            "        6.91579163e-01, -1.23191141e-01,  6.26253426e-01, -5.20354688e-01,\n",
            "        2.86119640e-01,  1.00196040e+00, -8.84912729e-01,  8.16917062e-01,\n",
            "       -4.59972888e-01,  6.53494477e-01, -1.73759256e-02,  9.36190560e-02,\n",
            "       -1.38260216e-01,  1.43378302e-01, -2.56945372e-01,  1.56786069e-01,\n",
            "        3.71958435e-01,  2.23075613e-01, -6.59774095e-02,  3.77115279e-01,\n",
            "        3.01267833e-01, -1.14550758e-02,  1.33835852e-01, -5.91584817e-02,\n",
            "        7.80611932e-02,  2.55018324e-02,  9.12210569e-02,  1.86849490e-01,\n",
            "        4.97481465e-01, -8.39872777e-01, -4.31326926e-01, -1.87579453e-01,\n",
            "        7.65029550e-01,  5.44549040e-02,  1.52833343e-01, -1.73643649e-01,\n",
            "        7.26028919e-01,  2.49563888e-01,  5.70184886e-01,  3.09029698e-01,\n",
            "       -7.53528178e-01, -1.40404761e-01,  8.80788743e-01, -8.99739787e-02,\n",
            "       -4.81269985e-01, -3.11923265e-01,  9.58924089e-03, -3.79162103e-01,\n",
            "       -1.90286949e-01, -1.45583257e-01,  4.99113142e-01,  1.00455128e-01,\n",
            "        2.68947005e-01,  1.01646626e+00, -4.51976508e-02, -2.44583368e-01,\n",
            "       -7.65189290e-01, -1.72713161e-01, -6.44554943e-02,  5.87611794e-01,\n",
            "        4.26294833e-01,  5.08857407e-02, -3.19000185e-02, -7.01738119e-01,\n",
            "       -7.13574231e-01, -6.87041163e-01, -8.53970740e-03, -4.97952193e-01,\n",
            "        9.31288958e-01,  7.59080127e-02, -5.04224718e-01, -4.04366851e-01,\n",
            "        5.42840898e-01, -6.57795727e-01,  3.14062595e-01,  6.17502816e-02,\n",
            "       -1.28323818e-02, -9.24377441e-01,  4.42936085e-02,  9.47149277e-01,\n",
            "       -1.34544373e-01, -3.84681135e-01, -3.27211112e-01,  2.46459737e-01,\n",
            "        1.23534396e-01,  1.27901956e-01,  5.28922141e-01, -9.40875888e-01,\n",
            "        1.15641970e-02,  3.80712360e-01,  4.31805789e-01, -4.99091029e-01,\n",
            "        5.78199029e-02, -1.71362519e-01, -8.75746667e-01, -1.09033883e-01,\n",
            "       -2.20934957e-01,  8.71112764e-01,  2.30012178e-01, -3.35829519e-02,\n",
            "       -1.47766575e-01,  2.11588636e-01,  1.31843891e-02, -4.95568871e-01,\n",
            "       -1.27322137e-01,  3.86868000e-01, -1.74373806e-01, -7.69126296e-01,\n",
            "        8.74199808e-01,  3.81149352e-01, -7.72009194e-01,  3.15696537e-01,\n",
            "       -1.03752688e-02,  2.28924200e-01,  3.02682728e-01, -3.52591664e-01,\n",
            "       -8.67752552e-01,  3.17393690e-01, -6.07674271e-02,  2.64416099e-01,\n",
            "       -6.88590646e-01,  8.62443671e-02,  4.80101168e-01, -4.87723768e-01,\n",
            "       -9.15222391e-02,  3.01575631e-01, -4.49494869e-01, -6.20578051e-01,\n",
            "        1.37138546e-01, -1.17336392e-01,  7.68787384e-01,  6.45446420e-01,\n",
            "       -5.40557921e-01,  2.17152581e-01,  3.33728075e-01, -5.04347086e-01,\n",
            "        2.80615501e-02, -1.75503969e-01, -9.89669323e-01,  1.17352442e-03,\n",
            "       -6.53068006e-01, -7.27456391e-01, -1.45291448e-01,  9.00130495e-02,\n",
            "        5.26389420e-01, -1.99133098e-01,  6.42356098e-01,  1.98838517e-01,\n",
            "        2.29609534e-01,  2.20126718e-01, -4.90352184e-01, -9.54479277e-01,\n",
            "        6.97331965e-01,  2.95442700e-01,  6.37854710e-02, -1.87545925e-01],\n",
            "      dtype=float32)), ('a', array([-0.83340555, -0.6395218 ,  0.3432811 , -0.4371189 ,  0.47766244,\n",
            "        0.01486485,  0.1521755 , -0.15829384, -0.38564795, -0.19725493,\n",
            "       -0.46657678, -0.6407843 ,  0.23089217, -0.11672577,  0.1864912 ,\n",
            "       -0.6001422 , -0.11646278, -0.5177186 ,  0.05559376, -0.05190364,\n",
            "       -0.4073921 ,  0.8451411 ,  0.03307216, -0.04032239,  0.04875869,\n",
            "        0.652852  ,  0.6440178 ,  0.163977  , -0.11538523, -0.54800093,\n",
            "       -0.48918033,  0.78013396,  0.25910103,  0.32154828,  0.26817176,\n",
            "       -0.34600496, -0.5425062 , -0.54922783, -0.14689082, -0.02149112,\n",
            "       -0.48985666,  0.07070766,  0.5883531 , -0.30372575,  0.04686327,\n",
            "       -0.17238325,  1.1680663 , -0.08063183, -0.26191294,  0.4047721 ,\n",
            "        0.27179325,  0.04195094,  0.264672  , -0.8340386 , -1.0685319 ,\n",
            "       -0.12752743, -0.0425894 ,  0.5919594 ,  0.10815884,  0.4418129 ,\n",
            "       -0.53239524,  0.11004786,  0.57632154,  0.11618835,  0.39323735,\n",
            "        0.03498054, -0.09914722, -0.4965719 , -0.20374124, -0.45741346,\n",
            "        0.28799778, -0.7304905 ,  0.3617147 , -0.17617753,  0.14367476,\n",
            "        0.72228587, -0.20133021, -0.24278785,  0.888099  , -0.36016873,\n",
            "        0.60776967, -0.21531154, -0.1212568 , -0.03109192, -0.4423586 ,\n",
            "        0.63264036,  0.45389906,  0.69048256,  0.04434328, -0.34049812,\n",
            "       -0.2273572 ,  0.32894492,  0.19867761, -0.2796674 ,  0.909392  ,\n",
            "        0.13293003, -0.06647578,  0.15193333, -0.09763282,  0.2151983 ,\n",
            "        0.02666878,  0.19525379, -0.5790117 ,  0.25935218, -0.02216154,\n",
            "       -0.24740155, -0.73632437,  0.03986634, -0.08290698,  0.08014393,\n",
            "        0.23215483,  0.0912572 ,  0.40687054, -0.17786153,  0.12816119,\n",
            "       -0.71825516, -0.14364281, -0.2033442 , -0.64076716, -0.576336  ,\n",
            "       -0.36857155,  0.29331133, -0.29351845, -0.357621  , -0.9458745 ,\n",
            "       -0.35918683,  0.03999856, -0.03118974, -0.1074781 , -0.23432013,\n",
            "        0.24595626,  0.55710536, -0.2845032 ,  0.05120766, -0.3751267 ,\n",
            "        0.598609  ,  0.37189573,  0.09371442,  0.68406934, -0.83311534,\n",
            "       -0.22348483,  0.00638476,  0.24051987, -0.42680287, -0.10081484,\n",
            "        0.14473495,  0.09039558, -0.16256681, -0.3208266 ,  0.01860263,\n",
            "       -0.14210136,  1.3332843 , -0.51060516,  0.01354046, -0.15474449,\n",
            "       -0.03660579,  0.37706617,  0.3096422 ,  0.52194977, -0.14107494,\n",
            "        0.21779996,  0.40900964, -0.46732903, -0.14319478,  0.62336516,\n",
            "       -0.261325  , -0.10611239, -0.7133566 , -0.14919959,  0.20990448,\n",
            "       -0.12220236,  0.34349263,  0.562687  , -1.008502  ,  0.34605926,\n",
            "       -0.39749444,  0.5774645 ,  0.33613968,  0.02726364,  0.32303318,\n",
            "        0.6828435 ,  0.2542833 ,  0.8525293 ,  0.20235175, -0.69546115,\n",
            "       -0.48112983,  0.5315244 ,  0.5819957 , -0.0748883 , -0.7424376 ,\n",
            "        0.5351424 ,  0.16781007,  0.09252251, -0.77398175,  0.35747117,\n",
            "       -0.36693448,  0.01656387,  0.55235535, -0.2640305 ,  0.08387369,\n",
            "       -0.12055083,  0.07985903,  0.22667183,  0.0544363 ,  0.6593114 ,\n",
            "        0.07397456,  0.16578977, -0.11924343, -0.07091533, -0.36315966,\n",
            "       -0.50352913,  0.48238423,  0.7481015 ,  0.29110858, -0.1361362 ,\n",
            "        0.08684598,  0.34056234, -0.5655195 ,  0.5064925 , -0.08180597,\n",
            "       -0.5119885 , -1.1352975 ,  0.07280405,  0.55523807,  0.19066961,\n",
            "       -0.4955723 , -0.16737516, -0.075184  , -0.04451047,  0.2126737 ,\n",
            "        0.22990532, -0.84064007,  0.5460036 ,  0.4282001 ,  0.59631014,\n",
            "        0.29435343, -0.27075347,  0.32430398, -0.3732596 , -0.39800933,\n",
            "       -0.14452852,  0.448886  ,  0.04718388, -0.14876422,  0.53712124,\n",
            "        0.2296757 ,  0.15197067, -0.06952769, -0.15721114,  0.25204828,\n",
            "        0.1132258 , -0.49239364, -0.12404571,  0.19622406, -0.03949092,\n",
            "        0.421563  ,  0.4116751 ,  0.12245455,  0.45435214, -0.5726679 ,\n",
            "       -0.61561537, -0.10541735, -0.19421157,  0.00306497,  0.09399574,\n",
            "       -0.44295287,  0.4084837 ,  0.18342935, -0.3562507 ,  0.34851778,\n",
            "       -0.830845  , -0.50956625, -0.26897138, -0.25105238,  0.6966771 ,\n",
            "        0.5205106 , -0.41253912,  0.44245493,  0.65560406, -0.851986  ,\n",
            "        0.04604212,  0.03816479, -0.5612144 , -0.12656103, -0.47244135,\n",
            "       -0.5258667 , -0.38630766,  0.00467656,  0.20658685,  0.12872238,\n",
            "        1.0336772 , -0.3018451 ,  0.24419203,  0.2928581 ,  0.47442356,\n",
            "       -1.0314436 ,  0.84675586,  0.09216378,  0.40524474, -0.0687547 ],\n",
            "      dtype=float32)), ('of', array([-4.25083041e-02, -8.86153519e-01,  3.85914832e-01, -1.21555187e-01,\n",
            "        4.33966368e-01, -2.47384101e-01, -5.22188796e-03,  2.03861427e-02,\n",
            "       -5.31987369e-01,  2.32740402e-01, -2.45682076e-01, -3.80348682e-01,\n",
            "       -2.98303545e-01,  3.33509564e-01,  6.92753345e-02, -1.83527395e-01,\n",
            "        3.67728546e-02, -4.10221219e-01,  3.44930053e-01,  3.58970799e-02,\n",
            "       -2.88976878e-01,  1.07900047e+00,  1.15345903e-01, -1.55089334e-01,\n",
            "       -9.39403009e-03,  6.10218287e-01,  9.68208909e-02, -3.64995301e-01,\n",
            "       -2.12569967e-01, -1.01524401e+00, -2.18722299e-01,  1.18631995e+00,\n",
            "       -1.29315900e-04,  1.43344373e-01,  5.13916552e-01, -2.85374612e-01,\n",
            "       -5.12037754e-01, -5.97012579e-01, -6.25899494e-01,  1.75136998e-01,\n",
            "       -1.74393550e-01,  3.64524364e-01, -3.28679234e-01,  5.33536561e-02,\n",
            "        3.38586867e-01, -5.56920290e-01,  1.06766617e+00, -3.91119182e-01,\n",
            "       -4.52586681e-01,  7.51920223e-01,  6.06645346e-01, -4.09600466e-01,\n",
            "        9.75170135e-02, -4.95932370e-01, -8.06235969e-01,  9.27601576e-01,\n",
            "       -5.79872727e-01,  8.78453135e-01,  1.80403218e-01, -4.64140594e-01,\n",
            "       -9.67568338e-01, -7.12365881e-02,  3.94262522e-01,  9.01971519e-01,\n",
            "       -1.11082550e-02,  1.53137013e-01, -5.85870862e-01,  1.11277699e-02,\n",
            "       -3.54834229e-01, -6.68618739e-01,  2.08570853e-01,  2.20659282e-02,\n",
            "        5.14698885e-02,  2.29446590e-01, -1.58379734e-01, -5.74896820e-02,\n",
            "       -5.68825841e-01, -1.16362117e-01,  2.86364943e-01,  4.71496657e-02,\n",
            "        7.01439917e-01, -1.89970613e-01,  3.16445380e-02,  3.33592206e-01,\n",
            "       -4.88110572e-01,  7.67903507e-01,  7.01077104e-01,  5.73370159e-01,\n",
            "       -4.69666123e-01, -2.59646416e-01, -1.25543952e-01,  8.23562920e-01,\n",
            "       -1.57769769e-01, -3.55570853e-01,  5.61390519e-01,  3.91858906e-01,\n",
            "        3.45614016e-01, -2.20276251e-01, -5.03359675e-01, -7.67110512e-02,\n",
            "        4.39114839e-01,  4.41258788e-01,  1.45223796e-01, -4.84806120e-01,\n",
            "        4.59246755e-01, -1.25759646e-01, -6.08062208e-01, -2.90794894e-02,\n",
            "        5.73687673e-01, -4.29395437e-01,  1.13446578e-01,  6.93983883e-02,\n",
            "        6.62116230e-01, -1.49639368e-01,  4.65111405e-01, -8.78444195e-01,\n",
            "       -7.83963278e-02,  3.84179771e-01,  1.64039299e-01, -6.15381658e-01,\n",
            "       -2.49860317e-01,  3.41800511e-01, -8.12917590e-01, -8.42539489e-01,\n",
            "        6.43681586e-02, -4.32815962e-02,  7.87446797e-02,  1.66791886e-01,\n",
            "       -5.02473712e-01, -4.70540583e-01, -1.05805092e-01,  1.74547043e-02,\n",
            "       -4.68316108e-01, -4.67025071e-01, -4.88429695e-01, -2.61918396e-01,\n",
            "        2.58285344e-01, -2.59355013e-03, -3.58933002e-01, -4.70997304e-01,\n",
            "        1.24510340e-01,  1.97448760e-01, -7.88078159e-02, -1.86183289e-01,\n",
            "        3.45459670e-01,  2.55909972e-02,  4.67356235e-01, -1.83751881e-02,\n",
            "       -3.73027951e-01,  6.12987816e-01, -4.32082444e-01,  4.83940423e-01,\n",
            "       -1.19447790e-01,  7.85165727e-01,  5.39626718e-01,  4.04214889e-01,\n",
            "        3.69869679e-01,  2.15497032e-01,  6.18369915e-02, -6.62815720e-02,\n",
            "       -2.87225276e-01,  2.71529734e-01, -8.11750233e-01,  5.77237546e-01,\n",
            "        5.56916893e-01, -1.46894157e-01, -4.72569942e-01,  1.07877091e-01,\n",
            "       -1.74060628e-01, -2.76060224e-01,  5.17960370e-01, -1.51177019e-01,\n",
            "        8.27853203e-01, -3.18581343e-01,  2.50785261e-01,  2.03304544e-01,\n",
            "        5.84764183e-01,  3.83671075e-01,  2.57631809e-01, -5.23507744e-02,\n",
            "        4.71095830e-01,  3.43064398e-01,  1.06393290e+00,  3.40385586e-01,\n",
            "       -1.57111689e-01,  1.46892637e-01,  6.62249774e-02,  4.03647631e-01,\n",
            "       -1.06643230e-01, -6.81879282e-01,  1.02300189e-01, -1.13679945e-01,\n",
            "       -1.95161819e-01, -5.77541530e-01,  6.24803185e-01, -2.24708363e-01,\n",
            "       -6.77080393e-01,  3.86672944e-01, -2.86264807e-01,  3.45953375e-01,\n",
            "       -5.66688329e-02,  4.53873515e-01, -1.44245803e-01,  1.41081706e-01,\n",
            "        6.26687258e-02,  2.78751016e-01, -4.09875140e-02, -3.64419520e-01,\n",
            "       -9.46673304e-02, -4.97142851e-01,  7.57408366e-02, -4.58141088e-01,\n",
            "        1.72175273e-01, -4.40718606e-02, -2.00898767e-01, -4.08197083e-02,\n",
            "        7.41360605e-01, -3.24279040e-01,  1.43921047e-01, -2.16900140e-01,\n",
            "       -2.49940500e-01, -8.60332072e-01,  4.68326569e-01,  7.64258742e-01,\n",
            "        4.88538235e-01, -4.00908262e-01, -6.69995904e-01,  2.31895655e-01,\n",
            "        5.20942025e-02, -9.20278847e-01,  1.60839841e-01, -9.22191322e-01,\n",
            "        2.71972507e-01,  4.74876255e-01,  7.52651095e-01,  1.99514657e-01,\n",
            "        8.42594653e-02, -4.96762320e-02, -6.29110456e-01, -8.60051513e-02,\n",
            "        3.61875701e-03,  3.29849094e-01,  6.97058976e-01, -9.74790454e-02,\n",
            "        2.54607975e-01, -2.86059797e-01,  9.37761888e-02,  2.04113588e-01,\n",
            "        5.04478931e-01,  6.52475178e-01,  3.89993995e-01, -5.79141855e-01,\n",
            "        3.43978077e-01,  1.54185459e-01, -2.09484160e-01,  8.89924988e-02,\n",
            "        1.46345021e-02,  2.70093739e-01,  3.49820048e-01, -1.80120930e-01,\n",
            "       -9.05278504e-01,  1.23419285e-01, -9.41904262e-02,  2.39930630e-01,\n",
            "       -1.09818816e-01, -1.08660661e-01,  4.19112176e-01, -9.52808037e-02,\n",
            "       -2.35174060e-01, -2.51746893e-01, -6.51903391e-01, -8.14872622e-01,\n",
            "       -2.20986038e-01,  7.11861029e-02,  7.61753321e-02,  6.07924402e-01,\n",
            "       -1.08009493e+00, -3.61566871e-01,  4.20927733e-01, -4.64396954e-01,\n",
            "        1.63653940e-01,  5.02533853e-01, -6.92780018e-01, -4.94310260e-01,\n",
            "       -1.32490575e-01, -1.02886951e+00,  2.42137183e-02, -5.97250760e-02,\n",
            "        4.78381306e-01, -2.56803572e-01,  8.91181588e-01,  4.89793390e-01,\n",
            "       -1.94485918e-01,  4.01605338e-01,  2.66049951e-01, -6.28464937e-01,\n",
            "        5.60995698e-01,  2.20496461e-01, -1.00226380e-01, -7.52284303e-02],\n",
            "      dtype=float32))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_index.get('society'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFd1djSzZwev",
        "outputId": "c0772722-9ad2-4897-c097-fdc2af460ecb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQCagTqZZwZ0",
        "outputId": "e4681924-f86b-488f-d744-75bcff87c589"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.37889999, -0.71711123,  0.33162379, ...,  0.44478926,\n",
              "         0.28268355, -0.38547325],\n",
              "       [-0.77622753, -0.73679912,  0.21458223, ...,  0.2954427 ,\n",
              "         0.06378547, -0.18754593],\n",
              "       [-0.83340555, -0.63952178,  0.34328109, ...,  0.09216378,\n",
              "         0.40524474, -0.0687547 ],\n",
              "       [-0.44995633, -0.65132201,  0.46993828, ...,  0.18409519,\n",
              "        -0.01396127, -0.13326971]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkWCc9vnaNSO",
        "outputId": "80b7a88d-5e32-45b7-a6d0-731e53eee7c4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "cvscores = []\n",
        "accscores = []\n",
        "rocscores = []\n",
        "\n",
        "for train, test in kfold.split(train_padding, y):\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1)(x)\n",
        "    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(6, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "\n",
        "    saved_model = \"w2vPP.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(train_padding, y, batch_size=32, epochs=4, callbacks=[checkpoint], validation_split=0.1)\n",
        "\n",
        "    scores = model.evaluate(train_padding[test], y[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    print(\"Loading model....\")\n",
        "    model = load_model('w2vPP.hdf5')\n",
        "    y_pred = model.predict(test_padding)\n",
        "\n",
        "    y_int = np.zeros_like(y_pred)\n",
        "    y_int[y_pred > 0.5] = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_int)\n",
        "    print('Accuracy is {}'.format(accuracy))\n",
        "    accscores.append(accuracy)\n",
        "    \n",
        "    rocauc = roc_auc_score(y_test, y_pred)\n",
        "    print('Roc-auc score is {}'.format(rocauc))\n",
        "    rocscores.append(rocauc)\n",
        "    \n",
        "    print('Classification report {}'.format(classification_report(y_test, y_int, zero_division=0)))\n",
        "    print('Confusion matrix {}'.format(multilabel_confusion_matrix(y_test, y_int)))\n",
        "        \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"Test accuracy is: {} %.2f (+/- %.2f)\" %  (np.mean(accscores), np.std(accscores)))\n",
        "print(\"Test roc-auc is: {} %.2f (+/- %.2f)\" % (np.mean(rocscores), np.std(rocscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scsG9K3IaNNZ",
        "outputId": "4f214362-78fb-48fb-a0ce-23010eb82681"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 200, 300)     6000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 200, 300)    0           ['embedding[0][0]']              \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 200, 128)     219648      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 198, 64)      24640       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 , 'global_max_pooling1d[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6)            390         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.3095 - acc: 0.8198\n",
            "Epoch 1: val_acc improved from -inf to 0.83454, saving model to w2vPP.hdf5\n",
            "624/624 [==============================] - 578s 920ms/step - loss: 0.3095 - acc: 0.8198 - val_loss: 0.2819 - val_acc: 0.8345\n",
            "Epoch 2/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2846 - acc: 0.8218\n",
            "Epoch 2: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 572s 917ms/step - loss: 0.2846 - acc: 0.8218 - val_loss: 0.2830 - val_acc: 0.8345\n",
            "Epoch 3/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2265 - acc: 0.8188\n",
            "Epoch 3: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 582s 933ms/step - loss: 0.2265 - acc: 0.8188 - val_loss: 0.3050 - val_acc: 0.8318\n",
            "Epoch 4/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.1801 - acc: 0.8260\n",
            "Epoch 4: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 559s 896ms/step - loss: 0.1801 - acc: 0.8260 - val_loss: 0.3703 - val_acc: 0.8165\n",
            "232/232 [==============================] - 25s 109ms/step - loss: 0.1441 - acc: 0.8392\n",
            "acc: 83.92%\n",
            "Loading model....\n",
            "694/694 [==============================] - 76s 109ms/step\n",
            "Accuracy is 0.7842810118591333\n",
            "Roc-auc score is 0.5631830064152349\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1835\n",
            "           1       0.87      1.00      0.93     19258\n",
            "           2       0.00      0.00      0.00      1864\n",
            "           3       0.00      0.00      0.00      2108\n",
            "           4       0.00      0.00      0.00      1619\n",
            "           5       0.00      0.00      0.00      1307\n",
            "\n",
            "   micro avg       0.87      0.69      0.77     27991\n",
            "   macro avg       0.14      0.17      0.15     27991\n",
            "weighted avg       0.60      0.69      0.64     27991\n",
            " samples avg       0.87      0.82      0.83     27991\n",
            "\n",
            "Confusion matrix [[[20342     0]\n",
            "  [ 1835     0]]\n",
            "\n",
            " [[    0  2919]\n",
            "  [    0 19258]]\n",
            "\n",
            " [[20313     0]\n",
            "  [ 1864     0]]\n",
            "\n",
            " [[20069     0]\n",
            "  [ 2108     0]]\n",
            "\n",
            " [[20558     0]\n",
            "  [ 1619     0]]\n",
            "\n",
            " [[20870     0]\n",
            "  [ 1307     0]]]\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 200, 300)     6000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_1 (SpatialDr  (None, 200, 300)    0           ['embedding_1[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 200, 128)     219648      ['spatial_dropout1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 198, 64)      24640       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.3098 - acc: 0.8200\n",
            "Epoch 1: val_acc improved from -inf to 0.83454, saving model to w2vPP.hdf5\n",
            "624/624 [==============================] - 594s 947ms/step - loss: 0.3098 - acc: 0.8200 - val_loss: 0.2820 - val_acc: 0.8345\n",
            "Epoch 2/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2852 - acc: 0.8218\n",
            "Epoch 2: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 611s 978ms/step - loss: 0.2852 - acc: 0.8218 - val_loss: 0.2789 - val_acc: 0.8345\n",
            "Epoch 3/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2281 - acc: 0.8229\n",
            "Epoch 3: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 567s 909ms/step - loss: 0.2281 - acc: 0.8229 - val_loss: 0.3071 - val_acc: 0.8260\n",
            "Epoch 4/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.1868 - acc: 0.8279\n",
            "Epoch 4: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 561s 898ms/step - loss: 0.1868 - acc: 0.8279 - val_loss: 0.3695 - val_acc: 0.8151\n",
            "231/231 [==============================] - 27s 115ms/step - loss: 0.1610 - acc: 0.8324\n",
            "acc: 83.24%\n",
            "Loading model....\n",
            "694/694 [==============================] - 79s 113ms/step\n",
            "Accuracy is 0.7842810118591333\n",
            "Roc-auc score is 0.5606571056046502\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1835\n",
            "           1       0.87      1.00      0.93     19258\n",
            "           2       0.00      0.00      0.00      1864\n",
            "           3       0.00      0.00      0.00      2108\n",
            "           4       0.00      0.00      0.00      1619\n",
            "           5       0.00      0.00      0.00      1307\n",
            "\n",
            "   micro avg       0.87      0.69      0.77     27991\n",
            "   macro avg       0.14      0.17      0.15     27991\n",
            "weighted avg       0.60      0.69      0.64     27991\n",
            " samples avg       0.87      0.82      0.83     27991\n",
            "\n",
            "Confusion matrix [[[20342     0]\n",
            "  [ 1835     0]]\n",
            "\n",
            " [[    0  2919]\n",
            "  [    0 19258]]\n",
            "\n",
            " [[20313     0]\n",
            "  [ 1864     0]]\n",
            "\n",
            " [[20069     0]\n",
            "  [ 2108     0]]\n",
            "\n",
            " [[20558     0]\n",
            "  [ 1619     0]]\n",
            "\n",
            " [[20870     0]\n",
            "  [ 1307     0]]]\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 200, 300)     6000000     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_2 (SpatialDr  (None, 200, 300)    0           ['embedding_2[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 200, 128)     219648      ['spatial_dropout1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 198, 64)      24640       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 6)            390         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.3128 - acc: 0.8200\n",
            "Epoch 1: val_acc improved from -inf to 0.83454, saving model to w2vPP.hdf5\n",
            "624/624 [==============================] - 569s 906ms/step - loss: 0.3128 - acc: 0.8200 - val_loss: 0.2896 - val_acc: 0.8345\n",
            "Epoch 2/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2857 - acc: 0.8218\n",
            "Epoch 2: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 595s 954ms/step - loss: 0.2857 - acc: 0.8218 - val_loss: 0.2814 - val_acc: 0.8345\n",
            "Epoch 3/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.2269 - acc: 0.8215\n",
            "Epoch 3: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 569s 911ms/step - loss: 0.2269 - acc: 0.8215 - val_loss: 0.3070 - val_acc: 0.8165\n",
            "Epoch 4/4\n",
            "624/624 [==============================] - ETA: 0s - loss: 0.1804 - acc: 0.8289\n",
            "Epoch 4: val_acc did not improve from 0.83454\n",
            "624/624 [==============================] - 558s 894ms/step - loss: 0.1804 - acc: 0.8289 - val_loss: 0.3957 - val_acc: 0.8188\n",
            "231/231 [==============================] - 28s 120ms/step - loss: 0.2247 - acc: 0.8323\n",
            "acc: 83.23%\n",
            "Loading model....\n",
            "694/694 [==============================] - 81s 116ms/step\n",
            "Accuracy is 0.7842810118591333\n",
            "Roc-auc score is 0.5674780239803076\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1835\n",
            "           1       0.87      1.00      0.93     19258\n",
            "           2       0.00      0.00      0.00      1864\n",
            "           3       0.00      0.00      0.00      2108\n",
            "           4       0.00      0.00      0.00      1619\n",
            "           5       0.00      0.00      0.00      1307\n",
            "\n",
            "   micro avg       0.87      0.69      0.77     27991\n",
            "   macro avg       0.14      0.17      0.15     27991\n",
            "weighted avg       0.60      0.69      0.64     27991\n",
            " samples avg       0.87      0.82      0.83     27991\n",
            "\n",
            "Confusion matrix [[[20342     0]\n",
            "  [ 1835     0]]\n",
            "\n",
            " [[    0  2919]\n",
            "  [    0 19258]]\n",
            "\n",
            " [[20313     0]\n",
            "  [ 1864     0]]\n",
            "\n",
            " [[20069     0]\n",
            "  [ 2108     0]]\n",
            "\n",
            " [[20558     0]\n",
            "  [ 1619     0]]\n",
            "\n",
            " [[20870     0]\n",
            "  [ 1307     0]]]\n",
            "83.46% (+/- 0.32%)\n",
            "Test accuracy is: {} 0.78 (+/- 0.00)\n",
            "Test roc-auc is: {} 0.56 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}