{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MmfhxkfM9S6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/unhealthy_full.csv\")\n",
        "\n",
        "data_csv = pd.read_csv(url_data)"
      ],
      "metadata": {
        "id": "NT6AepL6BX9Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "LeCtp8vgBYAK",
        "outputId": "ba20c83d-6ba2-4e13-e4f5-5f0ef76a18d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90fbf120-1f5c-4e3a-9abb-1c5f8cf439b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90fbf120-1f5c-4e3a-9abb-1c5f8cf439b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90fbf120-1f5c-4e3a-9abb-1c5f8cf439b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90fbf120-1f5c-4e3a-9abb-1c5f8cf439b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7mQ2QVRBYCV",
        "outputId": "f877bc4b-5c6a-4bcb-f756-8fa74f5257b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227975, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAPMmCI4aH1U",
        "outputId": "8374ad5a-9ec8-413c-8d2a-cf1c4e7637cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NnokaXvasZa",
        "outputId": "540d122e-3b43-4290-b936-48bf827ef5e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of           _unit_id                                            comment  _trust  \\\n",
              "0       2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1       2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2       1812167562                                    To you perhaps.  0.9929   \n",
              "3       2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4       1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "...            ...                                                ...     ...   \n",
              "227970  1739450093  In 2001 the price of oil was around $25 a barr...  0.9071   \n",
              "227971  1739449742  How about answering the question asked rather ...  0.8908   \n",
              "227972  1739443029  Re: 'he is not a war mugger' [sic]You seem to ...  0.9716   \n",
              "227973  1812168293  At last someone trotting out facts instead of ...  0.8409   \n",
              "227974  1739467981  why should I care what the catholic dinosaurs ...  0.9000   \n",
              "\n",
              "        _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0         44856405           0              0           0               0   \n",
              "1         45322411           0              0           0               1   \n",
              "2         44126774           0              0           0               0   \n",
              "3         45178195           0              0           0               0   \n",
              "4         44619566           0              0           0               0   \n",
              "...            ...         ...            ...         ...             ...   \n",
              "227970     6377879           0              0           0               0   \n",
              "227971    21459945           1              1           1               0   \n",
              "227972    43850628           0              1           0               0   \n",
              "227973    44665560           0              0           0               0   \n",
              "227974    44549002           1              1           0               1   \n",
              "\n",
              "        generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                         0.0        1        0          0  \n",
              "1                         1.0        0        0          0  \n",
              "2                         0.0        1        0          0  \n",
              "3                         0.0        1        0          0  \n",
              "4                         0.0        0        0          0  \n",
              "...                       ...      ...      ...        ...  \n",
              "227970                    0.0        1        0          0  \n",
              "227971                    0.0        1        1          1  \n",
              "227972                    0.0        0        0          0  \n",
              "227973                    0.0        1        0          0  \n",
              "227974                    1.0        0        1          1  \n",
              "\n",
              "[227975 rows x 12 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MUQZC1YYaHtm",
        "outputId": "b5134450-139a-48f9-95f8-6db27ac155f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        _unit_id  comment  _trust  _worker_id  antagonize  condescending  \\\n",
              "0          False    False   False       False       False          False   \n",
              "1          False    False   False       False       False          False   \n",
              "2          False    False   False       False       False          False   \n",
              "3          False    False   False       False       False          False   \n",
              "4          False    False   False       False       False          False   \n",
              "...          ...      ...     ...         ...         ...            ...   \n",
              "227970     False    False   False       False       False          False   \n",
              "227971     False    False   False       False       False          False   \n",
              "227972     False    False   False       False       False          False   \n",
              "227973     False    False   False       False       False          False   \n",
              "227974     False    False   False       False       False          False   \n",
              "\n",
              "        dismissive  generalisation  generalisation_unfair  healthy  hostile  \\\n",
              "0            False           False                  False    False    False   \n",
              "1            False           False                  False    False    False   \n",
              "2            False           False                  False    False    False   \n",
              "3            False           False                  False    False    False   \n",
              "4            False           False                  False    False    False   \n",
              "...            ...             ...                    ...      ...      ...   \n",
              "227970       False           False                  False    False    False   \n",
              "227971       False           False                  False    False    False   \n",
              "227972       False           False                  False    False    False   \n",
              "227973       False           False                  False    False    False   \n",
              "227974       False           False                  False    False    False   \n",
              "\n",
              "        sarcastic  \n",
              "0           False  \n",
              "1           False  \n",
              "2           False  \n",
              "3           False  \n",
              "4           False  \n",
              "...           ...  \n",
              "227970      False  \n",
              "227971      False  \n",
              "227972      False  \n",
              "227973      False  \n",
              "227974      False  \n",
              "\n",
              "[227975 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b36250b-f284-4c1b-9a87-dd575a783bea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227970</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227971</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227972</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227973</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227974</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>227975 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b36250b-f284-4c1b-9a87-dd575a783bea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b36250b-f284-4c1b-9a87-dd575a783bea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b36250b-f284-4c1b-9a87-dd575a783bea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jBui5D9aHhJ",
        "outputId": "e1783f4b-5504-438c-c0cb-cba3c7794c9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_unit_id                 False\n",
              "comment                   True\n",
              "_trust                   False\n",
              "_worker_id               False\n",
              "antagonize               False\n",
              "condescending            False\n",
              "dismissive               False\n",
              "generalisation           False\n",
              "generalisation_unfair    False\n",
              "healthy                  False\n",
              "hostile                  False\n",
              "sarcastic                False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop=data_csv.drop_duplicates(subset=\"comment\")"
      ],
      "metadata": {
        "id": "AyWmGYEaJN3J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv[\"comment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyUo0Kw5p-L",
        "outputId": "4f71b1f4-ae36-403c-e1d3-3d3d91c0aa4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Moon, Do you *really* need it spelled out to you?\n",
              "1         It means you can ask the values questions, but...\n",
              "2                                           To you perhaps.\n",
              "3         I don't want to put words in your mouth, but a...\n",
              "4         perhaps this is not a problem seeing as how ev...\n",
              "                                ...                        \n",
              "227970    In 2001 the price of oil was around $25 a barr...\n",
              "227971    How about answering the question asked rather ...\n",
              "227972    Re: 'he is not a war mugger' [sic]You seem to ...\n",
              "227973    At last someone trotting out facts instead of ...\n",
              "227974    why should I care what the catholic dinosaurs ...\n",
              "Name: comment, Length: 227975, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oSWbI9oLt4Z",
        "outputId": "85ff0ac8-b81a-4200-a497-149868c88755"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44355, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull= data_csv_drop.dropna()\n",
        "data_del_ind= data_cnull[(data_cnull[\"sarcastic\"]==0) & (data_cnull[\"healthy\"]==0) & (data_cnull[\"antagonize\"]==0) & (data_cnull[\"condescending\"]==0) & (data_cnull[\"dismissive\"]==0) & (data_cnull[\"hostile\"]==0)].index\n",
        "data_pnull = data_cnull.drop(data_del_ind)\n",
        "data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n",
        "data_wnull = data_pnull.drop(data_wnull_ind)\n",
        "data_wnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlg427rbxEDi",
        "outputId": "7c7d0531-1b0a-4d60-b1b3-f74b76bf3d5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9f9d33e04fea>:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39533, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_test= train_test_split(data_wnull, test_size=0.5, random_state=42)\n",
        "print(data_train.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnst4mR9w3uM",
        "outputId": "5c8fc09d-c5e6-4095-f1f6-001c765c452c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19766, 12) (19767, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgEKZzkNVe-",
        "outputId": "558a16a3-6214-40cf-d6c7-14049c60293f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8c6HmiVM2r9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, BatchNormalization, SpatialDropout1D, GlobalAveragePooling1D, concatenate, Activation, LSTM, Bidirectional\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models    \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, multilabel_confusion_matrix\n",
        "\n",
        "embed_size = 300 \n",
        "max_features = 20000 \n",
        "maxlen = 200 \n",
        "\n",
        "print('Loading data...')\n",
        "\n",
        "classes = [\"sarcastic\", \"healthy\", \"antagonize\", \"condescending\", \"dismissive\", \"hostile\"]\n",
        "y = data_train[classes].values\n",
        "y_test = data_test[classes].values\n",
        "\n",
        "train_sentences = data_train[\"comment\"]\n",
        "test_sentences = data_test[\"comment\"]\n",
        "\n",
        "words = list()\n",
        "for i in train_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(i) # word tokenizacia\n",
        "    words.append(tokens) # pridá výsledné slová do prázdneho listu, ktorý sme na začiatku vytvorili\n",
        "print('Word2Vec...')\n",
        "print(words[:10])\n",
        "\n",
        "\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding\n",
        "\n",
        "model = Word2Vec(words, min_count = 1,size=300) #word to vector, implementacia z kniznice gensim\n",
        "vocabulary = model.wv.vocab #slovnik\n",
        "name = 'w2v.txt'\n",
        "model.wv.save_word2vec_format(name, binary = False)\n",
        "\n",
        "EMBEDDING_FILE = 'w2v.txt' # load embeddings\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "tokenized_train_sentences = tokenizer.texts_to_sequences(train_sentences)\n",
        "tokenized_test_sentences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_train_sentences, maxlen)\n",
        "test_padding = pad_sequences(tokenized_test_sentences, maxlen)\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# cross validation        \n",
        "kfold = KFold(n_splits=3)\n",
        "cvscores = []\n",
        "accscores = []\n",
        "rocscores = []\n",
        "\n",
        "for train, test in kfold.split(train_padding, y):\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1)(x)\n",
        "    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(6, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "\n",
        "    saved_model = \"w2v.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(train_padding, y, batch_size=32, epochs=5, callbacks=[checkpoint], validation_split=0.1)\n",
        "\n",
        "    scores = model.evaluate(train_padding[test], y[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    print(\"Loading model....\")\n",
        "    model = models.load_model('w2v.hdf5')\n",
        "    y_pred = model.predict(test_padding)\n",
        "\n",
        "    y_int = np.zeros_like(y_pred)\n",
        "    y_int[y_pred > 0.5] = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_int)\n",
        "    print('Accuracy is {}'.format(accuracy))\n",
        "    accscores.append(accuracy)\n",
        "    \n",
        "    rocauc = roc_auc_score(y_test, y_pred)\n",
        "    print('Roc-auc score is {}'.format(rocauc))\n",
        "    rocscores.append(rocauc)\n",
        "    \n",
        "    print('Classification report {}'.format(classification_report(y_test, y_int, zero_division=0)))\n",
        "    print('Confusion matrix {}'.format(multilabel_confusion_matrix(y_test, y_int)))\n",
        "        \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"Test accuracy is: {} %.2f (+/- %.2f)\" %  (np.mean(accscores), np.std(accscores)))\n",
        "print(\"Test roc-auc is: {} %.2f (+/- %.2f)\" % (np.mean(rocscores), np.std(rocscores)))\n"
      ],
      "metadata": {
        "id": "Q7tbVDEUwUtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b6647c-221f-4ab4-de27-edc9a0786881"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Word2Vec...\n",
            "[['There', 'hasn', 't', 'been', 'a', 'pragmatic', 'conservative', 'voice', 'on', 'either', 'side', 'of', 'the', 'border', 'for', '40', 'years'], ['Canada', 'should', 'first', 'make', 'Canada', 'better', 'before', 'making', 'else', 'where'], ['Just', 'keep', 'blaming', 'others', 'for', 'the', 'fact', 'that', 'the', 'CPC', 'is', 'not', 'forward', 'looking', 'but', 'backward', 'looking', 'The', 'same', 'strategy', 'is', 'really', 'working', 'for', 'the', 'Ontario', 'PCs', 'who', 'have', 'been', 'reduced', 'to', 'being', 'nothing', 'but', 'a', 'rural', 'rump', 'party', 'of', 'grumpy', 'old', 'people'], ['Oh', 'the', 'conservatives', 'are', 'literally', 'in', 'knots', 'the', 'people', 'of', 'Canada', 'have', 'spoken', 'and', 'swept', 'you', 'out', 'of', 'power', 'federally', 'and', 'in', 'the', 'AB', 'heartland', 'That', 'was', 'populism', 'in', 'action'], ['Again', 'Jack', 'embarrassing', 'commentary', 'You', 'bring', 'nothing', 'to', 'the', 'conversation', 'of', 'value', 'Please', 'either', 'up', 'your', 'game', 'or', 'stay', 'home'], ['Prime', 'example', 'of', 'a', 'self', 'inflicted', 'injury'], ['Thanks', 'for', 'pointing', 'out', 'the', 'simple', 'spelling', 'error', 'to', 'everyone', 'how', 'could', 'we', 'have', 'ever', 'understood', 'the', 'comment', 'without', 'your', 'catty', 'comment'], ['Only', 'in', 'your', 'twisted', 'dreams', 'has', 'Harper', 'stood', 'up', 'to', 'Putin', 'whenever', 'Putin', 's', 'name', 'is', 'mentioned', 'Harper', 'instantly', 'soils', 'himself', 'while', 'dashing', 'into', 'the', 'nearest', 'closet', 'to', 'cower'], ['Madiba', 's', 'values', 'Communist', 'violence', 'incompetence', 'and', 'corruption', 'Ma', 'am', 'we', 'already', 'have', 'a', 'Liberal', 'party'], ['Obamacare', 'was', 'invented', 'by', 'the', 'Republicans', 'first', 'in', 'response', 'to', 'Hilary', 'Clinton', 's', 'health', 'care', 'reform', 'proposals', 'in', 'the', '1990s', 'and', 'then', 'in', 'Massachusetts', 'as', 'Romneycare']]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 200, 300)     6000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 200, 300)    0           ['embedding[0][0]']              \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 200, 128)     219648      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 198, 64)      24640       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 , 'global_max_pooling1d[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6)            390         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2469 - acc: 0.8805\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to w2v.hdf5\n",
            "556/556 [==============================] - 335s 596ms/step - loss: 0.2469 - acc: 0.8805 - val_loss: 0.2475 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2301 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 329s 592ms/step - loss: 0.2301 - acc: 0.8826 - val_loss: 0.2452 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1718 - acc: 0.8808\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 323s 580ms/step - loss: 0.1718 - acc: 0.8808 - val_loss: 0.2857 - val_acc: 0.8599\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1210 - acc: 0.8965\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 336s 604ms/step - loss: 0.1210 - acc: 0.8965 - val_loss: 0.3933 - val_acc: 0.8381\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.9056\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 332s 596ms/step - loss: 0.0947 - acc: 0.9056 - val_loss: 0.4516 - val_acc: 0.8280\n",
            "206/206 [==============================] - 15s 74ms/step - loss: 0.0678 - acc: 0.9199\n",
            "acc: 91.99%\n",
            "Loading model....\n",
            "618/618 [==============================] - 46s 75ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.5569617498206889\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 200, 300)     6000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_1 (SpatialDr  (None, 200, 300)    0           ['embedding_1[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 200, 128)     219648      ['spatial_dropout1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 198, 64)      24640       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2497 - acc: 0.8824\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to w2v.hdf5\n",
            "556/556 [==============================] - 359s 640ms/step - loss: 0.2497 - acc: 0.8824 - val_loss: 0.2488 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2320 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 357s 642ms/step - loss: 0.2320 - acc: 0.8826 - val_loss: 0.2458 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.8828\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 368s 663ms/step - loss: 0.1784 - acc: 0.8828 - val_loss: 0.2856 - val_acc: 0.8655\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1244 - acc: 0.8979\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 372s 670ms/step - loss: 0.1244 - acc: 0.8979 - val_loss: 0.3715 - val_acc: 0.8533\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.0972 - acc: 0.9075\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 364s 654ms/step - loss: 0.0972 - acc: 0.9075 - val_loss: 0.4478 - val_acc: 0.8316\n",
            "206/206 [==============================] - 17s 84ms/step - loss: 0.0852 - acc: 0.9080\n",
            "acc: 90.80%\n",
            "Loading model....\n",
            "618/618 [==============================] - 51s 82ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.5500114878014858\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 200, 300)     6000000     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_2 (SpatialDr  (None, 200, 300)    0           ['embedding_2[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 200, 128)     219648      ['spatial_dropout1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 198, 64)      24640       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 6)            390         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,252,934\n",
            "Trainable params: 6,252,934\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2491 - acc: 0.8795\n",
            "Epoch 1: val_acc improved from -inf to 0.86899, saving model to w2v.hdf5\n",
            "556/556 [==============================] - 362s 644ms/step - loss: 0.2491 - acc: 0.8795 - val_loss: 0.2485 - val_acc: 0.8690\n",
            "Epoch 2/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.2301 - acc: 0.8826\n",
            "Epoch 2: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 344s 619ms/step - loss: 0.2301 - acc: 0.8826 - val_loss: 0.2521 - val_acc: 0.8690\n",
            "Epoch 3/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1686 - acc: 0.8849\n",
            "Epoch 3: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 391s 703ms/step - loss: 0.1686 - acc: 0.8849 - val_loss: 0.2933 - val_acc: 0.8649\n",
            "Epoch 4/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.8983\n",
            "Epoch 4: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 339s 609ms/step - loss: 0.1194 - acc: 0.8983 - val_loss: 0.3334 - val_acc: 0.8569\n",
            "Epoch 5/5\n",
            "556/556 [==============================] - ETA: 0s - loss: 0.0933 - acc: 0.9057\n",
            "Epoch 5: val_acc did not improve from 0.86899\n",
            "556/556 [==============================] - 340s 612ms/step - loss: 0.0933 - acc: 0.9057 - val_loss: 0.4625 - val_acc: 0.8402\n",
            "206/206 [==============================] - 16s 80ms/step - loss: 0.1908 - acc: 0.8934\n",
            "acc: 89.34%\n",
            "Loading model....\n",
            "618/618 [==============================] - 51s 82ms/step\n",
            "Accuracy is 0.8766125360449234\n",
            "Roc-auc score is 0.5591179014569382\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1314\n",
            "           1       0.90      1.00      0.95     17822\n",
            "           2       0.00      0.00      0.00      1347\n",
            "           3       0.00      0.00      0.00      1196\n",
            "           4       0.00      0.00      0.00       956\n",
            "           5       0.00      0.00      0.00       996\n",
            "\n",
            "   micro avg       0.90      0.75      0.82     23631\n",
            "   macro avg       0.15      0.17      0.16     23631\n",
            "weighted avg       0.68      0.75      0.72     23631\n",
            " samples avg       0.90      0.89      0.89     23631\n",
            "\n",
            "Confusion matrix [[[18453     0]\n",
            "  [ 1314     0]]\n",
            "\n",
            " [[    0  1945]\n",
            "  [    0 17822]]\n",
            "\n",
            " [[18420     0]\n",
            "  [ 1347     0]]\n",
            "\n",
            " [[18571     0]\n",
            "  [ 1196     0]]\n",
            "\n",
            " [[18811     0]\n",
            "  [  956     0]]\n",
            "\n",
            " [[18771     0]\n",
            "  [  996     0]]]\n",
            "90.71% (+/- 1.08%)\n",
            "Test accuracy is: {} 0.88 (+/- 0.00)\n",
            "Test roc-auc is: {} 0.56 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}