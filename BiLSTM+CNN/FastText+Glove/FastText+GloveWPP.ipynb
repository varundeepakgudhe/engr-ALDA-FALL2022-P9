{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmfhxkfM9S6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/corpus/train.csv\")\n",
        "\n",
        "#data_csv = pd.read_csv(url_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_csv.head()"
      ],
      "metadata": {
        "id": "kXMDQXJ3BX3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_data = (r\"https://raw.githubusercontent.com/conversationai/unhealthy-conversations/main/unhealthy_full.csv\")\n",
        "\n",
        "data_csv = pd.read_csv(url_data)"
      ],
      "metadata": {
        "id": "NT6AepL6BX9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LeCtp8vgBYAK",
        "outputId": "b94e3f21-a2e6-48f6-db06-949ded48eaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afb63eef-dedc-491b-a24a-b5ebf8bbf445\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afb63eef-dedc-491b-a24a-b5ebf8bbf445')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afb63eef-dedc-491b-a24a-b5ebf8bbf445 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afb63eef-dedc-491b-a24a-b5ebf8bbf445');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7mQ2QVRBYCV",
        "outputId": "2acec010-d8a1-41a4-ce9e-7a503f9676fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227975, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv[\"comment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyUo0Kw5p-L",
        "outputId": "ba6f5b6a-171a-4390-9cc1-19d7c11ce3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Moon, Do you *really* need it spelled out to you?\n",
              "1         It means you can ask the values questions, but...\n",
              "2                                           To you perhaps.\n",
              "3         I don't want to put words in your mouth, but a...\n",
              "4         perhaps this is not a problem seeing as how ev...\n",
              "                                ...                        \n",
              "227970    In 2001 the price of oil was around $25 a barr...\n",
              "227971    How about answering the question asked rather ...\n",
              "227972    Re: 'he is not a war mugger' [sic]You seem to ...\n",
              "227973    At last someone trotting out facts instead of ...\n",
              "227974    why should I care what the catholic dinosaurs ...\n",
              "Name: comment, Length: 227975, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop=data_csv.drop_duplicates(subset=\"comment\")"
      ],
      "metadata": {
        "id": "nDc5Mt7R1o6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv_drop.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2idkutuJ1ze-",
        "outputId": "1c41ac90-6b79-4acf-be14-c2175a8cd1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44355, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull= data_csv_drop.dropna()\n",
        "data_cnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqqNcmOYpywO",
        "outputId": "c031a9ac-c83e-4542-8525-b2d8ae496bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44354, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cnull.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yOs2LL6ot3dP",
        "outputId": "3ba1ff14-57e9-4ed1-d1d9-efbb8a14db4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     _unit_id                                            comment  _trust  \\\n",
              "0  2028122383  Moon, Do you *really* need it spelled out to you?  0.9333   \n",
              "1  2327208388  It means you can ask the values questions, but...  0.9348   \n",
              "2  1812167562                                    To you perhaps.  0.9929   \n",
              "3  2319155917  I don't want to put words in your mouth, but a...  0.9778   \n",
              "4  1812168807  perhaps this is not a problem seeing as how ev...  0.9145   \n",
              "\n",
              "   _worker_id  antagonize  condescending  dismissive  generalisation  \\\n",
              "0    44856405           0              0           0               0   \n",
              "1    45322411           0              0           0               1   \n",
              "2    44126774           0              0           0               0   \n",
              "3    45178195           0              0           0               0   \n",
              "4    44619566           0              0           0               0   \n",
              "\n",
              "   generalisation_unfair  healthy  hostile  sarcastic  \n",
              "0                    0.0        1        0          0  \n",
              "1                    1.0        0        0          0  \n",
              "2                    0.0        1        0          0  \n",
              "3                    0.0        1        0          0  \n",
              "4                    0.0        0        0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c19f4e8a-5e21-4220-8bb2-0c621c5c4e33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>_trust</th>\n",
              "      <th>_worker_id</th>\n",
              "      <th>antagonize</th>\n",
              "      <th>condescending</th>\n",
              "      <th>dismissive</th>\n",
              "      <th>generalisation</th>\n",
              "      <th>generalisation_unfair</th>\n",
              "      <th>healthy</th>\n",
              "      <th>hostile</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028122383</td>\n",
              "      <td>Moon, Do you *really* need it spelled out to you?</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>44856405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2327208388</td>\n",
              "      <td>It means you can ask the values questions, but...</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>45322411</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1812167562</td>\n",
              "      <td>To you perhaps.</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>44126774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2319155917</td>\n",
              "      <td>I don't want to put words in your mouth, but a...</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>45178195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1812168807</td>\n",
              "      <td>perhaps this is not a problem seeing as how ev...</td>\n",
              "      <td>0.9145</td>\n",
              "      <td>44619566</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c19f4e8a-5e21-4220-8bb2-0c621c5c4e33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c19f4e8a-5e21-4220-8bb2-0c621c5c4e33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c19f4e8a-5e21-4220-8bb2-0c621c5c4e33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_del_ind= data_cnull[(data_cnull[\"sarcastic\"]==0) & (data_cnull[\"healthy\"]==0) & (data_cnull[\"antagonize\"]==0) & (data_cnull[\"condescending\"]==0) & (data_cnull[\"dismissive\"]==0) & (data_cnull[\"hostile\"]==0)].index\n",
        "data_pnull = data_cnull.drop(data_del_ind)\n",
        "data_pnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWvcOswmtkC1",
        "outputId": "0b22edf9-e67e-44c6-bd1f-a06e182657ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42278, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n",
        "data_wnull = data_pnull.drop(data_wnull_ind)\n",
        "data_wnull.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOdsHMpvzyrM",
        "outputId": "441f8f50-5fc0-4f98-c8c6-63fe8f1b96b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9fd0ced5066b>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  data_wnull_ind=data_pnull[((data_cnull[\"antagonize\"]==1) | (data_cnull[\"condescending\"]==1) | (data_cnull[\"dismissive\"]==1) | (data_cnull[\"hostile\"]==1)) & (data_cnull[\"healthy\"]==1)].index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39533, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_test= train_test_split(data_wnull, test_size=0.2, random_state=42)\n",
        "print(data_train.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5g_K__T0wfa",
        "outputId": "336a292b-4c10-4891-b994-f936d8ef4f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31626, 12) (7907, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_wnull[(data_wnull['sarcastic']==1) & (data_wnull['healthy']==0)]"
      ],
      "metadata": {
        "id": "olJUcqUtzlbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_wnull[(data_wnull['sarcastic']==0) & (data_wnull['healthy']==0) & (data_wnull['antagonize']==0) & (data_wnull['condescending']==0) & (data_wnull['dismissive']==0) & (data_wnull['generalisation']==0) & (data_wnull['generalisation_unfair']==0) & (data_wnull['hostile']==0)]"
      ],
      "metadata": {
        "id": "rlBcbpTktIjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_all= data_wnull.drop(data_wnull[(data_wnull['sarcastic']==0) & (data_wnull['healthy']==0) & (data_wnull['antagonize']==0) & (data_wnull['condescending']==0) & (data_wnull['dismissive']==0) & (data_wnull['generalisation']==0) & (data_wnull['generalisation_unfair']==0) & (data_wnull['hostile']==0)].index)\n",
        "# data_all.shape"
      ],
      "metadata": {
        "id": "3OWD6fgwwu65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgEKZzkNVe-",
        "outputId": "ee52b71f-1f0e-4106-bbc4-79dee06e985d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "embed_size = 200\n",
        "max_features = 20000 \n",
        "maxlen = 200 \n",
        "\n",
        "print('Loading data...')\n",
        "\n",
        "classes = [\"sarcastic\", \"healthy\", \"antagonize\", \"condescending\", \"dismissive\", \"hostile\"]\n",
        "y = data_train[classes].values\n",
        "y_test = data_test[classes].values\n",
        "\n",
        "train_sentences = data_train[\"comment\"]\n",
        "test_sentences = data_test[\"comment\"]\n",
        "\n",
        "print('Preprocessing train') \n",
        "train = list()\n",
        "for i in train_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    train.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "print('Preprocessing test')\n",
        "test = list()\n",
        "for i in test_sentences:\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')#removing punctuations\n",
        "    test.append([i.lower() for i in (tokenizer.tokenize(str(i))) if i not in stop_words])\n",
        "\n",
        "train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTivuJ6Ltju",
        "outputId": "1235cdc4-429e-43bd-f996-3635e52d9b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing train\n",
            "Preprocessing test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'upset', 'just', 'hoping', 'better', 'globe', 'mail'],\n",
              " ['i',\n",
              "  'understand',\n",
              "  'civil',\n",
              "  'servant',\n",
              "  'would',\n",
              "  'annoyed',\n",
              "  'raising',\n",
              "  'tfsa',\n",
              "  'limit',\n",
              "  'given',\n",
              "  'well',\n",
              "  'cared',\n",
              "  'retirement',\n",
              "  'but',\n",
              "  'us',\n",
              "  'dependent',\n",
              "  'investments',\n",
              "  'tfsas',\n",
              "  'godsend',\n",
              "  'please',\n",
              "  'raise',\n",
              "  'limit'],\n",
              " ['right', 'and', 'going', 'get', 'whole', 'lot', 'uglier'],\n",
              " ['but', 'first', 'you', 'serious'],\n",
              " ['call',\n",
              "  'thought',\n",
              "  'police',\n",
              "  'i',\n",
              "  'think',\n",
              "  'women',\n",
              "  'thinking',\n",
              "  'sex',\n",
              "  'selective',\n",
              "  'abortion',\n",
              "  'oh',\n",
              "  'wait',\n",
              "  'apparently',\n",
              "  'feel',\n",
              "  'additional',\n",
              "  'baby',\n",
              "  'may',\n",
              "  'stress',\n",
              "  'financially',\n",
              "  'carry']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnAgYv_Rh1tc",
        "outputId": "8d99ee38-9037-4b34-bee7-a23a5348c9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31626"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS7--RqfjBhm",
        "outputId": "64b0ea4c-ae24-4925-9167-af679b1f1d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7907"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "EMBEDDING_FILE = '/content/drive/My Drive/glove.twitter.27B.200d.txt' "
      ],
      "metadata": {
        "id": "L7Q4DB-pmVOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dc4ae9-d9d1-4e59-b510-7a7cb6dbf121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "g-a2OOXgzZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, BatchNormalization, SpatialDropout1D, GlobalAveragePooling1D, concatenate, Activation, LSTM, Bidirectional\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, multilabel_confusion_matrix"
      ],
      "metadata": {
        "id": "g8yG4oc_zKiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "tokenized_train_sentences = tokenizer.texts_to_sequences(train)\n",
        "tokenized_test_sentences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "train_padding = pad_sequences(tokenized_train_sentences, maxlen)\n",
        "test_padding = pad_sequences(tokenized_test_sentences, maxlen)\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
        "\n",
        "print(list(embeddings_index.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUdkl7HP0J9x",
        "outputId": "1eca9fb4-2c2e-446f-abd7-a6e7c26f43e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<user>', array([ 3.1553e-01,  5.3765e-01,  1.0177e-01,  3.2553e-02,  3.7980e-03,\n",
            "        1.5364e-02, -2.0344e-01,  3.3294e-01, -2.0886e-01,  1.0061e-01,\n",
            "        3.0976e-01,  5.0015e-01,  3.2018e-01,  1.3537e-01,  8.7039e-03,\n",
            "        1.9110e-01,  2.4668e-01, -6.0752e-02, -4.3623e-01,  1.9302e-02,\n",
            "        5.9972e-01,  1.3444e-01,  1.2801e-02, -5.4052e-01,  2.7387e-01,\n",
            "       -1.1820e+00, -2.7677e-01,  1.1279e-01,  4.6596e-01, -9.0685e-02,\n",
            "        2.4253e-01,  1.5654e-01, -2.3618e-01,  5.7694e-01,  1.7563e-01,\n",
            "       -1.9690e-02,  1.8295e-02,  3.7569e-01, -4.1984e-01,  2.2613e-01,\n",
            "       -2.0438e-01, -7.6249e-02,  4.0356e-01,  6.1582e-01, -1.0064e-01,\n",
            "        2.3318e-01,  2.2808e-01,  3.4576e-01, -1.4627e-01, -1.9880e-01,\n",
            "        3.3232e-02, -8.4885e-01, -2.5684e-01,  2.6369e-01,  2.9562e-01,\n",
            "        1.8470e-01, -2.0668e-01, -1.3297e-02,  1.2233e-01, -4.7751e-01,\n",
            "       -1.7202e-01, -1.4577e-01,  4.7446e-02, -1.5824e-01,  5.4215e-02,\n",
            "       -1.9426e-01, -8.1484e-02,  9.9009e-02,  1.0159e-01,  4.3571e-02,\n",
            "        5.0245e-01,  1.3362e-01,  6.5985e-02,  3.2969e-02, -2.0170e-01,\n",
            "       -5.6905e-01, -1.3203e-01,  7.3347e-02, -6.3728e-02, -2.7960e-01,\n",
            "       -3.8481e-01, -2.0193e-02,  2.2298e-01, -5.9115e-02,  4.5198e-02,\n",
            "       -1.3995e-01, -1.3299e-01,  4.7309e-01, -2.1874e-02,  3.8758e-01,\n",
            "       -7.4926e-02, -2.8093e-03, -2.9829e-01, -7.4987e-02, -5.8542e-01,\n",
            "       -1.8065e-01, -4.1805e-02,  4.1938e-01,  4.1004e-01, -5.9110e-01,\n",
            "        1.0459e-01,  1.0724e-01,  6.9768e-01, -1.5901e-01, -5.9596e-02,\n",
            "        2.9368e-01, -1.9609e-01,  3.9124e-01, -2.9333e-01, -5.0833e-03,\n",
            "       -3.7854e-01,  3.3858e-01,  2.4782e-01,  2.9144e-01, -2.2833e-01,\n",
            "        1.9421e-01, -5.5409e-02,  1.0322e-01,  3.8963e-01, -2.7813e-01,\n",
            "        2.1963e-01,  4.0014e-01,  7.1036e-02, -7.9786e-02,  1.9534e-01,\n",
            "       -6.9432e-01, -9.3075e-02, -1.3729e-01, -5.4014e-01,  5.7165e-01,\n",
            "        2.4443e-01,  3.6741e-02,  3.3606e-02, -1.4398e-01,  2.5873e-01,\n",
            "        8.9008e-02,  1.1109e-01,  3.8387e-01,  1.9013e-01, -2.3252e-01,\n",
            "       -2.6271e-01, -2.6936e-01, -3.2409e-01,  5.5236e-01, -4.6158e-01,\n",
            "       -1.1086e-01, -3.8417e-01,  5.9605e-01, -1.4479e-01, -2.8762e-01,\n",
            "       -2.9638e-01,  2.1889e-01, -4.1257e+00,  6.9382e-01, -2.6307e-01,\n",
            "       -1.3691e-02,  3.2916e-02,  1.7627e-02, -2.9090e-02,  4.2807e-01,\n",
            "       -2.0815e-01,  5.0598e-01, -8.0836e-02,  4.5083e-01, -1.1466e-01,\n",
            "       -2.7782e-01, -3.8373e-02,  1.5672e-01, -1.0899e-02,  8.2053e-02,\n",
            "       -1.9766e-01,  2.0574e-01, -7.5329e-02,  8.3754e-02, -7.2767e-01,\n",
            "        1.0403e-01,  4.2831e-01,  4.1023e-01, -9.7314e-02,  1.5128e-01,\n",
            "        3.9287e-01, -1.7807e-01, -2.9196e-02,  5.7502e-01, -1.7823e-01,\n",
            "       -7.6488e-01, -4.7383e-01, -2.1984e-01,  2.1190e-01, -1.5729e-02,\n",
            "       -6.2927e-02,  2.6674e-01, -2.3617e-01,  1.8109e-01, -2.6583e-01,\n",
            "        9.0904e-02, -8.1205e-01, -4.5664e-01, -4.6540e-01,  5.2066e-01],\n",
            "      dtype=float32)), ('.', array([ 3.5132e-01,  5.6084e-04, -2.1488e-01, -4.7070e-02, -1.7777e-01,\n",
            "        6.6162e-01, -7.4805e-03, -1.5963e-01, -2.2129e-01,  6.5523e-01,\n",
            "        3.4600e-01, -2.2968e-01, -7.8954e-02,  2.7465e-01,  3.6018e-01,\n",
            "        2.0373e-01, -4.8134e-02,  9.1749e-02, -9.3562e-02, -8.8653e-02,\n",
            "       -6.1514e-01, -1.1240e-01, -2.1046e-01,  1.3129e-01,  1.1224e-01,\n",
            "       -9.2995e-01, -1.8006e-01,  9.6874e-03,  9.3647e-01, -1.9493e-01,\n",
            "       -1.3873e-01,  1.8719e-01, -2.2502e-02,  3.9516e-01,  3.3007e-01,\n",
            "        3.6089e-01,  7.8608e-03, -2.4064e-02, -3.2890e-01, -2.8101e-01,\n",
            "       -2.0223e-01,  3.0049e-01, -2.2843e-01,  6.3900e-02,  5.9025e-01,\n",
            "       -1.7992e-01,  7.2733e-01,  2.8216e-02, -4.3656e-01, -6.4330e-02,\n",
            "        8.7363e-02,  5.4825e-03,  3.4902e-01,  8.1738e-02,  3.5089e-01,\n",
            "        5.3459e-02,  5.5370e-02,  1.0797e-01,  1.9663e-01,  6.3077e-01,\n",
            "       -7.4041e-02,  1.3848e-01,  2.4849e-01, -1.0183e-01,  4.2992e-01,\n",
            "       -4.1886e-01,  1.0814e-02, -4.8654e-01,  1.9154e-01, -1.8615e-01,\n",
            "        1.7851e-01,  4.0530e-01,  1.4635e-01,  2.2446e-01,  1.2614e-01,\n",
            "       -4.5649e-01, -1.6633e-01,  1.5915e-01, -1.2543e-01, -5.5649e-02,\n",
            "       -3.0481e-01,  1.2712e-01, -1.5809e-02, -6.2656e-02,  8.7436e-01,\n",
            "        4.8340e-01, -1.6578e-01,  3.9106e-01,  1.1319e-01, -1.7630e-01,\n",
            "        1.4110e-02, -4.0942e-01,  3.2281e-01, -2.2064e-01,  2.2058e-02,\n",
            "        7.6171e-02,  1.3255e-01, -6.7011e-02,  4.5695e-01,  4.4040e-02,\n",
            "        7.6988e-02, -1.5650e-01,  3.5628e-01,  1.8131e-01, -4.0064e-02,\n",
            "        5.6617e-01, -3.7482e-01, -3.6297e-01, -1.8098e-01,  2.6808e-02,\n",
            "       -1.6885e-01,  2.4951e-01, -1.4548e-01, -2.3878e-01, -7.4018e-02,\n",
            "       -3.2295e-02,  1.6866e-01,  3.3322e-01,  2.3116e-02, -4.7220e-01,\n",
            "        2.7615e-01,  2.5764e-01, -1.4382e-01, -3.3590e-01,  2.9436e-02,\n",
            "       -1.5695e-01, -8.4597e-02, -1.0684e-01, -2.4784e-01,  2.1849e-02,\n",
            "       -1.4485e-01, -1.2874e-01, -1.7975e-01, -2.0351e-01, -8.5811e-02,\n",
            "        3.1607e-01,  2.8477e-01, -1.1954e-02,  1.4860e-01, -1.5402e-01,\n",
            "        3.6125e-01, -8.2339e-02,  2.7478e-01,  5.6358e-02, -2.1401e-01,\n",
            "        7.4459e-01,  4.8518e-02,  6.1750e-02,  1.7656e-01, -7.5019e-02,\n",
            "       -6.1491e-01,  6.3787e-02, -3.9376e+00,  5.4504e-01,  1.5964e-01,\n",
            "       -4.1187e-01,  5.1993e-01,  1.3420e-01, -3.1554e-02, -2.6429e-01,\n",
            "        4.0603e-02,  2.6610e-01,  8.2515e-02, -9.0602e-02,  5.7244e-03,\n",
            "        4.0602e-01, -3.0109e-01,  3.7078e-01,  1.1716e-01, -2.6164e-01,\n",
            "       -3.8366e-01, -1.3616e-01, -3.0152e-01, -1.7193e-01,  1.4108e-01,\n",
            "        3.1278e-01,  1.6425e-01,  1.7671e-01, -2.9942e-01,  4.3029e-01,\n",
            "        5.7682e-02, -1.4110e-01, -3.1367e-02,  5.8953e-02, -3.0550e-01,\n",
            "       -8.8512e-01, -4.7983e-01, -5.6183e-02, -1.0459e-01,  3.9792e-02,\n",
            "       -4.4370e-01,  1.4186e-01, -4.2475e-01,  2.3551e-02, -9.6965e-02,\n",
            "        7.9513e-02, -1.4683e+00,  3.6684e-02, -3.7206e-02,  8.5384e-01],\n",
            "      dtype=float32)), (':', array([ 8.0767e-01,  4.9786e-01,  8.2696e-02, -7.9298e-03,  8.2471e-02,\n",
            "       -5.9360e-01, -1.8753e-01,  4.8645e-01,  1.0719e-01, -3.1299e-01,\n",
            "        1.7609e-01,  4.6026e-02,  3.6029e-02,  4.7656e-01, -1.2150e-01,\n",
            "       -9.8428e-02, -1.8983e-01,  3.8915e-02, -2.0902e-01, -3.1600e-01,\n",
            "        5.0070e-01, -2.2646e-01,  1.2353e-01, -2.7012e-01,  7.0739e-01,\n",
            "       -9.8348e-01, -5.4111e-01,  3.2431e-01, -1.9345e-01, -1.8299e-01,\n",
            "       -4.5738e-01, -4.4089e-01, -4.7504e-01, -9.0636e-02,  8.5478e-02,\n",
            "        2.8124e-02, -2.8045e-01,  2.1273e-01,  6.0152e-03, -3.7948e-01,\n",
            "       -6.8825e-01, -5.9779e-01, -4.6953e-02,  6.5887e-01,  4.4564e-01,\n",
            "       -2.5169e-01, -3.0223e-02,  2.5673e-01, -2.9300e-01, -4.7083e-02,\n",
            "       -4.3578e-01, -4.5254e-01, -1.5416e-01,  3.5722e-01,  4.8247e-01,\n",
            "        4.2448e-01, -3.2445e-01, -2.7119e-01,  3.1039e-01, -4.0884e-01,\n",
            "       -4.2270e-01,  8.0102e-02,  2.8311e-01,  1.3829e-02,  9.4008e-01,\n",
            "       -5.8542e-01,  3.4853e-01, -1.5336e-01,  1.6540e-01,  9.3904e-02,\n",
            "        4.6697e-01,  1.1781e-01,  9.1151e-02, -4.1349e-01, -1.9446e-01,\n",
            "       -5.8665e-01,  9.4378e-02,  1.4077e-01,  3.5482e-01, -1.7125e-01,\n",
            "       -5.0602e-02,  2.1653e-01, -1.1619e-01,  4.5904e-01, -3.0238e-01,\n",
            "        7.2354e-02, -4.6345e-01,  1.3963e+00, -2.1264e-01, -2.5539e-01,\n",
            "       -3.1002e-01, -2.7831e-01, -4.0129e-01,  1.0612e-01, -4.2636e-01,\n",
            "        3.5816e-02,  2.0376e-01,  2.2088e-01,  4.7981e-01, -7.6700e-02,\n",
            "        3.3610e-01,  3.4746e-01,  8.8655e-02,  6.5177e-01,  4.5665e-01,\n",
            "        9.1346e-02, -5.3175e-01,  1.4724e-01, -4.3770e-01,  2.7911e-01,\n",
            "       -6.7202e-01,  3.8052e-01, -1.1494e-02, -1.1314e-01, -2.9098e-01,\n",
            "        4.3887e-01, -4.5870e-03,  7.9091e-02, -4.5291e-03, -6.3007e-01,\n",
            "        1.4320e-01,  1.9420e-01, -7.6888e-02, -2.1021e-01,  2.5376e-01,\n",
            "       -4.7742e-01,  1.4886e-01,  2.2570e-01, -4.0912e-01,  1.8141e-01,\n",
            "       -1.9515e-01, -3.7970e-01, -3.2150e-01,  7.5749e-03,  6.8672e-01,\n",
            "        6.2260e-02,  1.0575e-03,  3.0921e-01,  1.0123e-01, -2.8578e-01,\n",
            "        2.0308e-01, -1.3243e-01, -8.9740e-01,  7.0887e-01, -4.7530e-02,\n",
            "        5.4342e-01, -4.0847e-01,  1.4928e-01,  2.3341e-01,  2.4772e-02,\n",
            "        3.0833e-01, -1.4153e-01, -3.6293e+00,  4.0686e-01,  2.2129e-01,\n",
            "       -2.9930e-01, -1.7630e-02,  4.5388e-02, -3.5380e-02, -1.4189e-01,\n",
            "       -9.8312e-02,  8.3338e-02, -2.0842e-01,  5.9749e-01,  3.9259e-02,\n",
            "       -4.6968e-02, -3.8719e-02,  4.1470e-02,  4.0501e-01, -1.3983e-01,\n",
            "       -4.0245e-01,  3.0089e-01, -3.7620e-02,  1.2831e-01, -1.5879e-01,\n",
            "        1.7023e-01,  7.5995e-01,  3.5490e-01,  4.6914e-03, -5.3001e-02,\n",
            "        1.3518e-01,  4.0568e-01, -2.2714e-01, -6.3414e-02, -3.6388e-01,\n",
            "       -4.5030e-01, -4.7098e-01, -9.7300e-02,  7.7199e-01, -1.0850e-02,\n",
            "       -1.5552e-01,  1.1186e-01,  6.8971e-02, -5.5048e-01, -5.0010e-01,\n",
            "        1.8860e-01, -8.5631e-01, -7.3302e-02, -4.7785e-01,  6.7059e-01],\n",
            "      dtype=float32)), ('rt', array([ 0.55687  ,  0.63284  , -0.15609  ,  0.26397  ,  0.28015  ,\n",
            "       -0.36506  , -0.12128  ,  0.45217  , -0.16123  ,  0.015791 ,\n",
            "        0.49511  ,  0.054643 ,  0.66865  ,  0.44101  , -0.48446  ,\n",
            "        0.12594  ,  0.40596  , -0.086889 , -0.2352   , -0.0073657,\n",
            "        0.58835  , -0.12101  , -0.11671  , -0.47415  ,  0.47753  ,\n",
            "       -1.3069   , -0.42765  , -0.0055401,  0.2247   ,  0.061141 ,\n",
            "        0.010707 ,  0.20652  , -0.48375  ,  0.40042  ,  0.35776  ,\n",
            "        0.17049  , -0.23819  ,  0.28888  , -0.069899 ,  0.094793 ,\n",
            "       -0.33917  , -0.11422  ,  0.016834 ,  0.53581  ,  0.25739  ,\n",
            "       -0.2775   ,  0.056731 ,  0.34448  , -0.10715  , -0.21423  ,\n",
            "        0.020693 , -0.59172  , -0.39452  , -0.1925   ,  0.20454  ,\n",
            "        0.40205  , -0.096825 , -0.037272 ,  0.32491  , -0.26628  ,\n",
            "        0.0072484,  0.19783  ,  0.17485  , -0.071738 ,  0.084738 ,\n",
            "       -0.43062  ,  0.016838 ,  0.14359  , -0.13822  ,  0.27964  ,\n",
            "        0.31179  ,  0.33653  ,  0.12314  , -0.15906  , -0.62741  ,\n",
            "       -0.83838  , -0.069363 ,  0.28698  , -0.11668  , -0.43706  ,\n",
            "       -0.063269 , -0.19582  ,  0.42072  ,  0.19197  ,  0.057278 ,\n",
            "        0.32468  , -0.59688  ,  0.82594  , -0.7103   ,  0.47354  ,\n",
            "        0.11517  , -0.11188  , -0.53444  ,  0.015748 , -0.57038  ,\n",
            "       -0.1253   , -0.45733  ,  0.42662  ,  0.41064  , -0.27635  ,\n",
            "       -0.2032   ,  0.14295  ,  0.46532  ,  0.16804  ,  0.022694 ,\n",
            "       -0.24602  ,  0.059308 ,  0.73777  , -0.29451  , -0.33315  ,\n",
            "       -0.29938  ,  0.33871  ,  0.37681  ,  0.31939  , -0.014027 ,\n",
            "        0.32298  ,  0.054817 ,  0.13213  ,  0.3252   , -0.6153   ,\n",
            "       -0.12941  ,  0.28465  ,  0.32881  ,  0.25362  ,  0.27244  ,\n",
            "       -0.82169  ,  0.41908  , -0.62524  , -1.2176   ,  0.27902  ,\n",
            "       -0.33003  , -0.20213  , -0.28881  , -0.071473 ,  0.23549  ,\n",
            "        0.38409  ,  0.13101  ,  0.17312  ,  0.018403 , -0.29669  ,\n",
            "        0.17959  , -0.33733  , -0.82358  ,  0.1042   , -0.51619  ,\n",
            "        0.035018 , -0.19027  ,  0.50867  ,  0.023113 , -0.53112  ,\n",
            "        0.10043  ,  0.27881  , -4.2515   ,  0.44271  ,  0.29931  ,\n",
            "       -0.23305  ,  0.011018 ,  0.07118  ,  0.14536  ,  0.2012   ,\n",
            "       -0.046338 ,  0.36196  , -0.33985  ,  0.65517  , -0.045043 ,\n",
            "       -0.39308  ,  0.22788  ,  0.30343  , -0.058125 ,  0.18367  ,\n",
            "       -0.22463  , -0.46903  , -0.20435  , -0.13256  , -0.73335  ,\n",
            "       -0.42302  ,  0.14038  ,  0.59022  , -0.28843  , -0.09194  ,\n",
            "        0.18957  ,  0.039595 , -0.11694  ,  0.67706  , -0.23313  ,\n",
            "       -0.079736 , -0.46375  , -0.054137 ,  0.0557   , -0.12069  ,\n",
            "       -0.30669  , -0.15438  , -0.19857  ,  0.064394 , -0.14346  ,\n",
            "       -0.10524  , -0.57253  ,  0.23857  , -0.79235  ,  0.23761  ],\n",
            "      dtype=float32)), (',', array([ 0.3927   , -0.084181 , -0.6075   ,  0.3231   , -0.35919  ,\n",
            "        0.62664  ,  0.29758  , -0.21039  , -0.23201  ,  0.11897  ,\n",
            "        0.41827  , -0.21206  , -0.036036 ,  0.39526  ,  0.53432  ,\n",
            "       -0.33607  , -0.23529  ,  0.027524 , -0.21025  , -0.49712  ,\n",
            "        0.12486  , -0.14865  , -0.45697  ,  0.35445  , -0.31083  ,\n",
            "       -1.8664   , -0.32149  , -0.41014  ,  0.35596  ,  0.25467  ,\n",
            "       -0.35302  ,  0.059504 ,  0.1571   ,  0.61731  , -0.13229  ,\n",
            "        0.18362  ,  0.1329   , -0.13754  , -0.068064 , -0.29138  ,\n",
            "       -0.53293  , -0.048187 , -0.1334   ,  0.11968  , -0.045649 ,\n",
            "       -0.42278  ,  0.69403  ,  0.30971  , -0.66289  ,  0.017076 ,\n",
            "       -0.45864  , -0.23924  ,  0.24663  ,  0.13362  , -0.34587  ,\n",
            "        0.031223 , -0.43579  ,  0.16547  , -0.25115  ,  0.48124  ,\n",
            "       -0.21432  ,  0.22534  ,  0.20446  , -0.45843  ,  0.60826  ,\n",
            "        0.20866  , -0.46438  , -0.34758  ,  0.088277 , -0.30944  ,\n",
            "        0.41937  ,  0.12139  , -0.46349  ,  0.08518  , -0.070756 ,\n",
            "       -0.84094  , -0.32331  , -0.53684  ,  0.28473  ,  0.22625  ,\n",
            "        0.092721 ,  0.039561 , -0.48258  ,  0.069858 ,  0.49982  ,\n",
            "        0.54392  , -0.34694  ,  0.72118  , -0.30233  , -0.049354 ,\n",
            "       -0.47386  , -0.26428  ,  0.27401  ,  0.1476   ,  0.091779 ,\n",
            "        0.10067  ,  0.15366  , -0.65149  , -0.085811 , -0.22351  ,\n",
            "        0.28081  ,  0.046785 ,  0.42656  ,  0.12003  ,  0.13375  ,\n",
            "       -0.035338 ,  0.0067347, -0.36015  , -0.70746  , -0.033635 ,\n",
            "       -0.11495  ,  0.45643  ,  0.11071  , -0.18302  , -0.335    ,\n",
            "       -0.13371  , -0.32718  ,  0.28352  ,  0.19098  , -0.53333  ,\n",
            "        0.49566  , -0.18797  , -0.1495   , -0.027403 , -0.0051272,\n",
            "       -1.2365   ,  0.049948 , -0.0711   , -0.74201  , -0.13454  ,\n",
            "       -0.35839  , -0.20315  , -0.20721  , -0.10175  , -0.13152  ,\n",
            "        0.089342 , -0.13269  ,  0.36283  ,  0.03283  , -0.36339  ,\n",
            "       -0.0097338, -0.20782  , -0.17021  ,  0.44278  , -0.29718  ,\n",
            "        0.76858  ,  0.29221  ,  0.21189  ,  0.39831  , -0.12685  ,\n",
            "       -0.49607  , -0.21184  , -4.3586   , -0.0046878, -0.01809  ,\n",
            "       -0.13526  , -0.44054  , -0.496    ,  0.11789  , -1.0292   ,\n",
            "        0.17799  , -0.021813 ,  0.2141   , -0.27944  ,  0.024458 ,\n",
            "        0.28278  , -0.49199  ,  0.49358  ,  0.34139  , -0.67217  ,\n",
            "       -0.44666  , -0.46249  , -0.56888  , -0.71003  , -0.39095  ,\n",
            "        0.2495   ,  0.46399  ,  0.15134  , -0.5881   , -0.1399   ,\n",
            "       -0.11789  ,  0.17936  , -0.22037  , -0.27648  ,  0.16274  ,\n",
            "       -1.1748   , -0.99164  ,  0.13503  ,  0.016681 , -0.45423  ,\n",
            "       -0.61859  , -0.32079  , -0.25119  ,  0.27893  ,  0.25774  ,\n",
            "       -0.46615  , -0.48912  ,  0.093868 , -0.58506  ,  0.19544  ],\n",
            "      dtype=float32))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_index.get('society'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FXbqdDdH2O5",
        "outputId": "d7b083a2-058b-47c6-81d1-806e7b3e7289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JtsYXYgHXV5",
        "outputId": "8fbfbad6-827e-4cf6-8dfe-cb29643c5eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 4.93499994e-01,  3.56979996e-01,  6.60679996e-01,\n",
              "        -3.29749994e-02,  2.49890000e-01,  2.59359986e-01,\n",
              "        -2.71690004e-02,  6.84029981e-02, -2.90630013e-01,\n",
              "        -4.57049996e-01, -7.79400021e-02,  3.25159997e-01,\n",
              "        -1.48520005e+00, -6.74720034e-02, -1.70330003e-01,\n",
              "        -9.29639954e-03,  3.46280009e-01, -1.15750004e-02,\n",
              "         3.79649997e-02,  4.56169993e-01,  8.04859996e-02,\n",
              "         1.53099999e-01, -1.53090000e-01, -1.88099995e-01,\n",
              "        -1.81950003e-01,  8.72449994e-01,  3.97920012e-01,\n",
              "         4.09949988e-01,  4.49820012e-01, -1.96509995e-03,\n",
              "        -4.11240011e-02, -4.78670001e-02, -2.40449995e-01,\n",
              "        -8.68830010e-02,  1.41799999e-02, -2.37599999e-01,\n",
              "         2.51830012e-01,  2.85510004e-01,  4.45039988e-01,\n",
              "        -4.96439993e-01, -1.27090007e-01, -1.74759999e-01,\n",
              "         8.21959972e-02,  4.54090014e-02,  5.17199993e-01,\n",
              "         3.45459990e-02, -8.58220011e-02, -3.49240005e-01,\n",
              "         5.22149980e-01, -3.95099998e-01,  6.41229972e-02,\n",
              "        -4.20199990e-01, -1.59429997e-01,  1.82830006e-01,\n",
              "        -5.78849986e-02, -1.91820003e-02, -4.45470005e-01,\n",
              "         3.15420002e-01, -1.60960004e-01, -9.21389982e-02,\n",
              "        -2.49599993e-01, -1.38969999e-03, -4.26429987e-01,\n",
              "        -1.79319993e-01,  8.16539973e-02,  1.83239996e-01,\n",
              "        -3.20650011e-01, -1.20090001e-04, -1.30950004e-01,\n",
              "        -2.98119992e-01, -2.51440005e-03, -1.13179997e-01,\n",
              "        -4.63779986e-01, -1.99599996e-01,  8.51000011e-01,\n",
              "        -6.80089965e-02,  1.28700003e-01, -6.72559977e-01,\n",
              "        -1.22250002e-02,  1.42010003e-01,  9.24780011e-01,\n",
              "         8.51560012e-02,  2.68880010e-01,  3.03900003e-01,\n",
              "        -1.40300006e-01,  1.85990006e-01, -2.55259991e-01,\n",
              "         1.83809996e-01, -3.52219999e-01, -7.83990026e-02,\n",
              "        -2.69439995e-01, -1.80830002e-01, -2.73049995e-02,\n",
              "        -3.93319994e-01,  2.45419994e-01, -1.11989997e-01,\n",
              "         1.20930001e-01, -4.61059988e-01,  3.77730001e-03,\n",
              "         2.37990007e-01, -1.94020003e-01,  1.54730007e-01,\n",
              "        -9.95020033e-04,  9.22560021e-02,  3.98499995e-01,\n",
              "        -3.80620003e-01, -3.64980012e-01,  4.92919981e-03,\n",
              "        -7.39630014e-02,  1.40340000e-01, -2.30849996e-01,\n",
              "         1.30009994e-01,  3.04080009e-01,  1.05899997e-01,\n",
              "         7.88960010e-02,  8.62519965e-02,  5.86629994e-02,\n",
              "         1.79260001e-01, -1.50999993e-01,  9.52400029e-01,\n",
              "         3.73050004e-01,  2.25370005e-02,  3.28189991e-02,\n",
              "        -4.99610007e-01,  1.67480007e-01,  3.03900003e-01,\n",
              "         3.30579996e-01, -4.73080009e-01,  5.63880026e-01,\n",
              "         5.71219981e-01,  5.56689985e-02, -2.90730000e-01,\n",
              "        -1.74659997e-01, -1.30909994e-01,  1.54090002e-01,\n",
              "        -2.14599997e-01,  3.16760004e-01,  2.09309995e-01,\n",
              "         1.19190002e-02, -3.44049990e-01,  1.19900003e-01,\n",
              "         3.91039997e-01, -4.11810011e-01,  2.08399996e-01,\n",
              "         1.97319999e-01,  4.00730014e-01,  4.16170001e-01,\n",
              "         7.27659985e-02, -3.39839995e-01,  2.03820005e-01,\n",
              "         8.61840025e-02,  2.83129990e-01, -6.76259995e+00,\n",
              "        -5.68319976e-01,  1.49529994e-01, -2.46730000e-01,\n",
              "         6.04529977e-01,  1.21490002e-01, -5.27149975e-01,\n",
              "         1.35910004e-01,  1.56760007e-01,  5.89680001e-02,\n",
              "        -3.29739988e-01,  2.13029999e-02,  1.27500005e-03,\n",
              "         2.49960005e-01, -2.46380009e-02,  2.55180001e-01,\n",
              "         3.85809988e-01, -2.42229998e-01, -1.82710007e-01,\n",
              "         2.96099991e-01,  2.18549997e-01,  1.92330003e-01,\n",
              "         1.52290002e-01, -1.36489999e-02, -5.06220013e-02,\n",
              "        -9.64460000e-02,  1.56459995e-02,  5.11669993e-01,\n",
              "         1.47229999e-01, -8.14919993e-02, -3.10689986e-01,\n",
              "        -1.11670002e-01, -1.34330004e-01,  3.66699994e-01,\n",
              "        -2.96590000e-01, -4.99520004e-01, -6.04740009e-02,\n",
              "         4.69540013e-03, -1.66170001e-01, -1.70179993e-01,\n",
              "         1.12329997e-01,  1.60400003e-01, -1.71419993e-01,\n",
              "        -1.56210005e-01, -1.13660000e-01,  1.77059993e-01,\n",
              "        -5.36949992e-01, -2.96990007e-01],\n",
              "       [ 6.17739975e-01,  2.10460007e-01,  5.26979983e-01,\n",
              "         2.04669997e-01,  2.56999999e-01, -2.17319995e-01,\n",
              "         6.13740027e-01, -1.00050000e-02,  3.07209998e-01,\n",
              "        -1.02229998e-01,  2.70749986e-01, -3.69100004e-01,\n",
              "        -1.44330001e+00, -1.11670002e-01, -1.17739998e-02,\n",
              "        -6.15090013e-01, -4.75739986e-02,  2.96079993e-01,\n",
              "        -5.39900005e-01, -6.68519974e-01, -1.09159999e-01,\n",
              "        -1.77029997e-01, -4.54290003e-01,  1.73850000e-01,\n",
              "         2.92530000e-01,  1.61149994e-01,  1.93990007e-01,\n",
              "         4.46249992e-01,  8.74949992e-01, -9.24649984e-02,\n",
              "         1.37270000e-02, -1.85800001e-01, -3.38759989e-01,\n",
              "        -4.52300012e-01, -4.37480003e-01,  1.04529997e-02,\n",
              "         4.08419997e-01,  1.36130005e-01, -7.87840009e-01,\n",
              "         9.94710028e-02,  8.81630033e-02,  6.67980015e-01,\n",
              "         3.44150007e-01, -3.95269990e-01,  2.37240002e-01,\n",
              "         1.53620005e-01, -4.94489998e-01, -5.69370016e-02,\n",
              "        -1.42700002e-01, -6.94490001e-02, -3.08679998e-01,\n",
              "        -7.62329996e-02,  2.09879994e-01,  7.85560012e-02,\n",
              "        -5.61550021e-01,  1.80899993e-01, -5.17729998e-01,\n",
              "         4.63569999e-01,  3.09870005e-01, -1.90689992e-02,\n",
              "         6.72420025e-01,  3.91250014e-01, -1.41249999e-01,\n",
              "         1.15729999e-02,  1.26920000e-01,  8.84139985e-02,\n",
              "        -3.03539991e-01,  3.20219994e-01, -7.50429988e-01,\n",
              "         6.47589982e-01,  4.07449991e-01, -3.23150009e-01,\n",
              "         1.30799994e-01,  1.14030004e-01,  2.21560001e-01,\n",
              "         1.35450006e-01,  3.09760004e-01, -3.50659996e-01,\n",
              "         2.64750004e-01, -1.88380003e-01,  2.08059996e-01,\n",
              "         2.40319997e-01,  4.37350005e-01,  3.46289992e-01,\n",
              "         2.16110006e-01,  3.55710000e-01, -2.30889991e-02,\n",
              "         3.40140015e-01, -9.72529966e-03, -3.81139994e-01,\n",
              "         7.21250027e-02,  3.16109993e-02,  3.74760002e-01,\n",
              "         1.88130006e-01,  6.78629994e-01, -3.92329991e-01,\n",
              "        -7.54719973e-02, -1.30989999e-01, -3.88929993e-01,\n",
              "         1.18800001e-02,  4.13370013e-01, -1.09980002e-01,\n",
              "         3.00330013e-01, -4.63440008e-02,  2.24309996e-01,\n",
              "        -6.33570015e-01,  4.21099991e-01,  6.16150014e-02,\n",
              "        -8.79390016e-02, -1.04410000e-01, -1.40259996e-01,\n",
              "         6.67549968e-02,  4.73580003e-01,  1.67190000e-01,\n",
              "         1.07579999e-01, -2.21530005e-01,  4.83190008e-02,\n",
              "         4.22740012e-01,  2.33129993e-01,  3.69639993e-01,\n",
              "         3.38759989e-01,  4.13470000e-01, -1.12369999e-01,\n",
              "         1.57250002e-01,  7.30650008e-01, -4.92470013e-03,\n",
              "         2.72029996e-01,  3.07630002e-01,  4.70400006e-01,\n",
              "         2.60320008e-01, -9.54539999e-02, -7.60749996e-01,\n",
              "         5.30489981e-01,  9.07969996e-02, -4.70600009e-01,\n",
              "        -2.98500001e-01,  2.86399990e-01,  5.75810015e-01,\n",
              "         5.86469993e-02, -8.29100013e-01,  1.55760005e-01,\n",
              "         2.27329992e-02, -4.57190014e-02,  7.03580022e-01,\n",
              "         3.46920013e-01,  6.02749996e-02,  1.87549993e-01,\n",
              "         8.31049979e-01,  6.58439994e-02,  2.82869995e-01,\n",
              "         5.27379990e-01,  2.62519985e-01, -6.66750002e+00,\n",
              "         6.46210015e-01,  7.55470013e-03,  7.89969981e-01,\n",
              "        -5.29429972e-01, -2.45460004e-01,  6.39159977e-01,\n",
              "         2.55450010e-01, -2.92000007e-02,  1.96520001e-01,\n",
              "         4.12149988e-02,  1.56969994e-01, -4.11020011e-01,\n",
              "        -2.46849999e-01,  1.96740001e-01, -1.57219991e-02,\n",
              "        -6.41240031e-02, -2.64840007e-01, -1.38090000e-01,\n",
              "         1.73659995e-01,  2.79510003e-02, -3.74259986e-02,\n",
              "        -1.84029996e-01, -2.90650010e-01,  7.00429976e-02,\n",
              "        -3.51200014e-01,  2.65379995e-01, -3.25039998e-02,\n",
              "         2.40600005e-01,  7.91989982e-01, -1.24420002e-01,\n",
              "         3.51159982e-02, -4.12999988e-01,  8.66329968e-02,\n",
              "         4.00750011e-01,  8.77809990e-03,  2.95359999e-01,\n",
              "         2.83089995e-01,  1.54699996e-01, -1.89140007e-01,\n",
              "         2.05679998e-01, -1.89380005e-01,  3.32980007e-02,\n",
              "         2.28220001e-02,  3.32069993e-01, -1.12690004e-02,\n",
              "        -5.21650016e-01,  9.37829986e-02],\n",
              "       [ 1.49309993e-01,  2.78890014e-01,  8.99790004e-02,\n",
              "         4.08820003e-01, -2.13280007e-01,  1.54060006e-01,\n",
              "        -2.56420001e-02, -6.45150006e-01, -7.16430008e-01,\n",
              "        -1.17940001e-01, -2.96000004e-01, -4.33629990e-01,\n",
              "        -2.18850002e-01,  3.27779986e-02,  1.56059995e-01,\n",
              "         2.29659993e-02, -5.37949987e-02,  3.36219996e-01,\n",
              "        -6.21129990e-01,  1.01439998e-01,  2.37159997e-01,\n",
              "        -5.17579988e-02,  2.91000009e-01, -4.33099985e-01,\n",
              "         5.16030014e-01, -1.96659994e+00,  2.03109995e-01,\n",
              "         6.64469972e-02,  1.53620005e-01,  6.47710025e-01,\n",
              "        -3.85589987e-01,  4.74020001e-03, -5.22679985e-02,\n",
              "        -1.02860004e-01,  6.79090014e-03,  5.10339975e-01,\n",
              "        -1.91489995e-01, -1.06760003e-01, -9.36389983e-01,\n",
              "         2.32789993e-01, -6.88839972e-01,  4.67410013e-02,\n",
              "         1.03909999e-01,  1.70440003e-01,  5.33200026e-01,\n",
              "        -1.60929993e-01,  9.83640030e-02,  3.60960007e-01,\n",
              "         7.65760019e-02,  4.03809994e-01, -2.15099994e-02,\n",
              "         6.40610009e-02, -3.26440006e-01, -1.55499995e-01,\n",
              "        -1.44469999e-02,  5.53369999e-01,  2.59030014e-01,\n",
              "         1.04809999e-01,  3.16060007e-01,  2.11160004e-01,\n",
              "         3.02450001e-01, -1.88769996e-01, -5.31780005e-01,\n",
              "         2.29839999e-02,  7.75330007e-01, -1.79010004e-01,\n",
              "        -1.44610003e-01,  7.90169984e-02, -6.10840023e-01,\n",
              "        -3.25709999e-01, -2.43619993e-01, -1.44720003e-01,\n",
              "         1.72999993e-01, -4.82259989e-01,  7.96450004e-02,\n",
              "        -1.74239993e-01, -2.03050002e-01,  8.74959975e-02,\n",
              "         8.47809985e-02,  1.95270002e-01,  3.92699987e-01,\n",
              "         1.66130006e-01, -3.15250009e-01, -7.97149986e-02,\n",
              "         1.72120005e-01,  4.55529988e-01, -1.11140003e-02,\n",
              "        -1.19499996e-01, -3.92129987e-01,  4.91659999e-01,\n",
              "         5.60159981e-01,  2.40920007e-01,  1.55969998e-02,\n",
              "         3.36809993e-01,  4.72400010e-01,  1.77070007e-01,\n",
              "        -1.74810007e-01, -2.67159998e-01, -2.41479993e-01,\n",
              "        -6.50669992e-01,  6.38300002e-01,  3.78160000e-01,\n",
              "        -9.02540028e-01, -4.24569994e-01,  6.79570017e-03,\n",
              "        -3.53919994e-03, -3.85390013e-01, -1.34969994e-01,\n",
              "        -2.64380008e-01, -9.15509984e-02,  4.57789987e-01,\n",
              "         2.06609994e-01,  3.13549995e-01, -2.99309999e-01,\n",
              "        -2.04290003e-01,  9.16830003e-02, -1.40200004e-01,\n",
              "         5.10770023e-01,  1.07120000e-01,  4.91979986e-01,\n",
              "        -5.61600029e-01,  5.41849993e-02,  5.80320001e-01,\n",
              "        -1.65959999e-01, -3.86429995e-01, -9.70510021e-02,\n",
              "         5.87069988e-01,  1.49639994e-01,  2.71129996e-01,\n",
              "        -1.28140002e-01, -3.40479985e-02,  9.29009989e-02,\n",
              "         2.33309999e-01, -2.79320002e-01, -4.00099993e-01,\n",
              "        -3.41930008e-03, -3.92500013e-01,  4.91829999e-02,\n",
              "        -4.35799986e-01, -6.43820018e-02,  3.79060000e-01,\n",
              "        -5.46320006e-02, -6.76760018e-01,  3.51429999e-01,\n",
              "         6.52379990e-01,  2.13579997e-01,  3.58119994e-01,\n",
              "         1.52209997e-01, -2.51120001e-01, -1.37649998e-01,\n",
              "         9.19900015e-02, -1.34610001e-03, -6.02059984e+00,\n",
              "         2.26019993e-01, -2.52799988e-01, -1.91290006e-01,\n",
              "         3.13820004e-01,  4.46069986e-01,  3.66299987e-01,\n",
              "         7.58939981e-02,  9.39470008e-02, -1.59559995e-01,\n",
              "         3.99890006e-01,  6.31609976e-01,  2.94230014e-01,\n",
              "        -7.75839984e-01, -2.36670002e-01, -2.01969996e-01,\n",
              "         1.71549991e-02, -3.85230005e-01,  6.66890025e-01,\n",
              "         8.97039995e-02, -3.15990001e-01,  5.02569973e-01,\n",
              "         5.19559979e-01,  6.91239983e-02,  1.76709995e-01,\n",
              "        -5.75169995e-02,  7.59289980e-01,  3.31510007e-02,\n",
              "        -2.67729998e-01,  1.47880003e-01,  1.29350007e-01,\n",
              "         2.00200006e-01,  3.93059999e-01,  1.81410000e-01,\n",
              "         9.38799977e-02, -3.77009988e-01,  7.41410032e-02,\n",
              "         2.50459999e-01,  1.26509994e-01,  4.68109995e-01,\n",
              "         4.96540010e-01, -1.86880007e-01,  5.71060002e-01,\n",
              "        -4.09079999e-01, -4.02459987e-02, -4.48210001e-01,\n",
              "         3.16040009e-01, -4.93649989e-01],\n",
              "       [ 2.65980009e-02, -2.62769997e-01,  5.30200005e-02,\n",
              "         4.95119989e-01, -7.61169987e-03, -7.15669990e-02,\n",
              "         4.71109986e-01,  1.53109998e-01, -3.06970000e-01,\n",
              "        -8.89639974e-01,  4.60770018e-02, -2.02010006e-01,\n",
              "        -1.15509999e+00, -4.94549990e-01, -2.28829999e-02,\n",
              "        -3.09359998e-01, -1.78780004e-01, -1.59099996e-01,\n",
              "         4.41320002e-01, -1.47170007e-01, -2.14269996e-01,\n",
              "         1.32689998e-01, -8.21070001e-02,  6.54369965e-02,\n",
              "        -4.50340003e-01,  1.23989999e+00,  3.05629998e-01,\n",
              "         2.11940005e-01,  2.98629999e-01,  1.22800000e-01,\n",
              "        -3.09079997e-02,  1.93350002e-01, -1.57350004e-02,\n",
              "        -8.64489973e-02, -2.27970004e-01,  5.23540005e-02,\n",
              "         1.98550001e-01,  1.76699996e-01,  5.21550000e-01,\n",
              "         2.12520003e-01,  4.25190002e-01, -3.91689986e-01,\n",
              "         5.13490021e-01,  2.10419998e-01,  4.05290015e-02,\n",
              "        -1.17610000e-01, -3.45549993e-02,  2.64979992e-02,\n",
              "        -1.59370005e-01, -4.44409996e-01, -4.46280003e-01,\n",
              "        -2.86780000e-01,  1.47220001e-01, -9.07900035e-02,\n",
              "        -2.29709998e-01, -1.33239999e-01, -1.31359994e-01,\n",
              "         2.58729998e-02, -7.44360015e-02,  3.17510009e-01,\n",
              "         2.78400004e-01,  3.11850011e-01, -2.19940007e-01,\n",
              "         1.31310001e-01,  3.27650011e-01,  1.60620004e-01,\n",
              "        -2.49180004e-01, -4.70609993e-01,  2.18119994e-01,\n",
              "        -2.99239997e-02,  2.75530010e-01, -1.41110003e-01,\n",
              "        -1.90789998e-01, -2.33640000e-01,  5.59069991e-01,\n",
              "         1.28099993e-01,  1.44820005e-01, -2.66159996e-02,\n",
              "        -3.41890007e-01, -1.28690004e-01,  5.33850014e-01,\n",
              "         1.13990001e-01, -2.05579996e-01,  5.55110015e-02,\n",
              "         8.07489976e-02,  2.01519996e-01,  9.40999985e-02,\n",
              "        -2.95309991e-01, -3.84909987e-01, -1.10440001e-01,\n",
              "         1.46809995e-01, -4.74560000e-02,  2.18009993e-01,\n",
              "         2.67650008e-01,  1.52390003e-01, -3.60190012e-02,\n",
              "        -1.62890002e-01, -3.94089997e-01, -1.81070000e-01,\n",
              "         2.62910008e-01,  2.95870006e-02,  5.21369994e-01,\n",
              "        -3.90080005e-01,  5.06599993e-02,  3.27899992e-01,\n",
              "        -6.83030009e-01,  6.34929985e-02,  2.70889997e-01,\n",
              "        -1.36810005e-01, -5.08530021e-01, -7.11980015e-02,\n",
              "         2.10360005e-01,  5.91199994e-02, -3.86979990e-02,\n",
              "         1.33059993e-01, -1.10940002e-01, -2.25250006e-01,\n",
              "        -3.83080006e-01,  3.25859994e-01,  2.79139996e-01,\n",
              "        -7.88389966e-02, -1.11240000e-01,  1.67840004e-01,\n",
              "         4.75120008e-01,  1.75280005e-01,  2.97060013e-01,\n",
              "        -3.05839986e-01, -6.26159981e-02,  3.24229985e-01,\n",
              "         2.75579989e-01, -7.26950020e-02,  1.10809997e-01,\n",
              "        -7.77620003e-02,  6.23029992e-02, -1.67319998e-01,\n",
              "         1.78919993e-02,  3.32969993e-01,  8.43200013e-02,\n",
              "        -3.84149998e-01, -4.15050000e-01, -2.86880005e-02,\n",
              "         5.10499999e-02, -8.92129987e-02,  1.66189998e-01,\n",
              "         1.18260004e-01, -9.07250028e-03, -4.12149988e-02,\n",
              "         4.68349993e-01, -1.72930002e-01,  1.76430002e-01,\n",
              "         1.10110000e-01, -2.85459999e-02, -6.73330021e+00,\n",
              "        -5.46969995e-02, -2.00739995e-01,  3.54860008e-01,\n",
              "         2.15910003e-02, -2.02620000e-01, -1.45899996e-01,\n",
              "        -7.26960003e-02,  2.39329994e-01,  2.66059995e-01,\n",
              "        -1.29539996e-01, -4.22340006e-01,  8.44990020e-04,\n",
              "        -1.14459999e-01, -1.94580004e-01, -6.27970025e-02,\n",
              "         4.84189987e-01,  5.59880018e-01, -2.49180004e-01,\n",
              "        -9.73989964e-02,  4.46079999e-01, -2.23680004e-01,\n",
              "        -1.89199999e-01, -2.86920011e-01, -1.03399999e-01,\n",
              "         6.63190037e-02, -3.95420015e-01,  2.96420008e-01,\n",
              "         1.80450007e-01, -1.85100004e-01, -3.26150000e-01,\n",
              "        -2.72810012e-01, -1.02790003e-03, -6.45720005e-01,\n",
              "        -1.40760005e-01, -3.00500002e-02, -4.65689987e-01,\n",
              "        -2.94600010e-01, -4.62879986e-01, -1.17119998e-01,\n",
              "         4.04049993e-01,  2.60780007e-01, -3.08109999e-01,\n",
              "        -3.92259985e-01,  5.15779972e-01,  1.30500004e-01,\n",
              "        -2.22320005e-01,  2.67720014e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2wdBZkUXXcX",
        "outputId": "2df67ded-64f1-48c5-ad21-0a6e574d8c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "cvscores = []\n",
        "accscores = []\n",
        "rocscores = []\n",
        "\n",
        "for train, test in kfold.split(train_padding, y):\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
        "    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(6, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "\n",
        "    saved_model = \"FTGPP.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(train_padding, y, batch_size=32, epochs=4, callbacks=[checkpoint], validation_split=0.1)\n",
        "\n",
        "    scores = model.evaluate(train_padding[test], y[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    y_pred = model.predict(test_padding)\n",
        "\n",
        "    y_int = np.zeros_like(y_pred)\n",
        "    y_int[y_pred > 0.5] = 1\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_int)\n",
        "    print('Accuracy is {}'.format(accuracy))\n",
        "    accscores.append(accuracy)\n",
        "    \n",
        "    rocauc = roc_auc_score(y_test, y_pred)\n",
        "    print('Roc-auc score is {}'.format(rocauc))\n",
        "    rocscores.append(rocauc)\n",
        "    \n",
        "    print('Classification report {}'.format(classification_report(y_test, y_int, zero_division=0)))\n",
        "        \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"Test accuracy is: {} %.2f (+/- %.2f)\" %  (np.mean(accscores), np.std(accscores)))\n",
        "print(\"Test roc-auc is: {} %.2f (+/- %.2f)\" % (np.mean(rocscores), np.std(rocscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCce4Qc4YdDJ",
        "outputId": "df6d9858-da2c-4f11-c98d-89f230666c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 200, 200)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d (SpatialDrop  (None, 200, 200)    0           ['embedding[0][0]']              \n",
            " out1D)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 200, 256)     336896      ['spatial_dropout1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 198, 64)      49216       ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['conv1d[0][0]']                 \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 , 'global_max_pooling1d[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6)            390         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,394,758\n",
            "Trainable params: 4,394,758\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2385 - acc: 0.8795\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to FTGPP.hdf5\n",
            "890/890 [==============================] - 1203s 1s/step - loss: 0.2385 - acc: 0.8795 - val_loss: 0.2253 - val_acc: 0.8751\n",
            "Epoch 2/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2089 - acc: 0.8815\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1270s 1s/step - loss: 0.2089 - acc: 0.8815 - val_loss: 0.2308 - val_acc: 0.8748\n",
            "Epoch 3/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1792 - acc: 0.8799\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1282s 1s/step - loss: 0.1792 - acc: 0.8799 - val_loss: 0.2440 - val_acc: 0.8675\n",
            "Epoch 4/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1457 - acc: 0.8869\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1281s 1s/step - loss: 0.1457 - acc: 0.8869 - val_loss: 0.2860 - val_acc: 0.8618\n",
            "330/330 [==============================] - 61s 184ms/step - loss: 0.1072 - acc: 0.9050\n",
            "acc: 90.50%\n",
            "248/248 [==============================] - 46s 183ms/step\n",
            "Accuracy is 0.8484886809156443\n",
            "Roc-auc score is 0.617652391522169\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       565\n",
            "           1       0.91      0.97      0.94      7108\n",
            "           2       0.26      0.06      0.10       549\n",
            "           3       0.18      0.03      0.05       498\n",
            "           4       0.07      0.01      0.01       393\n",
            "           5       0.18      0.02      0.04       397\n",
            "\n",
            "   micro avg       0.88      0.73      0.80      9510\n",
            "   macro avg       0.27      0.18      0.19      9510\n",
            "weighted avg       0.71      0.73      0.71      9510\n",
            " samples avg       0.88      0.86      0.87      9510\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 200, 200)     4000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_1 (SpatialDr  (None, 200, 200)    0           ['embedding_1[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 200, 256)    336896      ['spatial_dropout1d_1[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 198, 64)      49216       ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 64)          0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,394,758\n",
            "Trainable params: 4,394,758\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2407 - acc: 0.8796\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to FTGPP.hdf5\n",
            "890/890 [==============================] - 1297s 1s/step - loss: 0.2407 - acc: 0.8796 - val_loss: 0.2263 - val_acc: 0.8751\n",
            "Epoch 2/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2097 - acc: 0.8812\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1289s 1s/step - loss: 0.2097 - acc: 0.8812 - val_loss: 0.2366 - val_acc: 0.8751\n",
            "Epoch 3/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1769 - acc: 0.8812\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1304s 1s/step - loss: 0.1769 - acc: 0.8812 - val_loss: 0.2559 - val_acc: 0.8631\n",
            "Epoch 4/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.8867\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1333s 1s/step - loss: 0.1449 - acc: 0.8867 - val_loss: 0.2979 - val_acc: 0.8530\n",
            "330/330 [==============================] - 65s 197ms/step - loss: 0.1094 - acc: 0.9031\n",
            "acc: 90.31%\n",
            "248/248 [==============================] - 48s 190ms/step\n",
            "Accuracy is 0.8429239914000253\n",
            "Roc-auc score is 0.6118021573423001\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       565\n",
            "           1       0.91      0.97      0.94      7108\n",
            "           2       0.24      0.08      0.12       549\n",
            "           3       0.26      0.05      0.08       498\n",
            "           4       0.13      0.01      0.02       393\n",
            "           5       0.19      0.02      0.04       397\n",
            "\n",
            "   micro avg       0.88      0.73      0.80      9510\n",
            "   macro avg       0.29      0.19      0.20      9510\n",
            "weighted avg       0.72      0.73      0.71      9510\n",
            " samples avg       0.87      0.86      0.86      9510\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 200, 200)     4000000     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " spatial_dropout1d_2 (SpatialDr  (None, 200, 200)    0           ['embedding_2[0][0]']            \n",
            " opout1D)                                                                                         \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 200, 256)    336896      ['spatial_dropout1d_2[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 198, 64)      49216       ['bidirectional_2[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 6)            390         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,394,758\n",
            "Trainable params: 4,394,758\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training model...\n",
            "Epoch 1/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2437 - acc: 0.8795\n",
            "Epoch 1: val_acc improved from -inf to 0.87512, saving model to FTGPP.hdf5\n",
            "890/890 [==============================] - 1381s 2s/step - loss: 0.2437 - acc: 0.8795 - val_loss: 0.2237 - val_acc: 0.8751\n",
            "Epoch 2/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.2109 - acc: 0.8814\n",
            "Epoch 2: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1372s 2s/step - loss: 0.2109 - acc: 0.8814 - val_loss: 0.2289 - val_acc: 0.8742\n",
            "Epoch 3/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.8797\n",
            "Epoch 3: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1368s 2s/step - loss: 0.1784 - acc: 0.8797 - val_loss: 0.2570 - val_acc: 0.8678\n",
            "Epoch 4/4\n",
            "890/890 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.8861\n",
            "Epoch 4: val_acc did not improve from 0.87512\n",
            "890/890 [==============================] - 1383s 2s/step - loss: 0.1477 - acc: 0.8861 - val_loss: 0.2974 - val_acc: 0.8634\n",
            "330/330 [==============================] - 71s 214ms/step - loss: 0.1713 - acc: 0.8849\n",
            "acc: 88.49%\n",
            "248/248 [==============================] - 53s 206ms/step\n",
            "Accuracy is 0.853294549133679\n",
            "Roc-auc score is 0.62188832642342\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       565\n",
            "           1       0.91      0.98      0.94      7108\n",
            "           2       0.22      0.03      0.05       549\n",
            "           3       0.22      0.01      0.02       498\n",
            "           4       0.11      0.01      0.01       393\n",
            "           5       0.07      0.00      0.00       397\n",
            "\n",
            "   micro avg       0.89      0.73      0.81      9510\n",
            "   macro avg       0.25      0.17      0.17      9510\n",
            "weighted avg       0.71      0.73      0.71      9510\n",
            " samples avg       0.88      0.87      0.87      9510\n",
            "\n",
            "89.77% (+/- 0.90%)\n",
            "Test accuracy is: {} 0.85 (+/- 0.00)\n",
            "Test roc-auc is: {} 0.62 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}